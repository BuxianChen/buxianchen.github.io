---
layout: post
title: "(WIP) ğŸ¤— Transformers Trainer API"
date: 2023-08-02 22:00:04 +0800
labels: [huggingface]
---

## åŠ¨æœºã€å‚è€ƒèµ„æ–™ã€æ¶‰åŠå†…å®¹

åŠ¨æœº

- ä½¿ç”¨ ğŸ¤— Transformers æ—¶æ¶‰åŠåˆ°æ¨¡å‹è®­ç»ƒçš„ä»£ç æ€ä¹ˆå†™æ‰æ˜¯ä¼˜é›…çš„æ–¹å¼
- ğŸ¤— Transformers Trainer çš„å®ç°é€»è¾‘

æ¶‰åŠå†…å®¹

- ğŸ¤— Transformers Trainer çš„å®ç°ç»†èŠ‚
- åº”è¯¥æ€æ ·æŒ‰éœ€åœ¨ Trainer çš„åŸºç¡€ä¸Šä¿®æ”¹/å¢åŠ åŠŸèƒ½

## Trainer ä½¿ç”¨å‚è€ƒ

ğŸ¤— Transformers GitHub é¡¹ç›®é‡ŒåŒ…å«äº†è®¸å¤šç«¯åˆ°ç«¯çš„ä¾‹å­, Trainer API çš„ä½¿ç”¨å¯ä»¥å€Ÿé‰´ [examples/pytorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch) åº•ä¸‹çš„å†…å®¹, ç²—ç•¥æ€»ç»“å¦‚ä¸‹:

```
# speed
benchmarking

# NLP
language-modeling
  - run_clm.py: Trainer
  - run_mlm.py: Trainer
  - run_plm.py: Trainer
question-answering
  - run_qa.py: QuestionAnsweringTrainer(è‡ªå®šä¹‰)
  - run_qa_beam_search.py: QuestionAnsweringTrainer(è‡ªå®šä¹‰)
  - run_seq2seq_qa.py: QuestionAnsweringSeq2SeqTrainer(è‡ªå®šä¹‰)
summarization
  - run_summarization.py: Seq2SeqTrainer
text-classification
  - run_glue.py: Trainer
  - run_xnli.py: Trainer
text-generation(ä»…å«æ¨ç†)
token-classification
  - run_ner.py: Trainer
translation
  - run_translation.py: Seq2SeqTrainer
multiple-choice(swag, é€‰æ‹©é¢˜)
  - run_swag.py: Trainer

# Audio
audio-classification
speech-pretraining
speech-recognition

# CV
contrastive-image-text
image-classification
image-pretraining
semantic-segmentation
```

## Trainer API è¯¦è§£

æœ¬èŠ‚é’ˆå¯¹å¦‚ä¸‹ç‰¹å®šç‰ˆæœ¬å¯¹ Trainer çš„ API è¿›è¡Œè§£é‡Š

```
accelerate==0.21.0
transformers==4.31.0
```

Trainer çš„æ‰€æœ‰æ–¹æ³•å¦‚ä¸‹:

```python
__init__

create_accelerator_and_postprocess

# ============ callback, state, control ==================
add_callback
pop_callback
remove_callback
call_model_init

# ======= training(train_dataset) ============
train
_inner_training_loop
training_step

compute_loss
compute_loss_context_manager
autocast_smart_context_manager


_load_best_model
_load_from_checkpoint
_load_optimizer_and_scheduler
_load_rng_state
_issue_warnings_after_load


_save
_save_checkpoint
_save_tpu
save_metrics
save_model
save_state
_rotate_checkpoints
_sorted_checkpoints

_maybe_log_save_evaluate
_tune_save_checkpoint

# ============ evaluate(eval_dataset) =============
evaluate

# ============ predict(test_dataset) ================
predict

# predictä¸evaluateéƒ½å¯èƒ½ä¼šè°ƒç”¨evaluation_loopæˆ–prediction_loop,è¿™ä¸¤ç§â€œloopâ€æœ€ç»ˆéƒ½è§¦å‘prediction_step
# é»˜è®¤ use_legacy_prediction_loop ä¸º False, æ­¤æ—¶ evaluate å’Œ predict éƒ½èµ° evaluation_loop

evaluation_loop
prediction_loop
prediction_step


# =========== train/evalauate/predict ========
_get_eval_sampler
_get_train_sampler
get_test_dataloader
get_train_dataloader
get_eval_dataloader
_remove_unused_columns
_get_collator_with_removed_columns
_set_signature_columns_if_needed
_gather_and_numpify

create_optimizer
create_optimizer_and_scheduler
create_scheduler
get_optimizer_cls_and_kwargs
_get_learning_rate

# ============= others ==========
_move_model_to_device
_nested_gather
_prepare_input
_prepare_inputs
_wrap_model
ipex_optimize_model


store_flos
is_local_process_zero
is_world_process_zero
floating_point_ops
num_examples


_get_output_dir
_hp_search_setup


_push_from_checkpoint
create_model_card
_report_to_hp_search
_add_sm_patterns_to_gitignore
init_git_repo
push_to_hub


hyperparameter_search
log
log_metrics
metrics_format
torch_jit_model_eval
```

## æ ·ä¾‹

```python
# trainer.train çš„è¾“å‡º:
class TrainOutput(NamedTuple):
    global_step: int
    training_loss: float
    metrics: Dict[str, float]

# trainer.prediction_loop/trainer.evaluation_loop çš„è¾“å‡º:
class EvalLoopOutput(NamedTuple):
    predictions: Union[np.ndarray, Tuple[np.ndarray]]
    label_ids: Optional[Union[np.ndarray, Tuple[np.ndarray]]]
    metrics: Optional[Dict[str, float]]
    num_samples: Optional[int]
# trainer.evaluate çš„è¾“å‡ºæ˜¯ EvalLoopOutput.metrics

# trainer.predict çš„è¾“å‡º
class PredictionOutput(NamedTuple):
    predictions: Union[np.ndarray, Tuple[np.ndarray]]
    label_ids: Optional[Union[np.ndarray, Tuple[np.ndarray]]]
    metrics: Optional[Dict[str, float]]

# text-classification/run_glue.py ç®€åŒ–åå¦‚ä¸‹
# Trainer å³å¯ä»¥ç”¨äºè®­ç»ƒ(å•å¡/å¤šå¡),ä¹Ÿå¯ä»¥ç”¨äºéªŒè¯(å¸¦æ ‡ç­¾,è·Ÿè®­ç»ƒä¸€è‡´,å•å¡/å¤šå¡),ä¹Ÿå¯ä»¥ç”¨äºå¯¹ä¸€ä¸ªæ•°æ®é›†åšæ¨ç†(æµ‹è¯•, ä¸å¸¦æ ‡ç­¾, å•å¡/å¤šå¡)
trainer = Trainer(
    model,
    training_args,
    data_collator,
    train_dataset,
    eval_dataset,
    tokenizer
    model_init=None,
    compute_metrics=compute_metrics,  # Callable
    callbacks=None,
    optimizers=None,
    preprocess_logits_for_metrics=None,  # Callable
)

# training_args.resume_from_checkpoint: Optional[str]
checkpoint = None
if training_args.resume_from_checkpoint is not None:
    checkpoint = training_args.resume_from_checkpoint
train_result: "TrainOutput" = trainer.train(resume_from_checkpoint=checkpoint)
metrics = train_result.metrics

metrics: "EvalLoopOutput.metrics" = trainer.evaluate(eval_dataset=eval_dataset)

# predict_dataset = test_dataset
predict_dataset = predict_dataset.remove_columns("label")
predictions: "PredictionOutput" = trainer.predict(predict_dataset, metric_key_prefix="predict").predictions
predictions = np.squeeze(predictions) if is_regression else np.argmax(predictions, axis=1)
```

ä»¥ä¸‹å¯¹è¿™ä¸ªä¾‹å­åšåˆ†æ

## Trainer.train/evaluate/predict

Trainer.train çš„æ€»ä½“é€»è¾‘:
- train å®é™…ä¸Šå°±æ˜¯ _inner_training_loop, å®Œæˆäº†æ•´ä¸ª(å¤šä¸ªepoch)çš„è®­ç»ƒè¿‡ç¨‹, çœŸæ­£å¹²æ´»çš„æ˜¯: training_step ä¸ compute_loss (å¯ä»¥é‡è½½).
- train çš„ hook çš„è°ƒç”¨ç‚¹æœ‰å‡ é¡¹: on_train_begin, on_epoch_begin, on_step_begin, on_step_end/on_substep_end, on_epoch_end, on_train_end
- trainçš„é»˜è®¤hookæœ‰å¦‚ä¸‹:

```python
# DefaultFlowCallback
# on_step_end:
# on_epoch_end:

# ProgressCallback/NotebookProgressCallback/PrinterCallback
# on_train_begin: åˆå§‹åŒ–è¿›åº¦æ¡
# on_step_end: è¿›åº¦æ¡åŠ 1
# on_train_end:
# on_log:
# on_prediction_step/on_evaluate/on_predict

# TensorBoardCallback/WandbCallback/...
# on_train_begin
# on_train_end
# on_log: åœ¨trainerä¸­stepç»“æŸåå¯èƒ½ä¼šé€šè¿‡ _maybe_log_save_evaluate åœ¨ DefaultFlowCallback.on_step_end è§¦å‘
# å…·ä½“é€»è¾‘æ˜¯é¦–å…ˆ DefaultFlowCallback åœ¨ state.global_step % args.logging_steps == 0 æ—¶å°† control.should_log è®¾å®šä¸º True, ç„¶åè°ƒç”¨ trainer._maybe_log_save_evaluate æ—¶å†…éƒ¨ä¼šè§¦å‘ trainer.log, æœ€ç»ˆå½’ç»“ä¸º trainer.callback_handler.on_log
```
  æ³¨æ„: trainer.control.on_log å…ˆå°† control.should_log = False å†è§¦å‘ callbacks çš„ hook, trainer.control å¾ˆå¤š on_xxx éƒ½æœ‰ç±»ä¼¼çš„è¡Œä¸º. æ³¨æ„: TensorBoardCallback.on_log è§¦å‘æ—¶æ˜¯ä¸æ£€æŸ¥ control.should_log çš„. æ³¨æ„: DefaultFlowCallback ä¼šä¿®æ”¹ trainer.control å’Œ trainer.state, è€Œ ProgressCallback/TensorBoardCallback ä¸ä¿®æ”¹ trainer.control å’Œ trainer.state.

- evaluate/predict å®é™…ä¸Šå°±æ˜¯ evaluation_loop, å®Œæˆäº†æ•´ä¸ªè¯„ä¼°, çœŸæ­£å¹²æ´»çš„æ˜¯: prediction_step
- evaluation_loop ä¸ prediction_loop ä¼¼ä¹æœ‰ä¸€å®šå·®åˆ«
- evaluate ä¸ predict åŸºæœ¬ä¸Šæ˜¯ä¸€æ ·çš„ (ä½†è¿”å›ç»“æœpredictä¿¡æ¯æ›´å¤š,evaluateæ›´å°‘)

æ³¨è®°:
- use_legacy_prediction_loop é»˜è®¤ä¸º False, æ­¤æ—¶ evaluate å’Œ predict éƒ½èµ°åˆ° evaluation_loop
- evaluation_loop ä¸ predict_loop çš„åŒºåˆ«: ä¸ç¡®å®š


## Trainer ä¿®æ”¹æŒ‡å—

## æ¡ˆä¾‹åˆ†æ 1: run_glue.py

## æ¡ˆä¾‹åˆ†æ 2: chatglm2
---
layout: post
title: "(P1) ChatGLM 相关介绍"
date: 2023-07-27 10:31:04 +0800
labels: [llm,chatglm]
---

## 动机、参考资料、涉及内容

动机

- chatglm2 微调
- CEval 评估

参考资料

- 模型文件: [ChatGLM2-6b](https://huggingface.co/THUDM/chatglm2-6b), [ChatGLM2-6b-int4](https://huggingface.co/THUDM/chatglm2-6b-int4)
- ChatGLM2 官方代码仓库(含微调及简易版CEval测评): [https://github.com/THUDM/ChatGLM2-6B](https://github.com/THUDM/ChatGLM2-6B)
- CEval 官方代码仓库: [https://github.com/SJTU-LIT/ceval](https://github.com/SJTU-LIT/ceval)
- CEval 数据地址: [https://huggingface.co/datasets/ceval/ceval-exam](https://huggingface.co/datasets/ceval/ceval-exam)
- CEval Leaderboard: [https://cevalbenchmark.com](https://cevalbenchmark.com)

涉及内容

- 微调

## CEval

## ChatGLM2

根据 [ChatGLM2 官方代码仓库](https://github.com/THUDM/ChatGLM2-6B) 里的代码, 发现 ChatGLM2 在 CEval 测试方法如下:

```python
record = {
    "id": 0,
    "inputs_pretokenized": "使用位填充方法，以01111110为位首flag，数据为011011111111111111110010，求问传送时要添加几个0____\nA. 1\nB. 2\nC. 3\nD. 4",
    "choices_pretokenized": [" A", " B", " C", " D"],
    "label": 2,
    "targets_pretokenized": ["C"]
}

input_text = record["inputs_pretokenized"]
model_input_text = f"[Round 1]\n\n问：{input_text}\n\n答："
intermediate_output = model.generate(tokenizer(model_input_text, ...))
intermediate_answer_text = tokenizer.decode(intermediate_output)

concat_answer_text = input_text + intermediate_answer_text + "\n" + "综上所述，ABCD中正确的选项是："
final_input_text = f"[Round 1]\n\n问：{concat_answer_text}\n\n答："
outputs = model(**tokenizer(final_input_text, ...), return_last_logits=True)

logits = outputs.logits[:, -1]  # output.logits: (B, 1, C), logits: (B, C)
pred = logits[:, choice_tokens].argmax(-1)  # (B, 4) float -> (B,) int
```

从上面可以看出, 使用 ChatGLM2 对 CEval 进行评测时需要推理两次: 严格地说第一次是生成, 第二次只需要编码(因为只需要检查生成地第一个字符)
---
layout: post
title: "(WIP) T5 è¯¦è§£"
date: 2023-03-10 14:31:04 +0800
labels: [paper]
---

<style>
h2:after {
  content: "# ";
  color: gray;
}
h3:after {
  content: "## ";
  color: gray;
}
h4:after {
  content: "### ";
  color: gray;
}
h5:after {
  content: "#### ";
  color: gray;
}
.alert-red {
    padding: 1em;
    border: 1px solid #f44336;
    background-color: #ffebee;
    color: #f44336;
    /* font-weight: bold; */
    margin-top: 1em;
    margin-bottom: 1em
}
</style>

## åŠ¨æœºã€å‚è€ƒèµ„æ–™ã€æ¶‰åŠå†…å®¹

åŠ¨æœº

- ç†Ÿæ‚‰ ğŸ¤— Transformers çš„ç›¸å…³ API ä¸æºç 
- ç†Ÿæ‚‰ ğŸ¤— Tokenizers çš„ç›¸å…³ API ä¸æºç 
- æ·±å…¥ç†è§£ T5 çš„è®­ç»ƒä¸æ¨ç†æ­¥éª¤ï¼ŒåŒ…æ‹¬æ¯ä¸€æ­¥çš„è®¡ç®—è¿‡ç¨‹
- é€‚å½“è¡¥å……ç›¸å…³çŸ¥è¯†

å‚è€ƒèµ„æ–™

- ğŸ¤— Transformers 4.26.1 æºä»£ç 
- ğŸ¤— Transformers å®˜æ–¹æ–‡æ¡£
- T5åŸå§‹è®ºæ–‡
  - è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/pdf/1910.10683.pdf
  - æ ‡é¢˜ï¼šExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
  - æœºæ„ï¼šGoogle

æ³¨æ„äº‹é¡¹

ä¸»è¦ä»ä¸¤ä¸ªè§†è§’æ¥å†™è¿™ç¯‡åšå®¢ï¼š

- åŸç†è§†è§’ï¼šä¸»è¦æ˜¯è®ºæ–‡é‡Œæè¿°ä¸ºä¸»ï¼Œä½†ç¼ºç‚¹æ˜¯æŸäº›åœ°æ–¹å¯èƒ½ä¼šæœ‰ä¸€å®šçš„æ¨¡ç³Š
- å®ç°è§†è§’ï¼šä»¥ ğŸ¤— Transformers çš„å®é™…å®ç°ä¸ºå‡†

## Overview: T5

T5 æ¨¡å‹å°è¯•å°†æ‰€æœ‰çš„ NLP ä»»åŠ¡åšäº†ä¸€ä¸ªç»Ÿä¸€å¤„ç†ï¼Œå³ï¼šå°†æ‰€æœ‰çš„ NLP ä»»åŠ¡éƒ½è½¬åŒ–ä¸º Text-to-Text ä»»åŠ¡ã€‚å¦‚åŸè®ºæ–‡ä¸‹å›¾æ‰€ç¤ºï¼š
![](../assets/figures/t5/text-to-text.png)

ç»¿è‰²çš„æ¡†æ˜¯ä¸€ä¸ªç¿»è¯‘ä»»åŠ¡ï¼ˆè‹±æ–‡ç¿»è¯‘ä¸ºå¾·æ–‡ï¼‰ï¼ŒæŒ‰ç…§ä»¥å¾€æ ‡å‡†çš„ç¿»è¯‘æ¨¡å‹çš„åšæ³•ï¼Œæ¨¡å‹çš„è¾“å…¥ä¸ºï¼š`That is good.`ï¼ŒæœŸæœ›æ¨¡å‹çš„è¾“å‡ºä¸ºï¼š`Das ist gut.`ï¼Œè€Œ T5 çš„åšæ³•æ˜¯å°†è¾“å…¥è½¬åŒ–ä¸ºï¼š`translate English to German: That is good.`ï¼ŒæœŸæœ›çš„è¾“å‡ºä¾ç„¶ç»´æŒåŸæ ·ã€‚ä¹Ÿå°±æ˜¯å°† NLP ä»»åŠ¡çš„æè¿°ä¹ŸåŠ åœ¨äº†æ¨¡å‹è¾“å…¥é‡Œã€‚åŸæ–‡ä¸­é™„å½• D ä¸­ç»™å‡ºäº†æ›´å¤šçš„ä¾‹å­ã€‚

åœ¨æ¨¡å‹ç»“æ„ä¸Šï¼ŒT5 æ¨¡å‹é‡‡ç”¨äº† Encoder-Decoder çš„æ¶æ„ï¼Œä»å¤§ä½“ä¸Šè¯´ï¼Œå¯¹äºè®­ç»ƒè¿‡ç¨‹ï¼Œä¼ªä»£ç å¦‚ä¸‹ï¼š

```python
x, y = "translate English to German: That is good.", "Das ist gut."
x = tokenizer(x)  # [0, 23, 45, 89, 1230, 4, 9], å…¶ä¸­0ä»£è¡¨<BOS>, åœ¨å®ç°ä¸­<PAD>ä¹Ÿæ˜¯0
y = tokenizer(y)  # [0, 44, 156, 4, 1], å…¶ä¸­1ä»£è¡¨<EOS>
x_embedding = encoder.embed_layer(x)  # å°†tokenè½¬æ¢ä¸ºembedding, x_embeddingçš„å½¢çŠ¶ä¸º(7, 768)
encoded_x = encoder.other_layer(x_embedding)  # ç»è¿‡encoderåencoded_xçš„å½¢çŠ¶ä¸º(7, 768)

input_y = y[:-1]  # [0,  44,  156, 4]
# å°†tokenè½¬åŒ–ä¸ºemdedding, input_y_emdeddingçš„å½¢çŠ¶ä¸º(4, 768)
input_y_emdedding = decoder.embed_layer(input_y)  # åœ¨T5çš„è®¾è®¡ä¸­ï¼Œencoder.embed_layerä¸decoder.embed_layerå…±äº«å‚æ•°
target_y = y[1:]  # [44, 156, 4,   1]

# decoder_outputçš„å½¢çŠ¶ä¸º(4, 768)
decoder_output = decoder.other_layer(encoded_x, input_y_emdedding)

# logits çš„å½¢çŠ¶ä¸º(4, vocab_size=32128)
logits = linear_layer(decoder_output)  # åœ¨T5çš„è®¾è®¡ä¸­ï¼Œdecoder.embed_layerä¸linear_layerå…±äº«å‚æ•°

# æ¥ä¸‹æ¥ä½¿ç”¨ softmax ä¸æ™®é€šçš„äº¤å‰ç†µè®¡ç®—æŸå¤±
loss = loss_fn(logits, target_y)
```


## Overview: ğŸ¤— Transformers
å¯¹äº ğŸ¤— Transformers çš„æºç é˜…è¯»è€Œè¨€ï¼Œæœ¬æ–‡ä¸»è¦çš„å…³æ³¨ç‚¹åœ¨äºä»¥ä¸‹éƒ¨åˆ†ï¼Œé¦–å…ˆ ğŸ¤— Transformers github é¡¹ç›®çš„ç›®å½•ç»“æ„å¦‚ä¸‹ï¼ˆèŠ‚é€‰ï¼‰

```
examples                         # ä¸€äº›ç¤ºä¾‹ä»£ç , å¯ä¾›å­¦ä¹ , ä½†ä¸ç¡®ä¿èƒ½ä¸å½“å‰ç‰ˆæœ¬å…¼å®¹
  - flax/language-modeling/t5_tokenizer_model.py  # t5 tokenizer è®­ç»ƒå‚è€ƒ
  - flax/language-modeling/run_t5_mlm_flax.py     # t5 mask-LM é¢„è®­ç»ƒå‚è€ƒ
  - pytorch/summarization                         # t5 ç”Ÿæˆå¼æ¨¡å‹è®­ç»ƒå‚è€ƒ
src/transformers
  - generation/
    - beam_constraints.py        # constraint_beam_search è¾…åŠ©æ–¹æ³•/ç±»: Constraint, ConstraintListState
    - beam_search.py             # beam_search è¾…åŠ©æ–¹æ³•/ç±»: BeamSearchScorer, ConstrainedBeamSearchScorer, BeamHypotheses
    - configuration_utils.py     # ç”Ÿæˆå¼æ¨¡å‹çš„ç»Ÿä¸€é…ç½®æ–‡ä»¶, ç”¨æ¥æ§åˆ¶ç”Ÿæˆç®—æ³•åŠå„ç±»è¶…å‚æ•°, ä¾‹å¦‚ç”Ÿæˆé•¿åº¦æƒ©ç½š
    - logit_process.py           # ç”Ÿæˆè¿‡ç¨‹æ—¶å¯¹log-softmax scoreçš„åå¤„ç†ï¼šLogitsProcessor, LogitsWarpper
    - stopping_criteria.py       # ç”Ÿæˆä¸­æ­¢æ¡ä»¶ï¼šStoppingCriteria
    - streamer.py                # transformers 4.28.0 ç‰ˆæœ¬æ–°å¢, ç”¨äºç”Ÿæˆå­—ç¬¦æ—¶æµå¼é€è¯è¾“å‡º
    - utils.py                   # GenerationMixin çš„å®ç°
    ...
  - models/  # æ¯ä¸ªæ¨¡å‹ä¸ºä¸€ä¸ªå•ç‹¬çš„æ–‡ä»¶å¤¹, æ¯ä¸ªæ–‡ä»¶å¤¹çš„æ–‡ä»¶ç»“æ„æ¯”è¾ƒå›ºå®š, å‚è€ƒt5å­æ–‡ä»¶å¤¹
    - t5/
      - __init__.py
      - convert_t5_original_tf_checkpoint_to_pytorch.py  # æœ‰äº›æ¨¡å‹åŸå§‹å®˜æ–¹ä»“åº“çš„æƒé‡éœ€è¦é€šè¿‡è½¬æ¢å¾—åˆ° ğŸ¤— Transformers ä¸­æ¨¡å‹å®šä¹‰ä¸‹æ¨¡å‹è½½å…¥çš„æ ¼å¼, è¿™ç§æƒ…å†µä¸‹ä¼šç»´æŠ¤ä¸€ä¸ªè½¬æ¢è„šæœ¬
      - modeling_flax_t5.py      # flaxç‰ˆæœ¬çš„æ¨¡å‹ç»“æ„ä»£ç , æœ¬æ–‡ä¸æ¶‰åŠ
      - modeling_tf_t5.py        # tensorflowç‰ˆæœ¬çš„æ¨¡å‹ç»“æ„ä»£ç , æœ¬æ–‡ä¸æ¶‰åŠ
      - modeling_t5.py           # pytorchç‰ˆæœ¬çš„æ¨¡å‹ç»“æ„ä»£ç 
      - configuration_t5.py      # æ¯ä¸ªæ¨¡å‹éƒ½æœ‰ä¸€ä¸ªè‡ªå·±çš„æ¨¡å‹ç»“æ„å‚æ•°é…ç½®æ–‡ä»¶
      - tokenization_t5.py       # æ¯ä¸ªæ¨¡å‹çš„slow/pythonç‰ˆæœ¬çš„tokenizerå®ç°, é€Ÿåº¦ç›¸å¯¹è¾ƒæ…¢
      - tokenization_t5_fast.py  # æ¯ä¸ªæ¨¡å‹çš„fastç‰ˆæœ¬çš„tokenizerå®ç°, é€Ÿåº¦è¾ƒå¿«, ä¾èµ–äº ğŸ¤— Tokenizers
      - ...
    - ...
  - pipelines/                   # å°è£…tokenizerä¸model, ç®€åŒ–ä½¿ç”¨, æœ¬æ–‡ä¸æ¶‰åŠ
  - modeling_outputs.py          # æ¨¡å‹è¾“å‡ºç»“æœçš„æ•°æ®ç»“æ„
  - modeling_utils.py            # æ‰€æœ‰æ¨¡å‹çš„åŸºç±»: PreTrainedModel
  - tokenization_utils_base.py   # æ‰€æœ‰tokenizerçš„åŸºç±»: PreTrainedTokenizerBase
  - tokenization_utils.py        # æ‰€æœ‰slowç‰ˆæœ¬tokenizerçš„åŸºç±»: PreTrainedTokenizer
  - tokenization_utils_fast.py   # æ‰€æœ‰fastç‰ˆæœ¬tokenizerçš„åŸºç±»: PreTrainedTokenizerFast
  - trainer.py                   # Trainerç±», æœ¬æ–‡ä¸æ¶‰åŠ
  - trainer_callback.py          # Trainerç±»ä¸­ä½¿ç”¨åˆ°çš„ TrainerCallback/TrainerState/TrainerControl/CallbackHandler
  - integrations.py              # é«˜çº§æ—¥å¿—è®°å½•å·¥å…·, ä¾‹å¦‚: TensorBoardCallback
  - ...
```

## åŸç†è§£æï¼šT5 è®­ç»ƒè¿‡ç¨‹çš„å‰å‘è®¡ç®—æµç¨‹

### encoder

é¦–å…ˆç»™å‡ºæ€»ä½“çš„ç»“æ„å›¾

![](../assets/figures/t5/T5_encoder.png)

T5 æ¨¡å‹çš„ Encoder éƒ¨åˆ†ç”±è‹¥å¹²ä¸ª Block æ„æˆï¼Œæ¯ä¸ª Block éƒ½å…·æœ‰ç›¸åŒçš„ç»“æ„ï¼šä¸€ä¸ª Self-Attention Layer å’Œä¸€ä¸ª Feed-Forward Layerã€‚è¿™é‡Œä¹Ÿé¦–å…ˆç»™å‡ºä¼ªä»£ç ï¼š

```python
class Encoder:
    def forward(self, x_token, x_attention_mask):
        # x_token: (B, L=512), long
        # x_attention: (B, L), 0/1 mask
        x_embedding = embedding_layer(x_token)
        hidden = dropout(x_embedding)  # (B, L, C=768)
        
        positional_bias = None
        for block in blocks:
            hidden_1 = block.layernorm_layer(hidden)  # LayerNormå±‚, hidden_1: (B, L, C)
            # Self-Attentionå±‚, attention_hidden: (B, L, C), postional_bias: (1, n_heads, L, L)
            # postional_biasåœ¨ç¬¬ä¸€å±‚è¢«äº§ç”Ÿ, åé¢æ¯ä¸€å±‚éƒ½ä½¿ç”¨å®ƒ(å…±äº«å‚æ•°)
            attention_hidden, positional_bias = block.attention_layer(hidden_1, x_attention_mask, positional_bias)
            hidden = block.dropout(attention_hidden) + hidden  # æ®‹å·®è¿æ¥: hidden: (B, L, C)
            
            hidden = block.ff_layer(hidden)  # Feed-Forwardå±‚: hidden (B, L, C)
        
        hidden = layernorm_layer(hidden)  # hidden (B, L, C)
        hidden = dropout(hidden)  # hidden (B, L, C)
        return hidden
```

å¤‡æ³¨ï¼šåœ¨ ğŸ¤— Transformers çš„å®ç°ä¸­ï¼Œå°†æ­¤å¤„çš„ `block.layernorm_layer`, `block.attention_layer`ã€`block.dropout` çš„è®¡ç®—é€»è¾‘åŒ…è£…åœ¨äº†ä¸€èµ·ï¼Œç§°ä¸º `T5LayerSelfAttention`ã€‚è€Œæ­¤å¤„çš„ `block.ff_layer` ä¸º `T5LayerFF`ã€‚

#### LayerNorm Layer (Encoder)

```python
class LayerNorm(torch.nn.Module):
    def __init__(self, hidden_size, eps=1e-6):
        super().__init__()
        self.weight = nn.Parameter(torch.ones(hidden_size))
        self.variance_epsilon = eps

    def forward(self, hidden_states):
        # T5ç”¨çš„æ˜¯ç®€åŒ–ç‰ˆçš„layernormå¯¹æœ€åä¸€ç»´l2å½’ä¸€åŒ–åå†æ¯ä¸€ç»´ä¹˜ä¸Šä¸€ä¸ªæƒé‡, ä¸å¸¦åç½®é¡¹
        # hidden_states: (B, L, C)
        # return: (B, L, C)
        variance = hidden_states.to(torch.float32).pow(2).mean(-1, keepdim=True)
        hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)
        return self.weight * hidden_states
```

#### Self-Attention Layer (Encoder)

**relative positional embedding**

æ€»å…±çš„ postional embedding æ•°ç›®ä¸º (num_bucket, n_head), T5 çš„ postional embedding çš„ index çš„å–å€¼èŒƒå›´ä¸º [0, num_bucket)

åŒå‘ mask çš„æƒ…å†µä¸‹, $n=num\_bucket, m=max\_distance$

$$
\begin{equation*}
index(i, j) = \frac{n}{2} * \mathbb{1}[i-j<0] + \left\{
\begin{aligned}
    &abs(i - j), &abs(i - j) < \frac{n}{4} \\
&\min(\frac{n}{2}-1, \frac{n}{4}\times(1+\frac{log(4\times abs(i - j)/n)}{log(4\times m/n)})), &abs(i - j) \ge \frac{n}{4}

\end{aligned}
\right.
\end{equation*}
$$

```python
def relative_position_bidirectional(i, j, num_buckets=32, max_distance=128):
    position = i - j
    abs_position = abs(position)
    num_buckets = num_buckets // 2
    max_exact = num_buckets // 2
    offset = num_buckets if position < 0 else 0
    if abs_position < max_exact:
        return abs_position + offset
    else:
        ratio = math.log(abs_position/ max_exact) / math.log(max_distance / max_exact)
        return min(int(max_exact*(1+ratio)), num_buckets - 1) + offset
```

casual mask çš„æƒ…å†µä¸‹,

$$
\begin{equation*}
index(i, j) = 
\left\{
\begin{aligned}

&0, &i \ge j \\
&abs(i - j), &i < j\ and\ abs(i - j) < \frac{n}{2} \\
&\min(n-1, \frac{n}{2}\times(1+\frac{log(2\times abs(i - j)/n)}{log(2\times m/n)})), &i < j\ and\ abs(i - j) \ge \frac{n}{2}

\end{aligned}
\right.
\end{equation*}
$$

```python
def relative_position_onedirectional(i, j, num_buckets=32, max_distance=128):
    position = i - j
    if position <= 0:
        return 0
    elif position < (num_buckets // 2):
        return position
    else:
        ratio = math.log(2 * position / num_buckets) / math.log(2 * max_distance / num_buckets)
        return min(int(num_buckets // 2 * (1 + ratio)), num_buckets - 1)
```

åœ¨ T5 æ¨¡å‹çš„å®éªŒè®¾ç½®ä¸­:

```python
num_bucket, max_distance = 32, 128
```

åœ¨ encoder ä¸ decoder çš„ç¬¬ä¸€å±‚åŠ ä¸Šäº† positional bias:

```python
bias = nn.Embedding(num_buckect, n_heads)
positional_idx = ...  # å³ä¸Šé¢çš„å…¬å¼, (L, L)
scores = q @ k.T  # (B, L, L, n_heads)
positional_bias = bias(positional_idx)  # (L, L, n_heads)
scores += positional_bias
# weights = softmax(scores)
```

**self-attention**

```python
class EncoderSelfAttention(torch.nn.Module):
    def __init__(self, d_model=768, d_qkv=64, n_heads=12,
        relative_attention_num_buckets=32, has_relative_bias=False, dropout_rate=0.1):
        """
        relative_attention_num_buckets: è§åé¢å…³äºpositional biasçš„è¯´æ˜
        has_relative_bias: ç¬¬1ä¸ªEncoderBlockå–å€¼ä¸ºTrue, å…¶ä½™å‡ä¸ºFalse
        """
        super().__init__()
        self.inner_dim = d_qkv * n_heads
        self.q, self.k, self.v = [nn.Linear(d_model, self.inner_dim) for i in range(3)]
        self.o = nn.Linear(self.inner_dim, d_model)
        self.dropout_rate = dropout_rate
        if has_relative_bias:
            self.relative_attention_bias = nn.Embedding(self.relative_attention_num_buckets, self.n_heads)

    def compute_bias(self, q_len=512, k_len=512):
        # q_lenå’Œk_lenéƒ½æ˜¯encoderè¾“å…¥çš„åºåˆ—é•¿åº¦
        # åœ¨decoderçš„self-attentionçš„è®­ç»ƒé˜¶æ®µ, q_lenå’Œk_lenéƒ½æ˜¯decoderçš„è¾“å…¥é•¿åº¦
        
        # positions: (q_len, k_len) long tensor
        # æ¯ä¸ªå…ƒç´ çš„å–å€¼èŒƒå›´éƒ½æ˜¯[0, self.relative_attention_num_buckets=32)
        positions = get_relative_idx(q_len, k_len)
        
        bias = self.relative_attention_bias(positions).unsqueeze(0)  # (1, q_len, k_len, n_heads)
        bias = bias.transpose(0, 3, 1, 2)
        # bias: (1, n_heads, q_len, k_len), å…¶ä¸­ç¬¬0ç»´åœ¨è®¡ç®—ä¸­è¢«å¹¿æ’­, å³(B, n_heads, q_len, k_len)
        return bias
    
    def forward(self, hidden, attention_mask, bias=None):
        """
        Args:
            hidden: (B, L, d_model)
            attention_mask: (B, L) LongTensor, æœ‰tokençš„åœ°æ–¹ä¸º1, padå¤„ä¸º0
            bias: ç¬¬1å±‚è¾“å…¥ä¸ºNone, åç»­å±‚å°†ç¬¬ä¸€å±‚è¾“å‡ºçš„biasä½œä¸ºè¾“å…¥
        """
        # q, k, v: (B, L, self.inner_dim)
        q, k, v = self.q(hidden), self.k(hidden), self.v(hidden)
        q = q.reshape(B, L, n_heads, d_qkv).transpose(1, 2)  # (B, n_heads, L=q_len, d_qkv)
        k = k.reshape(B, L, n_heads, d_qkv).transpose(1, 2)  # (B, n_heads, L=k_len, d_qkv)
        v = v.reshape(B, L, n_heads, d_qkv).transpose(1, 2)  # (B, n_heads, L=k_len, d_qkv)
        
        scores = torch.matmul(q, k.transpose(2, 3))  # (B, n_head, L, L)
        if bias is None:
            bias = self.compute_bias(L, L)  # (1, n_head, L, L)
            extended_mask = torch.where(attention_mask[:, None, None, :]==1, 0, -inf)  # (B, 1, 1, L)
            bias = bias + extended_mask  # (B, n_head, L, L)
        scores += bias
        attn_weights = nn.functional.softmax(scores, dim=-1)
        attn_weights = nn.functional.dropout(attn_weights, self.dropout_rate)
        hidden = torch.matmul(atten_weights, v)  # (B, n_heads, L, d_qkv)
        hidden = hidden.transpose(1, 2).view(B, L, self.inner_dim)  # (B, L, inner_dim)
        hidden = self.o(hidden)  # (B, L, d_model)
        return hidden, bias
```


#### Feed-Forward

è§ä¸‹å›¾ï¼Œå«ä¹‰è‡ªæ˜

![](../assets/figures/t5/feed-forward.png)



### decoder

é¦–å…ˆç»™å‡ºæ€»ä½“çš„ç»“æ„å›¾

![](../assets/figures/t5/T5_decoder_training.png)

#### Self-Attention Layer (Decoder)

ä¸ `Self-Attention Layer(Encoder)` çš„è®¡ç®—è¿‡ç¨‹ä¸€è‡´, ä½†æœ‰å¦‚ä¸‹ä¸¤ä¸ªåŒºåˆ«ï¼š

- positional bias ä½¿ç”¨å•å‘çš„æ–¹å¼è¿›è¡Œè·å–

- `mask` æœ‰äº›å˜åŒ–:

  ```python
  bias = self.compute_bias(L, L)  # (1, n_head, L=trg_len, L=trg_len)
  mask = torch.triu(torch.ones((B, 1, L, L)))  # (B, 1, L, L), ä¸‹ä¸‰è§’å«å¯¹è§’çº¿ä¸º1, å…¶ä½™å‡ä¸º0
  extended_mask = torch.where(mask==1, 0, -inf)  # ä¸‹ä¸‰è§’å«å¯¹è§’çº¿ä¸º0, å…¶ä½™å‡ä¸º-inf
  bias = bias + extended_mask  # (B, n_head, L, L)
  ```

#### Cross-Attention Layer (Decoder)

```python
class DecoderCrossAttention(torch.nn.Module):
    def __init__(self, d_model=768, d_qkv=64, n_heads=12, dropout_rate=0.1):
        # æ²¡æœ‰postion biasçš„è®¡ç®—
        super().__init__()
        self.inner_dim = d_qkv * n_heads
        self.q, self.k, self.v = [nn.Linear(d_model, self.inner_dim) for i in range(3)]
        self.o = nn.Linear(self.inner_dim, d_model)
        self.dropout_rate = dropout_rate
    
    def forward(self, decoder_hidden, encoder_hidden, encoder_attention_mask):
        """
        Args:
            decoder_hidden: (B, trg_len, d_model)
            encoder_hidden: (B, src_len, d_model)
            encoder_attention_mask: (B, L) LongTensor, è¾“å…¥åºåˆ—æœ‰tokençš„åœ°æ–¹ä¸º1, padå¤„ä¸º0
        """
        q, k, v = self.q(decoder_hidden), self.k(encoder_hidden), self.v(encoder_hidden)
        q = q.reshape(B, trg_len, n_heads, d_qkv).transpose(1, 2)  # (B, n_heads, q_len=trg_len, d_qkv)
        k = k.reshape(B, src_len, n_heads, d_qkv).transpose(1, 2)  # (B, n_heads, k_len=src_len, d_qkv)
        v = v.reshape(B, src_len, n_heads, d_qkv).transpose(1, 2)  # (B, n_heads, k_len=src_len, d_qkv)
        
        scores = torch.matmul(q, k.transpose(2, 3))  # (B, n_heads, trg_len, src_len)
        
        bias = torch.zeros(B, n_heads, trg_len, src_len)  # (1, n_heads, trg_len, src_len)
        extended_mask = torch.where(attention_mask[:, None, None, :]==1, 0, -inf)  # (B, 1, 1, src_len)
        bias = bias + extended_mask  # (B, n_heads, trg_len, src_len)
        scores += bias

        attn_weights = nn.functional.softmax(scores, dim=-1)
        attn_weights = nn.functional.dropout(attn_weights, self.dropout_rate)
        hidden = torch.matmul(atten_weights, v)  # (B, n_heads, trg_len, d_qkv) = (B, n_heads, trg_len, src_len) * (B, n_heads, src_len, d_qkv)
        hidden = hidden.transpose(1, 2).view(B, trg_len, self.inner_dim)  # (B, trg_len, inner_dim)
        hidden = self.o(hidden)  # (B, trg_len, d_model)
        return hidden, bias
```

## æºç è§£æï¼šğŸ¤— Transformers ä¸­ T5 è®­ç»ƒè¿‡ç¨‹çš„å‰å‘è®¡ç®—æµç¨‹

å¦‚æœå¯¹T5çš„è®¡ç®—é€»è¾‘åŸºæœ¬ç†Ÿæ‚‰çš„è¯ï¼Œè¿™é‡Œç»™å‡º ğŸ¤— Transformers ä¸­çš„æ¨¡å‹å±‚æ¬¡ï¼Œå¯ä»¥å¸®åŠ©å¿«é€Ÿç†è§£æºç çš„å®ç°é€»è¾‘ï¼š

```yaml
# æ³¨æ„: T5Attention è¿™ä¸ªç±»åŒæ—¶å®ç°äº†ä¸‰ç±»æ³¨æ„åŠ›æœºåˆ¶
T5ForConditionalGeneration:
  - nn.Embedding  # A
  - encoder: T5Stack
    - nn.Embedding  # ä¸ A æ˜¯åŒä¸€ä¸ª
    - T5Block 
      - T5LayerSelfAttention
        - T5LayerNorm
        - T5Attention  # å…¨è‡ªæ³¨æ„åŠ›, ä½äºç¬¬ä¸€ä¸ªT5Blockä¸­æ­¤æ¨¡å—å«æœ‰ä¸€ä¸ªnn.Embeddingç”¨äºå­¦ä¹ relative postional bias, å¯å­¦ä¹ å‚æ•°å½¢çŠ¶:(num_bucket=32, num_heads=64)
        - nn.Dropout
      - T5LayerFF
    - T5Block
    ...
    - T5Block
    - T5LayerNorm
    - nn.Dropout
  - decoder: T5Stack
    - nn.Embedding  # ä¸ A æ˜¯åŒä¸€ä¸ª
    - T5Block
      - T5LayerSelfAttention
        - T5LayerNorm
        - T5Attention  # å› æœè‡ªæ³¨æ„åŠ›, ä½äºç¬¬ä¸€ä¸ªT5Blockä¸­æ­¤æ¨¡å—å«æœ‰ä¸€ä¸ªnn.Embeddingç”¨äºå­¦ä¹ relative postional bias, å¯å­¦ä¹ å‚æ•°å½¢çŠ¶:(num_bucket=32, num_heads=64)
        - nn.Dropout
      - T5LayerCrossAttention
        - T5LayerNorm
        - T5Attention  # ä¸encoderçš„è¾“å‡ºåšæ³¨æ„åŠ›, æ²¡æœ‰relative postional bias
        - nn.Dropout
      - T5LayerFF
    - T5Block
    ...
    - T5Block
    - T5LayerNorm
    - nn.Dropout
  - nn.Linear  # T5ä¸­çš„è®¾è®¡é‡Œä¸ A å…±äº«å‚æ•°
```

å¤‡æ³¨ï¼šåœ¨ ğŸ¤— Transformers çš„æºç å®ç°é‡Œ `T5Attention` æ¯”è¾ƒå¤æ‚ï¼Œå®ƒéœ€è¦æ‰¿æ‹…å‡ é¡¹ä¸åŒçš„å·¥ä½œï¼š

- è®­ç»ƒé˜¶æ®µï¼š
  - åœ¨ encoder ä¸­æ‰§è¡Œå…¨è‡ªæ³¨æ„åŠ›æœºåˆ¶
  - åœ¨ decoder ä¸­çš„ `T5LayerSelfAttention` ä¸­æ‰§è¡Œå› æœè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆè®­ç»ƒæ—¶å› ä¸ºå¯ä»¥å¹¶è¡Œè®¡ç®—æ•´ä¸ªdecoderåºåˆ—çš„å„ä¸ªéšå±‚å‘é‡ï¼Œä¸éœ€è¦è€ƒè™‘decoderå‰åºtokençš„keyå’Œvalueçš„ç¼“å­˜ï¼‰
  - åœ¨ decoder ä¸­çš„ `T5LayerCrossAttention` ä¸­æ‰§è¡Œå¯¹encoderè¾“å‡ºçš„æ³¨æ„åŠ›æœºåˆ¶ï¼ˆè®­ç»ƒæ—¶å› ä¸ºå¯ä»¥å¹¶è¡Œè®¡ç®—æ•´ä¸ªdecoderåºåˆ—çš„å„ä¸ªéšå±‚å‘é‡ï¼Œä¸éœ€è¦è€ƒè™‘encoderæœ€åä¸€å±‚çš„keyå’Œvalueçš„ç¼“å­˜ï¼‰
- æ¨ç†é˜¶æ®µï¼š
  - åœ¨ encoder ä¸­æ‰§è¡Œå…¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´
  - åœ¨ decoder ä¸­çš„ `T5LayerSelfAttention` ä¸­æ‰§è¡Œå› æœè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆæ¨ç†æ—¶æ˜¯ä¸²è¡Œè§£ç ï¼Œå› æ­¤éœ€è¦ç¼“å­˜decoderçš„ä¹‹å‰æ‰€æœ‰tokençš„keyå’Œvalueçš„ç¼“å­˜ï¼Œè®¡ç®—å½“å‰tokençš„éšå±‚å‘é‡æ—¶ä¹ŸæŠŠå½“å‰tokençš„keyå’Œvalueä¹Ÿç¼“å­˜ä¸‹æ¥ä¾›åç»­è®¡ç®—ï¼‰
  -  åœ¨ decoder ä¸­çš„ `T5LayerCrossAttention` ä¸­æ‰§è¡Œå¯¹encoderè¾“å‡ºçš„æ³¨æ„åŠ›æœºåˆ¶ï¼ˆæ¨ç†æ—¶æ˜¯ä¸²è¡Œè§£ç ï¼Œå› æ­¤è§£ç ç¬¬ä¸€ä¸ªå­—ç¬¦æ—¶ä¼šç¼“å­˜æ¯ä¸€å±‚é’ˆå¯¹encoderè¾“å‡ºå‘é‡çš„keyå’Œvalueï¼Œè§£ç åç»­å­—ç¬¦æ—¶ç›´æ¥ä½¿ç”¨è¿™äº›keyå’Œvalueç¼“å­˜è¿›è¡Œè®¡ç®—ï¼‰

ä¸‹é¢å°†ä¸å†æŒ‰ç…§ ğŸ¤— Transformers çš„æºç è¿›è¡Œæ¢³ç†ï¼Œè€Œæ˜¯ç›´æ¥æ‰‹å†™å¤§éƒ¨åˆ†å±‚çš„å®ç°æ¥è®²è§£ï¼Œæ‰‹å†™å®ç°ä¸ ğŸ¤— Transformers å®ç°çš„å¯¹åº”ä¹Ÿåœ¨å„å°èŠ‚ç»™å‡ºã€‚æ›´ä¸ºå®Œæ•´çš„å¯¹åº”å…³ç³»å¯ä»¥å‚è€ƒï¼š[../assets/code/t5](../assets/code/t5)

## æºç è§£æï¼šğŸ¤— Transformers PretrainedModelã€TODOã€‘

repeat yourself çš„å…¸å‹ä¾‹å­ï¼št5 ä¸ mt5 ä»£ç å®Œå…¨ç›¸åŒ

`PretrainedModel` ç±»æœ‰ 4 ä¸ªåŸºç±»ï¼š
- `nn.Module`: pytorch æ¨¡å‹åŸºç±»
- `ModuleUtilsMixin`: è§ä¸‹é¢æè¿°
- `GenerationMixin`: ä¸æ–‡æœ¬ç”Ÿæˆç›¸å…³çš„æ–¹æ³•, è§åæ–‡æè¿°
- `PushToHubMixin`: å¯¹å¤–æ–¹æ³•ä»…æœ‰ä¸€ä¸ª `push_to_hub`, ä½œç”¨æ˜¯å°†æ¨¡å‹æ¨é€è‡³ ğŸ¤— Hub ä»“åº“, æ­¤å¤„ä¸èµ˜è¿°

### `ModuleUtilsMixin` çš„æ–¹æ³•ç©·ä¸¾

#### memory hook

ç›¸å…³æ–¹æ³•å¦‚ä¸‹ï¼š

- `add_memory_hooks`: ä¸º `self.modules()` å¢åŠ å†…å­˜å¢åŠ ç›‘æ§çš„ hookï¼Œä½¿ç”¨åˆ°äº†ä»¥ä¸‹çš„ä¸‰ä¸ªæ–¹æ³•
- `_hook_rss_memory_pre_forward`
- `_hook_rss_memory_post_forward`
- `reset_memory_hooks_state`

#### mask ç›¸å…³ã€å¾…è¡¥å……ã€‘

- `invert_attention_mask`
- `create_extended_attention_mask_for_decoder`
- `get_extended_attention_mask`
- `get_head_mask`
- `_convert_head_mask_to_5d`

#### deviceã€dtypeã€num_parametersã€estimate_tokensã€floating_point_ops

- `device`: æ³¨æ„ `nn.Module` æ²¡æœ‰è¿™ä¸ªå±æ€§, è¿™é‡Œç”¨ `self` é‡Œçš„ tensor æ¥è·å– device ä¿¡æ¯ (å‡è®¾æ‰€æœ‰çš„ tensor éƒ½åœ¨åŒä¸€ä¸ª device ä¸Š)
- `dtype`: ä¸ `device` åŸç†ç›¸åŒ
- `num_parameters(only_trainable=False, exclude_embeddings=False)`: ç»Ÿè®¡æ¨¡å‹çš„å‚æ•°é‡
- `estimate_tokens(input_dict: Dict[str, torch.Tensor])`: è¾…åŠ©å‡½æ•°, å¤§å¤šæ•°æ—¶å€™ç”¨äºç»Ÿè®¡ `input_ids` çš„å…ƒç´ ä¸ªæ•°
- `floating_point_ops(input_dict, exclude_embeddings=True)`: å‚è€ƒ[è®ºæ–‡](https://arxiv.org/pdf/2001.08361.pdf), ç»™å‡ºæ¨¡å‹è®¡ç®—çš„æµ®ç‚¹æ•°è¿ç®—æ¬¡æ•°, ä¼°è®¡å€¼ä¸º:
  ```
  6 * self.estimate_tokens(input_dict) * self.num_parameters(exclude_embeddings=exclude_embeddings)
  ```

### `PretrainedModel` çš„æ–¹æ³•ä¸ç±»å±æ€§ç©·ä¸¾ã€å¾…è¡¥å……ã€‘

#### å±æ€§

```python
class PretrainedModel:
  config_class = None
  base_model_prefix = ""
  main_input_name = "input_ids"
  _auto_class = None
  _no_split_modules = None
  _keep_in_fp32_modules = None

  # a list of `re` patterns of `state_dict` keys that should be removed from the list of missing
  # keys we find (keys inside the model but not in the checkpoint) and avoid unnecessary warnings.
  _keys_to_ignore_on_load_missing = None
  # a list of `re` patterns of `state_dict` keys that should be removed from the list of
  # unexpected keys we find (keys inside the checkpoint but not the model) and avoid unnecessary
  # warnings.
  _keys_to_ignore_on_load_unexpected = None
  # a list of `state_dict` keys to ignore when saving the model (useful for keys that aren't
  # trained, but which are either deterministic or tied variables)
  _keys_to_ignore_on_save = None

  is_parallelizable = False
  supports_gradient_checkpointing = False
```

#### å®ä¾‹åŒ–ç›¸å…³

ç‰µæ¶‰åˆ°å¦‚ä¸‹æ–¹æ³•

- `from_pretrained`: æœ€ä¸ºé‡è¦çš„æ–¹æ³•
  - `__init__`
  - `_load_pretrained_model`
  - `_load_pretrained_model_low_mem`

- `post_init`
  - `init_weights`
    - `prune_heads`: éœ€è¦å®ç°`self.base_model._prune_heads`
    - `_init_weights`: ç”±å­ç±»é‡è½½
    - `tie_weights`:
      - `_tie_encoder_decoder_weights`
      - `_tie_or_clone_weights`
      - è°ƒç”¨ `self.modules()` å®ç°çš„ `_tie_weights`ï¼ˆå¦‚æœæœ‰å®ç°çš„è¯ï¼‰
  - `_backward_compatibility_gradient_checkpointing`

- `_from_config`: classmethod


#### resize token

ç‰µæ¶‰åˆ°çš„æ–¹æ³•å¦‚ä¸‹

- `resize_token_embeddings`
  - `_resize_token_embeddings`
- `_get_resized_embeddings`
- `_get_resized_lm_head`
- `resize_position_embeddings`: éœ€è¦å­ç±»å®ç°ã€æ˜¯å¦å¿…é¡»ã€‘
- `get_position_embeddings`: éœ€è¦å­ç±»å®ç°ã€æ˜¯å¦å¿…é¡»ã€‘


#### save_pretrained

- `save_pretrained`

#### è·å–ä¿¡æ¯

- `dummy_inputs`:
- `framework`:
- `can_generate`:
- `base_model`: `return getattr(self, self.base_model_prefix, self)`
  - `get_input_embeddings`: é»˜è®¤ä½¿ç”¨ `self.base_model.get_input_embeddings()`
  - `set_input_embeddings`: é»˜è®¤ä½¿ç”¨ `self.base_model.set_input_embeddings()`
- `get_output_embeddings`: å­ç±»é‡è½½æ­¤æ–¹æ³•ã€ä½œç”¨æ˜¯ä»€ä¹ˆã€‘
- `retrieve_modules_from_names`

#### activation checkpointing

- `gradient_checkpointing_enable`
- `gradient_checkpointing_disable`
- `is_gradient_checkpointing`

#### auto class

- `register_for_auto_class`

#### å…¶ä»–ã€å¾…è¡¥å……ã€‘

- `_set_default_torch_dtype`
- `get_memory_footprint`
- `to`
- `half`
- `float`


## åŸç†/æºç è§£æï¼šğŸ¤— Transformers ä¸­çš„æ–‡æœ¬ç”Ÿæˆç­–ç•¥

æœ¬èŠ‚ä»‹ç» ğŸ¤— Transformers é‡Œå„ç§ç”Ÿæˆæ–¹å¼çš„è¯¦ç»†ç®—æ³•

å…³äºæ–‡æœ¬ç”Ÿæˆï¼ŒğŸ¤— Transformers å®˜æ–¹æœ‰å¦‚ä¸‹å‡ ç¯‡åšå®¢å€¼å¾—é˜…è¯»ï¼š

- åŸºç¡€ç¯‡-å„ç±»ç”Ÿæˆç­–ç•¥ï¼š[how-to-generate](https://huggingface.co/blog/how-to-generate)
- 4.24.0ç‰ˆæœ¬ï¼ˆå‘å¸ƒæ—¶é—´2022/11/01ï¼‰å¼•å…¥contrastive searchï¼š[contrastive-search](https://huggingface.co/blog/introducing-csearch)

ä½¿ç”¨ ğŸ¤— Transformers ç”Ÿæˆæ–‡æœ¬ï¼Œç”¨æ³•å¦‚ä¸‹:

```python
from transformers import T5Tokenizer, T5ForConditionalGeneration
pretrained_name_or_path = "t5-small"
tokenizer = T5Tokenizer.from_pretrained(pretrained_name_or_path)
model = T5ForConditionalGeneration.from_pretrained(pretrained_name_or_path)
inputs = tokenizer(["I'm a student, ", "Deep learning"])
generated_ids = model.generate(
  input_ids=inputs["input_ids"],
  attention_mask=inputs["attention_mask"], 
  max_length=32, 
  num_beams=5,
  repetition_penalty=2.5, 
  length_penalty=1.0, 
  early_stopping=True
  )
```

è¿™é‡Œçš„ `generate` å‡½æ•°æ˜¯å®ç°åœ¨ `T5ForConditionalGeneration` çš„åŸºç±» `PreTrainedModel` ä¸­çš„ï¼Œè€Œ `generate` æ–¹æ³•ä¼šæ ¹æ®ä¼ å…¥çš„å‚æ•°(ä¾‹å¦‚è¿™ä¸ªä¾‹å­é‡Œçš„ `max_length`, `num_beams`, `repetition_penalty`, `length_penalty`, `early_stopping`)é€‰æ‹©æ›´ä¸ºå…·ä½“çš„ç”Ÿæˆæ–¹å¼è¿›è¡Œç”Ÿæˆ, è¿™äº›ç”Ÿæˆæ–¹å¼ä¹Ÿéƒ½æ˜¯åœ¨åŸºç±» `PreTrainedModel` ä¸­è¿›è¡Œå®ç°çš„, ç”±æ­¤å¯ä»¥çœ‹å‡ºåœ¨ç”Ÿæˆç­–ç•¥ä¸Šå…¶å®å¯¹äºä¸åŒçš„æ¨¡å‹æ˜¯ç»Ÿä¸€çš„ã€‚è¿™äº›æ›´ä¸ºå…·ä½“çš„ç”Ÿæˆæ–¹å¼åˆ—ä¸¾å¦‚ä¸‹ï¼Œåé¢å†åŠ ä»¥è¯¦ç»†ä»‹ç»ï¼š

- `greedy_search`ï¼šè´ªå¿ƒç­–ç•¥
- `beam_search`ï¼šbeam search
- `sample`ï¼šå¯¹æ¯æ¬¡å¾—åˆ°çš„æ¦‚ç‡åˆ†å¸ƒä¸Šè¿›è¡Œé‡‡æ ·
- `beam_sample`ï¼šå¯¹æ¯æ¬¡å¾—åˆ°çš„æ¦‚ç‡åˆ†å¸ƒä¸Šè¿›è¡Œé‡‡æ ·åå†è¿›è¡Œ beam search
- `group_beam_search`ï¼šå¯¹ beam_size è¿›è¡Œåˆ†ç»„, æ¯ç»„åˆ†åˆ«ä½¿ç”¨ beam search, ä»¥æå‡ beam search ç»“æœçš„å¤šæ ·æ€§
- `constrained_beam_search`ï¼šå¸¦çº¦æŸæ¡ä»¶çš„ beam search, ä¾‹å¦‚ç”Ÿæˆç»“æœé‡Œå¿…é¡»è¦åŒ…å«ç‰¹å®šçš„è¯
- `contrastive_search`ï¼šè¿™ç¯‡[è®ºæ–‡](https://arxiv.org/abs/2210.14140)é‡Œæå‡ºçš„ä¸€ç§ç”Ÿæˆæ–¹å¼ï¼Œæ”¹å–„äº† greedy search/beam search ç”Ÿæˆç»“æœç»å¸¸å‡ºç°é‡å¤å¥å­ï¼ˆæ–‡çŒ®ä¸­æˆä¸º model degenerationï¼‰çš„æƒ…å†µ, ä¹Ÿæ”¹å–„äº† sample/beam sample æ–¹æ³•å®¹æ˜“å‡ºç°è¯­ä¹‰å‰åä¸ä¸€è‡´çš„ç°è±¡ã€‚

é˜…è¯» [how-to-generate](https://huggingface.co/blog/how-to-generate) åšå®¢çš„è¯»è€…ï¼Œå¯èƒ½ä¼šç–‘æƒ‘äº top k sampling ä¸ top p sampling ï¼ˆtop pï¼‰å®ç°åœ¨å“ªé‡Œ, è¿™é‡Œç»™å‡ºç®€è¦çš„è§£é‡Šï¼šè¿™ä¸¤ä¸ªè¢«æŠ½è±¡ä¸ºå¯¹æŠ½æ ·è¿‡ç¨‹æ¦‚ç‡åˆ†å¸ƒçš„è°ƒæ•´ï¼Œå› æ­¤æ’åœ¨æ¦‚ç‡åˆ†å¸ƒä¸é‡‡æ ·ä¹‹é—´ã€‚å¦å¤–ï¼Œç›®å‰ä¸ºæ­¢æ¯”è¾ƒå…¬è®¤çš„ç›¸å¯¹ä¼˜ç§€ç”Ÿæˆæ–¹å¼ä¸ºå¸¦æœ‰ top p/top k çš„ beam sample æ–¹å¼ï¼Œå¹¶ä¸”éœ€è¦é€‚å½“è°ƒèŠ‚ `length_penalty` å‚æ•°ç”¨ä»¥ä¿ƒè¿›/æŠ‘åˆ¶ç”Ÿæˆçš„åºåˆ—é•¿åº¦ï¼Œè°ƒèŠ‚ `repetition_penalty` ç­‰ç›¸å…³å‚æ•°æ§åˆ¶é‡å¤è¯ç»„å‡ºç°çš„æ¬¡æ•°ã€‚æ€»çš„æ¥è¯´ï¼Œè°ƒæ•´è¿™äº›å‚æ•°å¯¹ç”Ÿæˆè´¨é‡è¿˜æ˜¯æœ‰ä¸€äº›å½±å“çš„ï¼Œå› æ­¤åœ¨ decoder çš„è§£ç ç­–ç•¥ä¸Šä¹Ÿä¸€ç›´æœ‰è®ºæ–‡è¿›è¡Œç ”ç©¶ï¼ˆä¾‹å¦‚ï¼šcontrastive search æ˜¯ 2022 å¹´çš„å·¥ä½œï¼‰ï¼Œä¸åŒçš„å¤§æ¨¡å‹åœ¨å¼€å‘è¿‡ç¨‹ä¸­ä¹Ÿå¯èƒ½ä¼šæ¢ç´¢å‡ºæ–°çš„ç”Ÿæˆç­–ç•¥ã€‚

æœ¬èŠ‚åç»­å†…å®¹ç»„ç»‡å¦‚ä¸‹ï¼š

- å…³äº generate æ–¹æ³•çš„ç®€è¦ä»‹ç»ï¼Œæ¶‰åŠåˆ° `PreTrainedModel` çš„ä¸€äº›ç»§æ‰¿å…³ç³»
- `GenerationConfig` çš„ç®€ä»‹ï¼šåªç®€å•ä»‹ç»ä¸€éƒ¨åˆ†å‚æ•°ï¼Œå…¶ä½™çš„å‚è€ƒå®˜æ–¹æ–‡æ¡£ã€‚é‡ç‚¹ä»‹ç»è·Ÿç”Ÿæˆç­–ç•¥å¼ºç›¸å…³çš„å‚æ•°
- æœ€ç®€ç‰ˆæœ¬çš„ `greedy search` ä»‹ç»
- `LogitsProcessor`ã€`LogitsWarpper` ç®€ä»‹
- `beam_search`
- `sample`/`beam_sample`
- `group_beam_search`
- `constrained_beam_search`: è¿™ä¸ªæ–¹æ³•è‡ªæˆä½“ç³»ä¸”å®ç°ä¸Šæœ‰äº›å¤æ‚, éœ€è¦é¢å¤–ä»‹ç»ç›¸å…³çš„å®ç°ç»†èŠ‚
- `contrastive_search`


### `PreTrainedModel`, `GenerationMixin`, `generate`

æœ¬èŠ‚ä¸»è¦æŒ‰ç…§ ğŸ¤— Transformers çš„æºç è¿›è¡Œä»‹ç»ï¼ŒæŒ‰ç…§ ğŸ¤— Transformers ä¸­çš„å®ç°ï¼Œ`T5ForConditionalGeneration` çš„ç»§æ‰¿å…³ç³»å¦‚ä¸‹ï¼š

```python
class T5ForConditionalGeneration(T5PreTrainedModel):
  # ç”¨äº load æƒé‡æ—¶å¯ä»¥å¿½ç•¥
  _keys_to_ignore_on_load_missing = [
        r"encoder.embed_tokens.weight",
        r"decoder.embed_tokens.weight",
        r"lm_head.weight",
  ]
  _keys_to_ignore_on_load_unexpected = [
      r"decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight",
  ]
  # ...

class T5PreTrainedModel(PreTrainedModel):
  config_class = T5Config
  base_model_prefix = "transformer"  # åœ¨ from_pretrained å‡½æ•°ä¸­ load æƒé‡æ—¶æœ‰ç”¨
  def _init_weights(self, module):
    ...
  # å…¶ä»–ä¸€äº›æ–¹æ³•å’Œå±æ€§ä»ç•¥

class PreTrainedModel(nn.Module, ModuleUtilsMixin, GenerationMixin, PushToHubMixin):
  pass
```

è€Œä¸ç”Ÿæˆç›¸å…³çš„ä»£ç ä¸»è¦å®ç°åœ¨ `GenerationMixin` ä¸­ï¼Œä¸€èˆ¬è€Œè¨€ï¼Œé€šè¿‡è¿™ä¸ªç±»çš„ `generate` æ–¹æ³•è¿›è¡Œä½¿ç”¨ï¼Œæ ¹æ®ä¸åŒçš„å‚æ•°è®¾å®šï¼Œä¼šå®é™…ä¸Šé€šè¿‡è°ƒç”¨ä»¥ä¸‹ 7 ç§æ–¹æ³•æ¥å®Œæˆå®é™…çš„ç”Ÿæˆï¼š

`generate` æ–¹æ³•å¦‚ä¸‹:

```python
def generate(
  self,
  inputs: Optional[torch.Tensor] = None,
  generation_config: Optional[GenerationConfig] = None,
  logits_processor: Optional[LogitsProcessorList] = None,
  stopping_criteria: Optional[StoppingCriteriaList] = None,
  prefix_allowed_tokens_fn: Optional[Callable[[int, torch.Tensor], List[int]]] = None,
  synced_gpus: Optional[bool] = False,
  **kwargs):
  # åªæ‘˜å½•æ ¸å¿ƒéƒ¨åˆ†
  if generation_config is None:
    generation_config = self.generation_config

  generation_config = copy.deepcopy(generation_config)
  # æ ¹æ®kwargsæ›´æ–°
  model_kwargs = generation_config.update(**kwargs)  # All unused kwargs must be model kwargs
  self._validate_model_kwargs(model_kwargs.copy())

  logits_processor = logits_processor if logits_processor is not None else LogitsProcessorList()
  stopping_criteria = stopping_criteria if stopping_criteria is not None else StoppingCriteriaList()
  inputs_tensor, model_input_name, model_kwargs = self._prepare_model_inputs(
    inputs, generation_config.bos_token_id, model_kwargs
  )
  # å†æ ¹æ®generation_configå¢åŠ ä¸€éƒ¨åˆ†logits_processor
  logits_processor = self._get_logits_processor(generation_config, input_ids_seq_length, encoder_input_ids,
    prefix_allowed_tokens_fn, logits_processor)
  # å†æ ¹æ®generation_configå¢åŠ ä¸€éƒ¨åˆ†stopping_criteria
  stopping_criteria = self._get_stopping_criteria(generation_config, stopping_criteria)
  # æ ¹æ®ä¸åŒçš„generation_configè®¾ç½®, åˆ†åˆ«è°ƒç”¨ä¸Šè¿°7ç§æ–¹æ³•
  ...
```

å¤‡æ³¨ï¼šæ­¤å¤„çš„ `generation_config` å˜é‡çš„ç±»å‹ä¸º `GenerationConfig`, è€Œ `self.generation_config` æ˜¯ `PreTrainedModel` å®ä¾‹åŒ–æ—¶å¾—åˆ°çš„ã€‚

ã€æ­¤å¤„éœ€å¢åŠ ä¸€ä¸ªéšè—æŒ‰é’®ã€‘
```python
class PreTrainedModel(nn.Module, ModuleUtilsMixin, GenerationMixin, PushToHubMixin):
  def __init__(self, config, *inputs, **kwargs):
    # *inputs, **kwargs åœ¨æ­¤å¤„æœªè¢«ä½¿ç”¨åˆ°
    super().__init__()  # nn.Moduleçš„__init__å‡½æ•°, å…¶ä½™ç»§æ‰¿ç±»å‡ä¸ºMixin, æ²¡æœ‰__init__å‡½æ•°
    self.config = config
    self.name_or_path = config.name_or_path
    self.warnings_issued = {}
    self.generation_config = GenerationConfig.from_model_config(config) if self.can_generate() else None
  @classmethod
  def from_pretrained(self, pretrained_model_name_or_path, *model_args, **kwargs):
    # åªæ‘˜å½•é‡è¦çš„éƒ¨åˆ†
    config = kwargs.pop("config", None)
    if not isinstance(config, PretrainedConfig):
      config_path = config if config is not None else pretrained_model_name_or_path
      config, model_kwargs = cls.config_class.from_pretrained(..., **kwargs)
    else:
      model_kwargs = kwargs
    model = cls(config, *model_args, **model_kwargs)  # è°ƒç”¨ __init__
    state_dict = load_state_dict(resolved_archive_file)
    model, ... = cls._load_pretrained_model(model, state_dict, ...)  # loadæƒé‡è‡³æ¨¡å‹
    model.eval()  # å°†æ¨¡å‹è®¾ç½®ä¸ºevalæ¨¡å¼
    if model.can_generate():  # å¦‚æœpretrained_model_name_or_pathç›®å½•ä¸‹åŒ…å«generation_config.jsonæ–‡ä»¶, åˆ™æŒ‰è¿™ä¸ªæ–‡ä»¶é‡æ–°åˆå§‹åŒ–model.generation_config
      model.generation_config = GenerationConfig.from_pretrained(pretrained_model_name_or_path, ..., **kwargs)
  def save_pretrained(self, save_directory, ...):
    # åªæ‘˜å½•é‡è¦çš„éƒ¨åˆ†
    os.makedirs(save_directory, exist_ok=True)
    model_to_save = unwrap_model(self)
    if is_main_process:
      model_to_save.config.save_pretrained(save_directory)
      if self.can_generate():
          model_to_save.generation_config.save_pretrained(save_directory)
    if state_dict is None:
      state_dict = model_to_save.state_dict()
    # æŸäº›å‚æ•°åœ¨ä¿å­˜æ—¶å¯ä»¥å¿½ç•¥
    if self._keys_to_ignore_on_save is not None:
        for ignore_key in self._keys_to_ignore_on_save:
            if ignore_key in state_dict.keys():
                del state_dict[ignore_key]
    # åœ¨æ­£å¸¸æƒ…å†µä¸‹(æ¨¡å‹å‚æ•°ä¸å¤š), shardæ˜¯ä¸€ä¸ªåªæœ‰ä¸€ä¸ªé”®å€¼å¯¹çš„å­—å…¸, keyä¸º"pytorch_model.bin", valueå³ä¸ºstate_dict
    weights_name = SAFE_WEIGHTS_NAME if safe_serialization else WEIGHTS_NAME
    shards, index = shard_checkpoint(state_dict, max_shard_size=max_shard_size, weights_name=weights_name)
    for shard_file, shard in shards.items():
        if safe_serialization:
            safe_save_file(shard, os.path.join(save_directory, shard_file), metadata={"format": "pt"})
        else:
            save_function(shard, os.path.join(save_directory, shard_file))
    # ä¿å­˜index
    ...
```


### `GenerationConfig` çš„ä¸»è¦å‚æ•°ã€TODOã€‘


### greedy_search

å›¾è§£å¦‚ä¸‹

![](../assets/figures/t5/greedy_search.png)


### `LogitsProcessor`ã€`LogitsWarpper`ã€`StoppingCriteria`ã€TODOã€‘

### beam_search

- å½“ beam_size ä¸º 1 æ—¶é€€åŒ–ä¸º greedy_search

```
logits_processor: å®é™…ä¸Šæ˜¯å¯¹å½“å‰é¢„æµ‹çš„log-softmaxåˆ†æ•°è¿›è¡Œåå¤„ç†(ä¾‹å¦‚é‡å¤å‡ºç°çš„å­—åšäº›scoreä¸Šçš„æƒ©ç½š)
stopping_criteria: åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»“æŸ, è¿”å›Trueè¡¨ç¤ºåº”è¯¥ç»“æŸ(æœ€å…¸å‹çš„æ˜¯beamè¾¾åˆ°æœ€å¤§é•¿åº¦)

input_ids: å½¢çŠ¶ä¸º(batch_size*beam_size, 1)  # å…¨éƒ¨ä¸ºdecoder_satrt_token
beam_scores: å½¢çŠ¶ä¸º(batch_size, beam_size)  # å…¶ä¸­æ¯ä¸€è¡Œçš„ç¬¬ä¸€ä¸ªå…ƒç´ ä¸º0, å…¶ä½™å…ƒç´ ä¸º-inf
beam_scores.view(-1, 1)
beam_hypotheses: batch_sizeä¸ªå€™é€‰æ± 
is_done: åˆå§‹åŒ–ä¸ºbatch_sizeä¸ªFalse

while True:

  æˆªå–æœ€åä¸€ä¸ªinput_idså¾—åˆ°input_tensor(batch_size*beam_size, 1)
  é€šè¿‡å‰å‘è®¡ç®—å¾—åˆ°logits(batch_size*beam_size, vocab_size)å
  è¿›è¡Œlog_softmaxä¹‹åå¾—åˆ°next_token_scores
  next_token_scores_processed = logits_processor(input_ids, next_token_scores)  # (batch_size*beam_size, vocab_size)
  next_token_scores = beam_scores + next_token_scores_processed  # (batch_size*beam_size, vocab_size)

  next_token_scores.view(batch_size, beam_size*vocab_size)
  # å¯¹äºbatchä¸­çš„æ¯ä¸€ä¸ª, éƒ½ç•™ä¸‹2*beam_sizeä¸ªå¯é€‰é¡¹ï¼ˆæ³¨æ„æ ¹æ®æ­¤å¤„çš„è§„åˆ™è¿™äº›å¯é€‰é¡¹é‡Œè‡³å¤šæœ‰beam_sizeä¸ªeosï¼‰
  next_token_scores, next_tokens = next_token_scores.topk(2*beam_size)

  # è¿™ä¸ªè¿‡ç¨‹çš„é€»è¾‘å¦‚ä¸‹:
  å¯¹äºæ¯ä¸ªæ ·æœ¬
    å¦‚æœis_doneå–å€¼ä¸ºTrue, åˆ™ä¸ºæ¯ä¸ªbeamå¡«å……pad_token, continue
    ä»next_token_scoresæœ€å¤§çš„å¼€å§‹
      å¦‚æœå¯¹åº”çš„é¢„æµ‹tokenä¸ºeosï¼š
        å¦‚æœæ­¤scoreæ˜¯å‰beam_sizeå¤§çš„score, åˆ™å°†å…¶åŠ å…¥è¯¥æ ·æœ¬å¯¹åº”çš„å€™é€‰é›†beam_hypotheses
          åŠ å…¥è§„åˆ™å¦‚ä¸‹ï¼š
            å¦‚æœå€™é€‰æ± å½“å‰ä¸è¶³beam_sizeä¸ªæ ·æœ¬, åˆ™ç›´æ¥å°†å…¶åŠ å…¥, å¹¶è®¡ç®—scoreè®¡ç®—é•¿åº¦æƒ©ç½šåï¼Œæ›´æ–°æ± å­ä¸­çš„æœ€å·®åˆ†æ•°
            å¦‚æœå½“å‰å€™é€‰æ± å·²æœ‰beam_sizeä¸ªæ ·æœ¬, åˆ™å¯¹æ­¤scoreè®¡ç®—é•¿åº¦æƒ©ç½šåä¸æ± å­é‡Œçš„scoreè¿›è¡Œæ¯”è¾ƒï¼Œå¦‚æœä¼˜äºæœ€å·®åˆ†æ•°ï¼Œåˆ™åŠ å…¥å¹¶å‰”é™¤æ± å­é‡Œæœ€å·®çš„é‚£ä¸ªåºåˆ—, ä¹‹åæ›´æ–°æ± å­çš„æœ€å·®åˆ†æ•°
            å¤‡æ³¨: æ± å­ä¸­çš„scoreå‡ä¸ºé•¿åº¦æƒ©ç½šåçš„score
        å¦‚æœæ­¤scoreä¸æ˜¯å‰beam_sizeå¤§çš„score, åˆ™ç›´æ¥å¿½ç•¥è¿™ä¸ªæ ·æœ¬
      å¦‚æœå¯¹åº”çš„é¢„æµ‹tokenä¸æ˜¯eosï¼š
        å°†å…¶åŠ å…¥åˆ°beam_scores, beam_next_tokensä¸­ç›´åˆ°è¾¾åˆ°beam_sizeä¸ª
    åˆ¤æ–­beam_hypothesesæ˜¯å¦å®Œæˆï¼Œç”±æ­¤æ›´æ–°is_done
      åˆ¤æ–­è§„åˆ™å¦‚ä¸‹ï¼š
        (1) å¦‚æœbeam_hypothesesçš„æ¨¡å¼ä¸ºearly_stop, é‚£ä¹ˆåªè¦æ± å­é‡Œæœ‰num_beamä¸ªæ ·æœ¬, å°±è®¤ä¸ºæœç´¢ç»“æŸ
        (2) éearly_stopæ¨¡å¼, åˆ™æ ¹æ®beam_scoresä¸­çš„æœ€å¤§è€…æ˜¯å¦åœ¨è®¡ç®—é•¿åº¦æƒ©ç½šåæ¯”å€™é€‰æ± ä¸­çš„æœ€å·®åˆ†æ•°å¤§, å¦‚æœæ›´å¤§åˆ™ç»§ç»­æœç´¢(is_done=False), å¦‚æœæ›´å°åˆ™è®¤ä¸ºæœç´¢ç»“æŸ(is_done=True)

  beam_scores, beam_next_tokens = beam_scorer.process(input_ids, next_token_scores, next_tokens) # é€»è¾‘è§å‰é¢ä¸€å¤§æ®µçš„è¯´æ˜
  input_ids = cat(input_ids, beam_next_tokens)

  å¦‚æœis_doneå‡ä¸ºTrueæˆ–è€…stopping_criteria(input_ids, scores)ä¸ºTrue, åˆ™è·³å‡ºwhile True

æœ€ååšæ”¶å°¾:
  å¯¹äºè¿˜æ²¡ç»“æŸçš„beam, å°è¯•æ·»åŠ è‡³beam_hypothesesä¸­
  å°†è¾“å‡ºåºåˆ—ä½¿ç”¨pad_tokenè¡¥é½
```

### group_beam_search

group_beam_searchä¸beam_searchçš„åŒºåˆ«åœ¨äº, å°†å½“å‰çš„beamåˆ†ä¸ºè‹¥å¹²ç»„, æ¯ç»„group_sizeä¸ªåºåˆ—, æ¯æ¬¡å¯¹è¿™ä¸ªåºåˆ—åšbeam_search, å¹¶ç•™ä¸‹group_sizeä¸ªåºåˆ—, è¿™æ ·æ€»å…±ä»ç•™æœ‰beam_sizeä¸ªåºåˆ—
- å½“ group_size ä¸ beam_size ç›¸ç­‰æ—¶, é€€åŒ–ä¸ºbeam_search

### beam_sample/sample

beam_sampleä¸beam_searchçš„åŒºåˆ«åœ¨äºå°†è¿™å‡ è¡Œ

```
next_token_scores_processed = logits_processor(input_ids, next_token_scores)  # (batch_size*beam_size, vocab_size)
next_token_scores = beam_scores + next_token_scores_processed  # (batch_size*beam_size, vocab_size)
next_token_scores.view(batch_size, beam_size*vocab_size)
next_token_scores, next_tokens = next_token_scores.topk(2*beam_size)
```

æ›¿æ¢ä¸º

```
logit_warpper: é€šå¸¸è¿›è¡Œtop-k/top-pä¿®æ”¹åˆ†æ•°/ä¸ä¿®æ”¹åˆ†æ•°, å½±å“åç»­çš„æŠ½æ ·ç»“æœ

next_token_scores_processed = logits_processor(input_ids, next_token_scores)  # (batch_size*beam_size, vocab_size)
next_token_scores = beam_scores + next_token_scores_processed  # (batch_size*beam_size, vocab_size)
next_token_scores.view(batch_size, beam_size*vocab_size)

next_token_scores = logits_warper(input_ids, next_token_scores)
probs = nn.functional.softmax(next_token_scores, dim=-1)
next_tokens = torch.multinomial(probs, num_samples=2 * num_beams)
next_token_scoresæ ¹æ®next_tokensçš„é€‰æ‹©å¾—åˆ°
```

### constrained_beam_searchã€TODOã€‘

```
<<<ç¬¬ä¸€é¡¹æ”¹åŠ¨>>>
å¯¹äºæ¯ä¸ªæ ·æœ¬ï¼Œè¿›è¡Œæ­£å¸¸çš„beam_sizeå¾—åˆ°ï¼š

beam_scores: beam_sizeä¸ªåˆ†æ•°
input_ids: (beam_size, cur_len)
next_tokens: (beam_size)

å¯¹æ¯ä¸ªinput_id, æ ¹æ®çº¦æŸè®¡ç®—ä¸‹ä¸€æ­¥å¯èƒ½çš„tokenï¼Œå‡è®¾å¢åŠ äº† H ä¸ªæ–°çš„å¯é€‰é¡¹ï¼Œå¾—åˆ°
full_hypo: (beam_size+H, cur_len+1) æ‰€æœ‰çš„å‡è®¾
full_score: (beam_size+H,) æ‰€æœ‰å‡è®¾çš„åˆ†æ•°
bank: (beam_size+H,) æ•´æ•°å€¼, å¯¹beam_size+Hä¸­æ¯ä¸ªå‡è®¾è®¡ç®—ä¸€ä¸ªæ»¡è¶³çº¦æŸçš„åˆ†æ•°: æ‰€æœ‰çº¦æŸæ¡ä»¶çš„æœ€å¤§é•¿åº¦*å·²å®Œæˆçš„çº¦æŸ+è¿›è¡Œä¸­çš„çº¦æŸå·²å®Œæˆçš„é•¿åº¦

zipped = bank * 100 + full_score  # 100æ˜¯hfä¸­å†™æ­»çš„è¶…å‚æ•°

æŒ‰ç…§zippedè¿›è¡Œä»å¤§åˆ°å°æ’åºå¾—åˆ°indice, å¹¶æŒ‰ç…§æ­¤é¡ºåºé‡æ’bankï¼Œå¾—åˆ°sorted_bankï¼Œä¾‹å¦‚ï¼š

indice=[5, 4, 1, 2, 0, 3]  # å³zippedä¸­ä¸‹æ ‡ä¸º5çš„å…ƒç´ æœ€å¤§ï¼Œç›¸åº”çš„bankå€¼ä¸º
sorted_bank=[2, 2, 1, 0, 2, 3]
ç”±sort_bankè®¡ç®—dup_num = [0, 1, 0, 0, 0, 0]ï¼Œdup_numä¸ºé‡å¤å‰ä¸€ä¸ªbankå€¼å¾—æ¬¡æ•°

å‡è®¾beam_sizeä¸º3, åˆ™æœ€ç»ˆå¾—indiceä¸º[5, 1, 2]  # æŒ‰dup_numä»å°åˆ°å¤§ç¨³å®šæ’åº, å› æ­¤ä¼šè·³è¿‡indice[1]
<<<ç¬¬äºŒé¡¹æ”¹åŠ¨>>>
æ·»åŠ è‡³hypæ—¶éœ€è¦æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ¡ä»¶ï¼Œæ»¡è¶³åˆ™æ·»åŠ ï¼Œä¸æ»¡è¶³åˆ™ä¸æ·»åŠ 
```


constrained_beam_searchç›¸å…³


```python
class Constraint(ABC):
    def __init__(self):
        self.test()  # æµ‹è¯•å­ç±»çš„å®šä¹‰æ˜¯å¦åˆæ³•

    def test(self):
        counter = 0
        completed = False
        while not completed:
            if counter == 1:  # å¦‚æœéœ€è¦è‡³å°‘2æ­¥æ‰èƒ½å®Œæˆ,åˆ™å¯ä»¥æµ‹è¯•resetæ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
                # self.resetå‡½æ•°è¯­ä¹‰(æ”¹å˜çŠ¶æ€): é‡æ–°åˆå§‹åŒ–å†…éƒ¨çš„çŠ¶æ€
                self.reset()
            # self.advanceå‡½æ•°è¯­ä¹‰(ä¸æ”¹å˜çŠ¶æ€): ç»™å‡ºä¸€ä¸ªèƒ½æ»¡è¶³ä¸‹ä¸€æ­¥çº¦æŸæ¡ä»¶çš„token_id(å¦‚æœæœ‰å¤šä¸ªtoken_idèƒ½æ»¡è¶³æ—¶åˆ™è¿”å›token_idåˆ—è¡¨)
            advance = self.advance()  # å¾—åˆ°ä¸€ä¸ªèƒ½å®Œæˆä¸‹ä¸€ä¸ªæ­¥éª¤çš„token_id
            # self.does_advanceè¯­ä¹‰(ä¸æ”¹å˜çŠ¶æ€): åˆ¤æ–­è¾“å…¥çš„å€¼æ˜¯å¦æ»¡è¶³ä¸‹ä¸€æ­¥çº¦æŸçš„æ¡ä»¶
            if not self.does_advance(advance):  # éªŒè¯ä¸€å®šèƒ½èµ°åˆ°ä¸‹ä¸€æ­¥
                raise Exception(
                    "Custom Constraint is not defined correctly. self.does_advance(self.advance()) must be true."
                )
            # self.updateè¯­ä¹‰: steppedè¡¨ç¤ºå½“å‰è¾“å…¥æ˜¯å¦èƒ½æ»¡è¶³ä¸‹ä¸€æ­¥çš„çº¦æŸæ¡ä»¶, completedä¸ºæ˜¯å¦å®Œå…¨ç»“æŸ, resetè¡¨ç¤ºæ˜¯å¦éœ€è¦é‡ç½®
            # å¹¶ä¸”æ ¹æ®å„ç§æƒ…å†µæ”¹å˜çŠ¶æ€, ä¾‹å¦‚ä¿®æ”¹å†…éƒ¨çš„çŠ¶æ€æˆ–è€…è°ƒç”¨self.reset
            stepped, completed, reset = self.update(advance)
            counter += 1

            if counter > 10000:
                raise Exception("update() does not fulfill the constraint.")
        # self.remainingè¯­ä¹‰: å‰©ä½™æ­¥æ•°
        if self.remaining() != 0:  # åœ¨completedçš„æ—¶å€™, å‰©ä½™æ­¥æ•°åº”è¯¥ä¸º0
            raise Exception("Custom Constraint is not defined correctly.")
    
    # å¤åˆ¶(å¤åˆ¶å½“å‰çŠ¶æ€/ä¸å¤åˆ¶å½“å‰çŠ¶æ€)
    @abstractmethod
    def copy(self, stateful=False):
        pass

```

ğŸ¤— Transformers 4.26.1 ç‰ˆæœ¬ä¸­ç›®å‰åªå®ç°äº†ä¸¤ç±» `Constraint`

- `PhrasalConstraint`: ç”Ÿæˆçš„ç»“æœé‡Œå¿…é¡»å‡ºç°æŒ‡å®šçš„ token_id åºåˆ—
  ```python
  constraint = PhrasalConstraint([1, 2, 5])  # é™åˆ¶è¾“å‡ºåºåˆ—å¿…é¡»åŒ…å«è¿ç»­çš„tokenåºåˆ—[1, 2, 5]
  ```
- `DisjunctiveConstraint`: ç”Ÿæˆçš„ç»“æœé‡Œå¿…é¡»å‡ºç°æŒ‡å®šçš„ token_id åºåˆ—(æ»¡è¶³å…¶ä¸­ä¹‹ä¸€å³å¯)
  ```python
  constraint = PhrasalConstraint([[1, 2, 5], [3, 4]])  # é™åˆ¶è¾“å‡ºåºåˆ—å¿…é¡»åŒ…å«è¿ç»­çš„tokenåºåˆ—[1, 2, 5]æˆ–[3, 4]
  ```
- `ConstraintListState`
  ```python
  constraints = [PhrasalConstraint([1, 2, 5]), PhrasalConstraint([1, 3])]
  ConstraintListState(constraints)  # é™åˆ¶è¾“å‡ºåºåˆ—å¿…é¡»æ»¡è¶³å¤šä¸ªé™åˆ¶æ¡ä»¶
  ```


`DisjunctiveConstraint` çš„å®ç°ä¾èµ–äºä¸€ä¸ªè¾…åŠ©ç±», æœ¬è´¨ä¸Šæ˜¯å°†ä¸€ä¸ªåˆ—è¡¨çš„åˆ—è¡¨è½¬æ¢ä¸ºäº†ä¸€ä¸ªå­—å…¸(å‰ç¼€æ ‘)

```python
class DisjunctiveTrie:
    def __init__(self, nested_token_ids: List[List[int]], no_subsets=True):
        ...

t = DisjunctiveTrie([[1, 2], [1, 3, 4], [1, 4, 5]])
t.trie
# {
#   1: {
#     2: {},
#     3: {4: {}},
#     4: {5: {}}
#   }
# }
```


```python
class ConstraintListState:
    def __init__(self, constraints: List[Constraint]):
        self.constraints = constraints

        # max # of steps required to fulfill a given constraint
        self.max_seqlen = max([c.seqlen for c in constraints])
        self.n_constraints = len(constraints)
        self.completed = False

        self.init_state()

    def init_state(self):
        # complete_constraints + inprogress_constraint + pending_constraints = å…¨éƒ¨çš„constraint
        self.complete_constraints = []
        self.inprogress_constraint = None  # åªèƒ½ä¸ºNoneæˆ–è€…å…¶ä¸­ä¸€ä¸ªconstraint
        self.pending_constraints = [constraint.copy(stateful=False) for constraint in self.constraints]
    def advance(self) -> List[int]:
        ...
    def reset(self, token_ids: Optional[List[int]]):
        # åœ¨ä¼ å…¥token_idså‚æ•°æ—¶, ä¼šè°ƒç”¨self.addå‡½æ•°
        ...
    def add(self, token_id: int):
        # å¦‚æœinprogress_constraintä¸ºç©º, åˆ™åœ¨pending_constraintsæ‰¾æœ‰æ²¡æœ‰èƒ½updateçš„çº¦æŸ, å¦‚æœæœ‰, å°±å°†å®ƒupdateå¹¶ä½œä¸ºinprogress_constraint
        # å¦‚æœinprogress_constraintä¸ä¸ºç©º, åˆ™update inprogress_constraintç›´è‡³è¿™ä¸ªçº¦æŸè¾¾åˆ°å®ŒæˆçŠ¶æ€
        return complete: bool, stepped: bool
```

### contrastive_searchã€TODO: å¾…è¡¥å……ã€‘

Huggingface å®˜æ–¹åšå®¢ï¼ˆ2022/10 å¼•å…¥ï¼‰ï¼šhttps://huggingface.co/blog/introducing-csearch


ç®—æ³•ä¼ªä»£ç å¦‚ä¸‹ï¼š
```
é¦–å…ˆåˆå§‹åŒ–decoderçš„input_ids: (0,)*B
å°†å…¶è¾“å…¥è‡³decoderè®¡ç®—å‡º next_logits: (B, vocab_size), cur_hidden: (B, 1, d_model)
L = 1
while True:
  # input_ids: å·²ç¡®å®šåºåˆ—, next_logits: å·²ç¡®å®šåºåˆ—çš„logits, cur_hidden: å·²ç¡®å®šåºåˆ—çš„decoderçš„è¾“å‡º
  å¯¹next_logitsè¿›è¡Œåå¤„ç†
  å–å‡ºnext_logitsä¸­å‰top_kä¸ªå¯èƒ½çš„token: (B, top_k), æ‹¼æ¥input_idsåºåˆ— possible_input_ids: (B*top_k, L)
  å°†possibleåºåˆ—ä½œä¸ºdecoderçš„è¾“å…¥, å¾—åˆ° hidden: (B*top_k, d_model), new_next_logits: (B*top_k, vocab_size)
  æ ¹æ®contrastive searchçš„è¯„åˆ†è§„åˆ™æ ¹æ® next_logits, cur_hidden, hidden æŒ‘é€‰å‡ºæ¯ä¸ªæ ·æœ¬æœ€ä¼˜çš„ä¸‹ä¸€ä¸ªåºåˆ— input_ids: (B, L+1)
  æ ¹æ®input_idsæŒ‘é€‰å¾—åˆ°cur_hidden: (B, L+1, d_model), æŒ‘é€‰å¾—åˆ° new_next_logits: (B, vocab_size)
  next_logits = new_next_logits
  L += 1
  åˆ¤æ–­æ˜¯å¦è¾¾åˆ°æœ€å¤§é•¿åº¦æˆ–å…¶ä»–ä¸­æ­¢æ¡ä»¶æ˜¯å¦æˆç«‹ï¼šbreak
è¿”å›input_ids
```

### Streamer

é€šå¸¸æˆ‘ä»¬å¿…é¡»ç­‰ generate æ–¹æ³•ç”Ÿæˆ `eos` æ‰èƒ½ä¸€æ¬¡æ€§æ‹¿åˆ°è¿”å›ç»“æœ, ä½†å¯¹äºå¤§æ¨¡å‹æ¥è¯´, ç”Ÿæˆ token çš„é€Ÿåº¦å¯èƒ½æ¯”è¾ƒæ…¢, å› æ­¤éœ€è¦æµå¼è¾“å‡º, ğŸ¤— Transformers åœ¨ 4.28.0 ç‰ˆæœ¬å·¦å³å¢åŠ äº†ä¸€ä¸ª API

```python
# å®˜æ–¹æ–‡æ¡£ç¤ºä¾‹: https://huggingface.co/docs/transformers/internal/generation_utils#transformers.TextStreamer
from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer, TextIteratorStreamer

tok = AutoTokenizer.from_pretrained("gpt2")
model = AutoModelForCausalLM.from_pretrained("gpt2")
inputs = tok(["An increasing sequence: one,"], return_tensors="pt")
streamer = TextStreamer(tok)

# Despite returning the usual output, the streamer will also print the generated text to stdout.
_ = model.generate(**inputs, streamer=streamer, max_new_tokens=20)


# å®˜æ–¹æ–‡æ¡£ç¤ºä¾‹: https://huggingface.co/docs/transformers/internal/generation_utils#transformers.TextIteratorStreamer
# ä¸»è¦ç”¨äº Gradio
from threading import Thread
tok = AutoTokenizer.from_pretrained("gpt2")
streamer = TextIteratorStreamer(tok)
# Run the generation in a separate thread, so that we can fetch the generated text in a non-blocking way.
generation_kwargs = dict(inputs, streamer=streamer, max_new_tokens=20)
thread = Thread(target=model.generate, kwargs=generation_kwargs)  # æ–°å¼€ä¸€ä¸ªçº¿ç¨‹ç”¨äºäº§ç”Ÿtoken, tokenè¢«putåˆ°streamerå†…éƒ¨çš„queue.Queueä¸­
thread.start()
generated_text = ""
for new_text in streamer:  # ä¸»çº¿ç¨‹ä»streamerå†…éƒ¨çš„queue.Queueå–æ•°æ®
    generated_text += new_text
generated_text
```

å†…éƒ¨é€»è¾‘å…¶å®æ¯”è¾ƒç®€å•, Streamer ç›¸å…³çš„ API ä»…æœ‰å¦‚ä¸‹ 3 ä¸ª

æ³¨æ„: ç›®å‰åªèƒ½ç”¨äº batch_size ä¸º 1 çš„æƒ…å½¢, å¹¶ä¸”ä¸èƒ½ç”¨äº beam_size > 1
```python
# transformers/generation/streamers.py
class BaseStreamer:
  def put(self, value):
    # value æ˜¯ä¸€ä¸ªä¸€ç»´tensor, æˆ–è€…ç¬¬0ç»´ä¸º1çš„äºŒç»´tensor, ä»£è¡¨token_idåºåˆ—
    raise NotImplementError()
  def end(self):
    raise NotImplementError()
class TextStreamer(BaseStreamer):
  ...
class TextIteratorStreamer(TextStreamer):
  ...
```

åœ¨ ğŸ¤— Transformers çš„ generate ä¸­, ä½¿ç”¨ Streamer çš„é€»è¾‘æ˜¯: é¦–å…ˆè°ƒç”¨ `put` å°† prompt æ¨å…¥ Streamer ä¸­, æ¯æ¬¡ç”Ÿæˆäº†ä¸€ä¸ªæ–°çš„ token ä¹‹å, å°†æ–°ç”Ÿæˆçš„ token æ¨å…¥ Streamer ä¸­(å¦‚æœæ˜¯TextStreamer, åˆ™æ‰“å°æœ€æ–°çš„å®Œæ•´word), ç”Ÿæˆç»“æŸå, è°ƒç”¨ `end` æ–¹æ³•


ä»¥ä¸‹æ˜¯ä¸€ä¸ªç›¸å¯¹ç‹¬ç«‹åœ°ä½¿ç”¨ TextStreamer çš„ä¾‹å­, ä¾›å‚è€ƒ
```python
from transformers import AutoTokenizer, TextStreamer
tokenizer = AutoTokenizer.from_pretrained("gpt2")
streamer = TextIteratorStreamer(tokenizer)
text = "A B C D E F"
tokens = tokenizer(text, return_tensors="pt")["input_ids"][0]

import time
import random
cur_idx = 0
n = len(tokens)
while True:
  num = random.randint(1, 3)
  end = cur_idx + num
  streamer.put(token[cur_idx:end])
  cur_idx = num
  time.sleep(0.2)
  if end >= n:
    streamer.end()
    break
```

## Trainerã€TODO: è€ƒè™‘ç§»é™¤ã€‘

## Pipelineã€TODO: è€ƒè™‘ç§»é™¤ã€‘

## åè®°ã€TODOã€‘

æœ¬æ–‡åŸæœ¬åªæ˜¯æƒ³ç†æ¸… T5 é¢„è®­ç»ƒã€å¾®è°ƒã€æ¨ç†çš„ç»†èŠ‚ã€‚å› æ­¤æœ‰å¿…è¦åŸºäºè¿™æ¡ä¸»çº¿å¯¹å…¨æ–‡çš„è¡Œæ–‡è¿›è¡Œæ¢³ç†

- æ€ä¹ˆé¢„è®­ç»ƒ T5
  - C4 æ•°æ®é›†
  - æ€ä¹ˆè®­ç»ƒä¸€ä¸ª tokenizer
    - è®­ç»ƒä¸€ä¸ª T5Tokenizer/T5TokenizerFast
  - æ€ä¹ˆä½¿ç”¨ tokenizer
  - é¢„è®­ç»ƒè„šæœ¬
    - ğŸ¤— Datasets æˆ–è‡ªå®šä¹‰ torch.data.utils.Dataset
    - ğŸ¤— Transformers Trainer æˆ– raw pytorch æˆ– raw pytorch with ğŸ¤— Accelerate æˆ– Lightning æˆ– deepspeed
- å¾®è°ƒ T5
  - å¾®è°ƒæ•°æ®é›†
  - å¾®è°ƒè„šæœ¬
- T5 æ¨ç†
  - æ€ä¹ˆç”Ÿæˆæ–‡æœ¬
    - ç”Ÿæˆç­–ç•¥åŠå‚æ•°çš„å«ä¹‰
    - pipeline

## ä¸»è¦å‚è€ƒèµ„æ–™ã€TODOã€‘

- Huggingface å®˜æ–¹è¯¾ç¨‹: [course](https://huggingface.co/learn/nlp-course)

- Transformer æ¨¡å‹ç»“æ„
  - Huggingface å®˜æ–¹åšå®¢ï¼Œä»‹ç» encoder-decoder æ¶æ„ï¼š[encoder-decoder](https://huggingface.co/blog/encoder-decoder)
  - å›¾è§£ Transformer çš„ä¸€ç¯‡åšå®¢(å¼ºåŠ›æ¨è)ï¼š[illustrated-transformer](http://jalammar.github.io/illustrated-transformer/)ï¼Œ[ä¸­æ–‡ç¿»è¯‘ç‰ˆ](https://blog.csdn.net/longxinchen_ml/article/details/86533005)
  - ä»£ç å®ç° Transformer çš„ä¸€ç¯‡åšå®¢(å“ˆä½›å‡ºå“ï¼Œå¼ºåŠ›æ¨è): [åŸç‰ˆ](https://nlp.seas.harvard.edu/2018/04/03/attention.html)ï¼Œ[æ›´æ–°ç‰ˆ](http://nlp.seas.harvard.edu/annotated-transformer/)

- tokenizer
  - ğŸ¤— Transformers å®˜æ–¹æ–‡æ¡£å¯¹å„ä¸ªæ¨¡å‹æ‰€ä½¿ç”¨çš„ tokenizer çš„æ¦‚è¿°ï¼š[å®˜æ–¹æ–‡æ¡£](https://huggingface.co/docs/transformers/main/en/tokenizer_summary)
  - ğŸ¤— nlp course: [chapter 6](https://huggingface.co/learn/nlp-course/chapter6/1?fw=pt)
  - BPE
    - BPE ç®—æ³•è¯¦è§£åšå®¢ï¼š[åšå®¢](https://towardsdatascience.com/byte-pair-encoding-subword-based-tokenization-algorithm-77828a70bee0)
  - Unigram/SentencePiece:
    - åŸå§‹è®ºæ–‡1: [Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates](https://arxiv.org/abs/1804.10959)
    - åŸå§‹è®ºæ–‡2: [SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing](https://arxiv.org/abs/1808.06226)
    - åšå®¢: [sentencepiece tokenizer demystified](https://towardsdatascience.com/sentencepiece-tokenizer-demystified-d0a3aac19b15)
  - æ‚é¡¹
    - æœºå™¨ç¿»è¯‘é‡Œä¸èƒ½ç”¨ word å½“ä½œè¯è¡¨çš„åŸå› åŠè§£å†³æ–¹æ³•ç®€ä»‹ï¼š[open vocabulary problem in neural machine translation(NMT)](https://homepages.inf.ed.ac.uk/rsennric/mt18/7_4up.pdf)
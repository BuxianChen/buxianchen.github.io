---
layout: post
title: "(WIP) ZeRO (deepspeed & pytorch fsdp)"
date: 2023-11-04 14:10:04 +0800
labels: [deepspeed]
---


## 动机、参考资料、涉及内容

参考资料

- [ZeRo-Offload](https://arxiv.org/abs/2101.06840)

太长不看: 食用指南+DeepSpeed使用+Pytorch FSDP使用


## 原理简介【说人话版本】

- [https://github.com/huggingface/transformers/issues/8771#issuecomment-758418429](https://github.com/huggingface/transformers/issues/8771#issuecomment-758418429)
- [https://engineering.fb.com/2021/07/15/open-source/fsdp/](https://engineering.fb.com/2021/07/15/open-source/fsdp/): fairscale 博客

摘自 fairscale 博客

```
FSDP forward pass:
    for layer_i in layers:
        all-gather full weights for layer_i
        forward pass for layer_i
        discard full weights for layer_i

FSDP backward pass:
    for layer_i in layers:
        all-gather full weights for layer_i
        backward pass for layer_i
        discard full weights for layer_i
        reduce-scatter gradients for layer_i
```


以下是个人拙见【不准确，待优化】

假设在 fp16 的情况下使用 Adam 进行训练, 模型参数量是 `P`, 假设总批量激活值的存储总共为 `A`, 假设现在希望做 `N` 卡并行, 显存主要包含几方面:

- 优化器状态: fp32 模型参数, Adam 对每个参数需要记录两个状态值
- fp16 模型参数
- fp16 模型梯度

**ZeRO-1**

每个 GPU 一部分优化器状态, 具体来说:

```python
partial_optimizer_states = (partial_fp32_weights, partial_fp32_adam_betas_1, partial_fp32_adam_betas_2)
# 每个节点只需存储一份完整的 fp16 模型参数, 完整的 fp16 梯度, 一部分优化器状态, 全部的激活值
memory = [fp16_model, fp_16_grad, partial_optimizer_states, full_activations]

loss = fp16_model(input[local_rank*batch_size:(local_rank+1)*batch_size])  # 产生一些 activation
loss.backward()  # fp16 模型梯度

# 以下有些模糊, 不确定
all_reduce(fp_16_grad, "MEAN")  # 将梯度平均
update(partial_optimizer_states, fp_16_grad)  # 更新自己维护的优化器状态

for rank in range(world_size):
    if rank == local_rank:
        cast_fp32_to_fp16(partial_fp32_weights, fp16_model, local_rank)  # 更新一部分fp16模型参数, 简单的 fp32 cast to fp16
        cast_fp32_to_fp16_and_broadcast_to(partial_fp32_weights)  # 广播给其他进程自己的更新后参数
    else:
        receive_and_update(fp16_model, rank)  # 接收其他进程广播的更新后参数
```

这样一来: 每个 GPU 所需要的显存量变为: `4*P+12*P/N + 2*A/N`

**ZeRO-2**

在 ZeRO-1 的基础上, 每个 GPU 只保存一部分 fp16 的梯度, 具体来说:

```python
partial_optimizer_states = (partial_fp32_weights, partial_fp32_adam_betas_1, partial_fp32_adam_betas_2)
# 每个节点只需存储一份完整的 fp16 模型参数, 一部分的 fp16 梯度, 一部分优化器状态, 全部的激活值
memory = [fp16_model, partial_fp_16_grad, partial_optimizer_states, full_activations]

loss = fp16_model(input[local_rank*batch_size:(local_rank+1)*batch_size])  # 产生一些 activation
# 将 backward 的过程一层一层地进行
dloss_dlayer = [loss]
# loss.backward()
for layer in model.layers[::-1]:
    dloss_dlayer, layer_fp_16_grad = caculate_layer_fp16_grad(dloss_dlayer, layer)
    reduce_scatter(layer_fp_16_grad, "MEAN")  # 将这一层的梯度平均
    partial_fp_16_grad.record(layer_fp_16_grad, layer) # 每个 GPU 只保留这一层一部分的梯度

update(partial_optimizer_states, partial_fp_16_grad)  # 更新自己维护的优化器状态
for rank in range(world_size):
    if rank == local_rank:
        cast_fp32_to_fp16(partial_fp32_weights, fp16_model, local_rank)  # 更新一部分fp16模型参数, 简单的 fp32 cast to fp16
        cast_fp32_to_fp16_and_broadcast_to(partial_fp32_weights)  # 广播给其他进程自己的更新后参数
    else:
        receive_and_update(fp16_model, rank)  # 接收其他进程广播的更新后参数
```

这样一来: 每个 GPU 所需要的显存量变为: `2*P+14*P/N + 2*A/N`

**Zero-3**

在 Zero-2 的基础上, 每个 GPU 只保留一部分权重参数, 原理是在 Zero-2 的基础上, 在前向或反向的操作时, 任何需要完整参数的操作首先触发一个 hook: 从其他的 `N-1` 个 GPU 上要过来所需要的参数再执行计算

这样一来: 每个 GPU 所需要的显存量变为: `16*P/N + 2*A/N`

**对比 DDP**

在 DDP 的情况里, 每个 GPU 所需要的显存为: `16*P + 2*A/N`, 因此如果参数量 `P` 过大时可能会超出如果单张 GPU 的最大显存, 然而在 ZeRO-3 的情况下, 每个 GPU 所需要的显存量为: `16*P/N + 2*A/N`, 所以只要卡足够多, 总是能运行.

备注: 其实还有一些额外开销如下:

- 每张卡至少 batch size 为 1, activation 需要占一些显存
- 计算时实际上会再增加一些内存开销, 例如: 对于 Zero-3, 在执行一个算子时, 需要有充足的显存放下这个算子所需的完整模型参数
- 内存碎片问题

## 原理深入

参考资料:

- [huggingface 的集成 (2021.1)](https://huggingface.co/blog/zero-deepspeed-fairscale), 文章中有许多参考资料
- [强烈推荐(内含动画演示): deepspeed 作者“官方”博客](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/)


## 食用指南

![https://fairscale.readthedocs.io/en/latest/getting_started.html](https://fairscale.readthedocs.io/en/latest/_images/flowchart.png)


实验数据 (能训练多大的模型):

- [https://huggingface.co/blog/zero-deepspeed-fairscale](https://huggingface.co/blog/zero-deepspeed-fairscale)


## DeepSpeed 使用

本节主要介绍 deepspeed 的使用

## Pytorch FSDP 使用


## FairScale 源码分析

因为 fairscale 代码库比较简单, 因此适合仔细分析. 但使用上还是推荐用 Pytorch FSDP 或者 deepspeed.

## Pytorch FSDP (FairScale) vs DeepSpeed

本节主要解答两个疑问:

- 核心算法是否一致?
- deepspeed 大概还做了很多功能优化, pytorch 可能也做了一些优化, 目前从端到端效果看差距有多少?

[pytorch 的一个 PR](https://github.com/pytorch/pytorch/pull/46750)

## 一些实验数据

这篇 [博客](https://huggingface.co/blog/zero-deepspeed-fairscale) 指出即使在单卡的情况下, deepspeed 也能提供一些改善效果, 并且提到可以使用 24GB 单卡训练 [t5-3b](https://huggingface.co/t5-3b), 具体来说作者做了如下[尝试](https://github.com/huggingface/transformers/issues/8771#issuecomment-759176685)

单卡不使用 deepspeed

```bash
# OOM!
export BS=1
CUDA_VISIBLE_DEVICES=0 ./finetune_trainer.py \
--model_name_or_path t5-3b --n_train 60 --n_val 10 \
--per_device_eval_batch_size $BS --per_device_train_batch_size $BS \
--task translation_en_to_ro --fp16 [...]
```

单卡使用 deepspeed [ZeRO-Offload](https://www.deepspeed.ai/tutorials/zero-offload/)

```bash
# OK
export BS=20
CUDA_VISIBLE_DEVICES=0 deepspeed --num_gpus=1 ./finetune_trainer.py \
--model_name_or_path t5-3b --n_train 60 --n_val 10 \
--per_device_eval_batch_size $BS --per_device_train_batch_size $BS \
--task translation_en_to_ro --fp16 --deepspeed ds_config_1gpu.json [...]
```

`ds_config_1gpu.json` 内容如下:

```json
{
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "hysteresis": 2,
        "min_loss_scale": 1
    },
    "zero_optimization": {
        "stage": 2,
        "allgather_partitions": true,
        "allgather_bucket_size": 2e8,
        "reduce_scatter": true,
        "reduce_bucket_size": 2e8,
        "overlap_comm": true,
        "contiguous_gradients": true,
        "cpu_offload": true
    },
    "optimizer": {
        "type": "Adam",
        "params": {
            "lr": 3e-5,
            "betas": [ 0.9, 0.999 ],
            "eps": 1e-8,
            "weight_decay": 3e-7
        }
    },
    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": 0,
            "warmup_max_lr": 3e-5,
            "warmup_num_steps": 500
        }
    }
}
```

---
layout: post
title: "(WIP) OpenAI ChatGPT/GPT4 使用"
date: 2023-07-24 10:31:04 +0800
labels: [gpt, openai]
---

## 动机、参考资料、涉及内容

动机

- 梳理 ChatGPT 与 GPT4 的使用
- 为学习 LangChain 等利用大模型做应用做准备

**参考资料**

- openai官网: [https://openai.com/](https://openai.com/)
- openai API 文档: [https://platform.openai.com/docs](https://platform.openai.com/docs)
- **使用示例(公共维护)**: [https://github.com/openai/openai-cookbook](https://github.com/openai/openai-cookbook)
- **使用示例教程(公共维护)**: [https://cookbook.openai.com/](https://cookbook.openai.com/)
- openai官方 Python API 封装仓库: [https://github.com/openai/openai-python](https://github.com/openai/openai-python)
- chatml: [https://github.com/openai/openai-python/blob/main/chatml.md](https://github.com/openai/openai-python/blob/main/chatml.md), 备注: 这个[提交](https://github.com/openai/openai-python/commit/08b8179a6b3e46ca8eb117f819cc6563ae74e27d)已移除
- tiktoken 仓库: [https://github.com/openai/tiktoken](https://github.com/openai/tiktoken)
- token 数量估算网页: [https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)


涉及内容

- OpenAI 账号申请
- gpt3.5/gpt4 的网页版使用及 API 调用
- gpt3.5/gpt4 模型版本及调用量约束等
- 代理相关的网络知识简单理解(可能会误解)

## 流程梳理

- 网页对话机器人(ChatGPT): [https://chat.openai.com/chat](https://chat.openai.com/chat)
- API 调用:

注册 OpenAI 账号:
- 注册过程中需要绑定一个手机号, 会通过手机验证码来验证
- 注册成功后会送 5 美元 (无论是否绑定银行卡), 注意 5 美元额度会有过期时间
- 如果需要充值, 则需要绑定银行卡

ChatGPT的使用及收费方式如下(截至至2023/07/24):
- 前置条件: 注册 OpenAI 账号
- 使用方式: 通过网页对话框的方式进行对话
- 收费方式:
  - 不充值: 可以使用 GPT3.5 (暂不确定究竟是哪个模型)
  - 充值【待确认】: 每月20美元, 可以使用 GPT4 (暂不确定究竟是哪个模型), 可以使用插件?

API 调用的使用及收费方式如下:
- 前置条件: 注册 OpenAI 账号, 如果注册后不绑定银行卡, 则只能使用赠送的 5 美元额度
- 使用方式: 参考 API 文档, 可以直接构造 HTTP 请求进行调用, 也可以使用 OpenAI 官方封装的 python 包进行调用
- 收费方式: 按输入输出 token 数计费, 优先使用赠送的 5 美元额度. token 消耗量获取方式有几种
  - 可以在账号页面查看费用, 大致估算总体使用量
  - API 响应参数里会包含 token 数信息
  - 可以使用这个网页或者 tiktoken 包进行计算确认

## OpenAI 账号相关


## 网页版对话

略

## API

API官方文档:

- [https://platform.openai.com/](https://platform.openai.com/)

设置代理:

```python
# 方法1
import os
os.environ["http_proxy"] = "http://127.0.0.1:7890"
os.environ["https_proxy"] = "http://127.0.0.1:7890"

# 方法2
import openai
openai.proxy = "http://127.0.0.1:7890"
```

设置 API KEY:

```python
# 方法1
import os
os.environ["OPENAI_API_KEY"] = "sk-xxxx"

# 方法2
import openai
openai.api_key = "sk-xxxx"
```

### Raw HTTP


下面的例子演示了 `stream=True`, 本质上是打开了 `openai.Completion.create` 的细节, 仅供理解

```python
import openai
import os
openai.api_key = "sk-xxx"

kwargs = {
    "prompt": "1+1",
    "model": "text-davinci-003",
    "max_tokens": 1965,
    "temperature": 1.0,
    "top_p": 1.0,
    "n": 3,
    "stream": True,
    "stop": [
        "\n20",
        "20.",
        "20."
    ],
    "presence_penalty": 0.0,
    "frequency_penalty": 0.0,
    "suffix": None,
    "logprobs": 5,
    "echo": True,
    "logit_bias": {
        "50256": -100
    }
}
# 这里用了 python 的 name mangling 来调用双下划线开头的方法, 非常规方式
(
    deployment_id,
    engine,
    timeout,
    stream,
    headers,
    request_timeout,
    typed_api_type,
    requestor,
    url,
    params,
) = openai.Completion._EngineAPIResource__prepare_create_request(**kwargs)

response, _, api_key = requestor.request(
    "post",
    url,
    params=params,  # 在这个例子中, params 和最开始设置的 kwargs 完全一致
    headers=headers,
    stream=stream,
    request_id=None,
    request_timeout=request_timeout,
)
# response 是一个生成器: generator
lines = [line for line in response]

# lines[0].data 是一个字典, 在 openai.Completion.create 中, 实际上还会进一步封装为 OpenAIObject
lines[0].data
```

### openai-python

```python
import openai
import os

openai.proxy = "http://127.0.0.1:7890"
openai.api_key = "sk-xxxx"

completion = openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"}
  ]
)

print(completion.choices[0].message)
print()
print(completion)  # json.loads(str(completion)) 似乎更好?
# completion 是 openai.openai_object.OpenAIObject 对象, 重载了 __repr__ 

completion.to_dict_recursive()  # 转化为字典
```

```
<OpenAIObject at 0x151ffd04d08> JSON: {
  "role": "assistant",
  "content": "Hello! How can I assist you today?"
}

<OpenAIObject chat.completion id=chatcmpl-7ffC8bop9PLLFxkEkGK0oEFFRLKQL at 0x151ffd046a8> JSON: {
  "id": "chatcmpl-7ffC8bop9PLLFxkEkGK0oEFFRLKQL",
  "object": "chat.completion",
  "created": 1690164156,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I assist you today?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 19,
    "completion_tokens": 9,
    "total_tokens": 28
  }
}
```

这里分析一下上面的代码经过“解封装”后实际的执行内容为

```python
import requests
MAX_CONNECTION_RETRIES = 2

proxy = "http://127.0.0.1:7890"
s = requests.Session()
proxies = {"http": proxy, "https": proxy}
if proxies:
    s.proxies = proxies
s.mount(
    "https://",
    requests.adapters.HTTPAdapter(max_retries=MAX_CONNECTION_RETRIES),
)

abs_url = 'https://api.openai.com/v1/chat/completions'
api_key = "sk-sggs"

# openai/api_requestor.py:APIRequestor:request_headers
headers = {
    # lang_version 是 python 版本号: platform.python_version()
    # platform 是系统版本号: platform.platform()
    # uname 是机器信息, 去除了node信息
    # 其余均是写死的参数
    # uname=" ".join(v for k, v in platform.uname()._asdict().items() if k != "node")
    # platform.uname() 包含6条信息:
    # 'system': "Windows"         # 系统信息,
    # 'node': "DESKTOP-XXXX"      # 计算机的网络名称(Win10可以设置->重命名电脑)
    # 'release': '10',            # 大版本号
    # 'version': '10.0.22621',    # 详细版本号
    # 'machine': 'AMD64',         # 芯片型号
    # 'processor': 'Intel64 Family 6 Model 142 Stepping 10, GenuineIntel'  # 详细型号
    'X-OpenAI-Client-User-Agent': '{"bindings_version": "0.27.8", "httplib": "requests", "lang": "python", "lang_version": "3.7.7", "platform": "Windows-10-10.0.22621-SP0", "publisher": "openai", "uname": "Windows 10 10.0.22621 AMD64 Intel64 Family 6 Model 142 Stepping 10, GenuineIntel"}',
    # 0.27.8 是 python-openai 的版本号, 定义于: openai/version.py:VERSION
    'User-Agent': 'OpenAI/v1 PythonBindings/0.27.8',
    'Authorization': f'Bearer {api_key}', 
    'Content-Type': 'application/json'，
    # 这些在上面例子中没有
    # "OpenAI-Organization": ""
    # "OpenAI-Version"
},

data = b'{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Hello!"}]}'


result = s.request(
    "POST",
    abs_url,
    headers=headers,
    data=data,
    files=None,
    stream=False,
    timeout=request_timeout if request_timeout else TIMEOUT_SECS,  # 600
    proxies={},
    )

# body (bytes): result.content
data = result.json()
# data:
# {
#     'id': 'chatcmpl-7fknMajmdyXElkaWO5nGZZtnCfT4f',
#     'object': 'chat.completion',
#     'created': 1690185684,
#     'model': 'gpt-3.5-turbo-0613',  # 注意调用时用的是gpt-3.5-turbo,说明它实际指向0613版本
#     'choices': [
#         {
#             'index': 0,
#             'message': {'role': 'assistant', 'content': 'Hello! How can I assist you today?'},
#             'finish_reason': 'stop'
#         }
#     ],
#     'usage': {'prompt_tokens': 19, 'completion_tokens': 9, 'total_tokens': 28}
# }

response_header = result.header
# response_header:
# {
#     'Date': 'Mon, 24 Jul 2023 08:01:25 GMT',
#     'Content-Type': 'application/json',
#     'Transfer-Encoding': 'chunked',
#     'Connection': 'keep-alive',
#     'access-control-allow-origin': '*',
#     'Cache-Control': 'no-cache, must-revalidate',
#     'openai-model': 'gpt-3.5-turbo-0613',
#     'openai-organization': 'user-8osqpz0rjgwewdswfrt4gxxg',
#     'openai-processing-ms': '865',
#     'openai-version': '2020-10-01',
#     'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '200',
#     'x-ratelimit-limit-tokens': '40000',
#     'x-ratelimit-remaining-requests': '21',
#     'x-ratelimit-remaining-tokens': '39973',
#     'x-ratelimit-reset-requests': '21h26m17.041s',
#     'x-ratelimit-reset-tokens': '40ms',
#     'x-request-id': '087e715601dc95810344c235a963f543',
#     'CF-Cache-Status': 'DYNAMIC',
#     'Server': 'cloudflare',
#     'CF-RAY': '7ebaa2911a9e2ac3-LAX',
#     'Content-Encoding': 'gzip',
#     'alt-svc': 'h3=":443"; ma=86400'
# }

response = openai.openai_response.OpenAIResponse(data, response_header)
completion = openai.util.convert_to_openai_object(response, api_key, ...)
```


### token 数量

此处的记录可能会发生变化, 最准确的是接口返回显示的 token 数.

官方解释:
- chatml: [https://github.com/openai/openai-python/blob/main/chatml.md](https://github.com/openai/openai-python/blob/main/chatml.md)
- 官方在线计算: [https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)

其他参考:

- openai-cookbook
  - [https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb)
  - [https://github.com/openai/openai-cookbook/blob/5e050080abf3b5bbed340d8d6e9b812dbe3a00e8/examples/How_to_count_tokens_with_tiktoken.ipynb](https://github.com/openai/openai-cookbook/blob/5e050080abf3b5bbed340d8d6e9b812dbe3a00e8/examples/How_to_count_tokens_with_tiktoken.ipynb)
- 博客及讨论
  - 一篇2023/07/23发布的博客: [https://hmarr.com/blog/counting-openai-tokens/](https://hmarr.com/blog/counting-openai-tokens/)

## ChatComplete

(2023/11/08 API)

**prompt 部分**
- `messages`: 必选参数, 表示历史对话信息, 格式如下:
  ```python
  message = [
    {"role": "system", "content": "you are gpt4-turbo"},
    {"role": "user", "content": "1+1=?"},
    {
      "role": "assistant",
      "content": None,
      "tool_calls": [
        {"id": "??", "type": "function", "function": {"name": "add", "argument": '{"a": 1, "b": 1}'}}
      ]  # type 目前仅支持 function, 整条信息表示模型给出的需要调用的函数参数
    },
  ]
  ```
**模型选择**
- `model`: 必选参数
**生成质量调节参数**
- `seed`: 随机数种子, 可以与返回参数 `system_fingerprint` 进一步确认可复现性
- `frequency_penalty`: 浮点数, 默认值为 0, 取值范围为 `[-2.0, 2.0]`, `frequency_penalty` 大于 0 则降低已经出现的 token 的生成概率
- `presence_penalty`: 浮点数, 默认值为 0, 取值范围为 `[-2.0, 2.0]`, `presence_penalty` 大于 0 表示会提升没有出现的 token 的生成概率
- `logit_bias`: 字典, 默认为 `None`, 键是 `token_id`, 值是 `bias`, `bias` 小于 0, 表示降低该 `token_id` 出现的次数, `bias`一般设置在 `[-1, 1]`, 如果将它设置为 `-100`, 那么基本上表示永远不会生成这个 `token_id` 了, 参考[alpaca的例子](https://github.com/tatsu-lab/stanford_alpaca/blob/main/generate_instruction.py#172)
  ```python
  logit_bias = {"50256": -100}
  ```
- `temperature`: 浮点数, 默认值为 0, 取值范围为 `[0, 2]`, `temperature` 越大表示每个 step 的 token 之间的概率差异会变得越小, 表现的更随机
- `top_p`: 浮点数, 默认值为 1, 取值范围为 `[0, 1]`, 表示采样范围只在最大概率累积和在 `top_p` 的范围内选取, 因此 `top_p` 越大, 表现的更随机, **官方推荐只修改 `temperature` 和 `top_p` 中的一个, 不要同时修改**
- `max_token`: 整数, 最大 token 数, 指**输入+输出** token 总数
- `stop`: 字符串或字符串数组或 `None`, 至多可以设置 **4** 组结束字符串, 参考[alpaca例子](https://github.com/tatsu-lab/stanford_alpaca/blob/main/generate_instruction.py#164)
  ```python
  stop=["\n20", "20.", "20."]  # 表示知道生成了这些字符串就停止生成, 注意返回结果不包含这些结束的字符串
  # 例如本来的生成结果应该是 "19. 20.", 那么使用 stop 后, 结果将变成 "19. "
  ```
- `response_format`: 字典, 例子如下, 取值可以是 `text` (默认值) 或 `json_object`
  ```python
  response_format = {"type": "json_object"}
  ```
**工具**
- `tools`: 描述可以使用的工具
- `tool_choice`: 本次调用只允许使用哪些工具
**其他**
- `n`: 生成的回答数量
- `stream`: 布尔类型, 默认为 `False`, 是否流式生成, 具体看后面的例子

## 潘多拉

项目地址: [https://github.com/pengzhile/pandora.git](https://github.com/pengzhile/pandora.git)

使用此项目将网页版 ChatGPT 功能转化为使用接口调用 (原理是模拟网页版浏览器的行为). 因此, 由于 ChatGPT 网页版可以免费使用 gpt-3.5-turbo, 所以相当于免费的 API 接口.

## 附录: OpenAI

**关注点 1: OpenAI 官网**

[https://openai.com/](https://openai.com/)

官网(2023/07/25)包含了如下入口:

```
Research  # 可以从这里看 OpenAI 发的文章
Product   # 产品介绍, 一般是一篇产品介绍文章
  - ChatGPT
  - GPT-4
  - DALL·E 2
  - API data privacy
  - Pricing  # 售价
Developer  # 开发者文档, 即本文前面涉及的内容
Safety     # 未知, 大概是 OpenAI 未来计划的重要方向
Company
  - Blog   # 博客, 这个也可以时常关注
  - ...
Log in
Sign up
```

![](../assets/figures/openai/openai-website.png)

关于 OpenAI 的账号与收费问题 (Log in 入口)

![](../assets/figures/openai/login.png)

可以看到这里一共有三个入口:
- ChatGPT: 一个对话机器人窗口, gpt-3.5-turbo 免费使用, 每月 20 美元付费版可以使用 GPT4 以及插件功能, 功能更新相对频繁 (例如最新发布的代码解释器功能).
- DALL·E (这个中间的点号是 `middle dot (U+0087)`): 图像生成一个产品, 没有仔细探索过玩法.
- API: 各个模型的 API 接口, 语言模型一般按 token 收费, 图像生成模型按分辨率及张数收费, ... 似乎[playground](https://platform.openai.com/playground)是不收费的

三个入口的账号均共享 (OpenAI 账号, 即注册时的邮箱), 但收费以及免费额度各自独立.

**关注点 2: OpenAI 官方 GitHub 组织**

[https://github.com/openai](https://github.com/openai)

- evals: [https://github.com/openai/evals](https://github.com/openai/evals), 似乎是一个评价 LLM 的仓库, 应该很有参考意义, 但国内各种公众号啥的似乎宣传的不多?
- openai-python: [https://github.com/openai/openai-python](https://github.com/openai/openai-python), API 调用的封装包, 个人觉得国内环境下也许避免使用?(使用这个封装的包在发请求时可能会暴露一些机器信息, 引起封号?)
- openai-cookbook: [https://github.com/openai/openai-cookbook](https://github.com/openai/openai-cookbook), 一些 API 调用的样例, 由社区维护, 可以参考.
- triton: [https://github.com/openai/triton](https://github.com/openai/triton)
- ...

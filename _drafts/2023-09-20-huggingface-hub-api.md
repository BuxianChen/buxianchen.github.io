---
layout: post
title: "(WIP) ğŸ¤— Hub API"
date: 2023-09-20 07:20:24 +0800
labels: [huggingface, hub]
---

## åŠ¨æœºã€å‚è€ƒèµ„æ–™ã€æ¶‰åŠå†…å®¹

åŠ¨æœº

- ğŸ¤— Transformers `AutoModel.from_pretrained` è¿‡ç¨‹ä¸­çš„ä¸‹è½½ä¸ç¼“å­˜æœºåˆ¶: æ¨¡å‹è„šæœ¬ä¸‹è½½åæ€ä¹ˆåŠ¨æ€åŠ è½½, è„šæœ¬æ–‡ä»¶æ€ä¹ˆç¼“å­˜, æ¨¡å‹æ–‡ä»¶æ€ä¹ˆç¼“å­˜. æå‰ä½¿ç”¨ git clone å°† Hub ä¸­çš„æ¨¡å‹åº“ä¸‹è½½åå†æ‰§è¡Œ `from_pretrained`, è·Ÿä¸æ‰‹åŠ¨ git clone ä¹‹é—´çš„å·®åˆ«åœ¨å“ª (åœ¨æ–‡ä»¶ç¼“å­˜æ–¹é¢)
- ğŸ¤— Datasets `load_dataset` è¿‡ç¨‹é‡Œä¸‹è½½è„šæœ¬, åŠ¨æ€ import, ä¸‹è½½æ•°æ®, å°†æ•°æ®è½¬åŒ–ä¸º arrow æ ¼å¼çš„å…·ä½“é€»è¾‘
- ğŸ¤— ç¼“å­˜ç›®å½•æœ‰æ²¡æœ‰å¯èƒ½è·Ÿ git clone çš„æ–¹å¼ä¸‹è½½èƒ½åšæŸç§â€œç›¸äº’è½¬æ¢â€
- æ€ä¹ˆåœ¨ ğŸ¤— Hub Python API ä¹‹ä¸Šå¼€å‘æ–°çš„é¡¹ç›®: [https://huggingface.co/docs/huggingface_hub/guides/integrations](https://huggingface.co/docs/huggingface_hub/guides/integrations)
- â€œç©è½¬â€ huggingface æä¾›çš„ Hub æœåŠ¡

æ¶‰åŠå†…å®¹

- ğŸ¤— Hub API
- ğŸ¤— Transformers ä¸­æ€ä¹ˆåˆ©ç”¨ ğŸ¤— Hub API

å‚è€ƒèµ„æ–™

- ğŸ¤— Hub å®˜æ–¹æ–‡æ¡£[https://huggingface.co/docs/huggingface_hub/guides/manage-cache](https://huggingface.co/docs/huggingface_hub/guides/manage-cache)

## Huggingface Hub

æœ¬ç¯‡åšå®¢çš„å†…å®¹å±äº ğŸ¤— çš„åŸºç¡€è®¾æ–½èŒƒç•´, è¿™é‡Œæƒ³å°† Huggingface ä½œä¸ºä¸€ä¸ªäº§å“è€Œè¨€åšä¸€äº›è§£è¯», ä»¥è¯»è€…çš„è®¤çŸ¥èŒƒå›´, Huggingface ç”±è¿™å‡ éƒ¨åˆ†æ„æˆ

- Hub (æœåŠ¡): åŒ…å« Models, Datasets, Spaces, è¿™ä¸‰è€…é¦–å…ˆæ˜¯ä½œä¸º git è¿œç¨‹ä»“åº“å­˜åœ¨çš„, å› æ­¤ ğŸ¤— æä¾›äº†ä¸€ä¸ª Git ä»“åº“çš„æ‰˜ç®¡å¹³å°, è€Œä¸”ç±»ä¼¼äº GitHub, è€Œè¿™ä¸ªå¹³å°è¿˜å…·å¤‡ä¸€äº›é¢å¤–åŠŸèƒ½, ä¾‹å¦‚: æƒé™ç®¡ç†, æ¯ä¸ª Dataset ä»“åº“è¿˜æœ‰æ•°æ®é¢„è§ˆåŠŸèƒ½, æ¯ä¸ª Model ä»“åº“ä¸€èˆ¬éƒ½æœ‰æ¨¡å‹å¡ç‰‡é¡µ, å¸®åŠ©è¯»è€…å¿«é€Ÿä¸Šæ‰‹, Space ä»“åº“è¿˜å…è´¹æä¾›äº†å°†ä»“åº“å†…çš„ä»£ç éƒ¨ç½²çš„åŠŸèƒ½
- è½¯ä»¶ä¸å¼€å‘å·¥å…·: é¦–å…ˆæ˜¯ Hub API, ç„¶åæ˜¯å„ç§ä¸‹æ¸¸åº“, æœ€çŸ¥åçš„æ˜¯ transformers åº“

## Huggingface Hub Python API

### Main API

é€šè¯»å®˜æ–¹æ–‡æ¡£å, æ„Ÿè§‰å¯¹ä¸‹æ¸¸åº“æˆ–è€…å¯¹åŸºäº Huggingface Hub è¿›è¡Œå¼€å‘æ¯”è¾ƒæœ‰ä½œç”¨çš„ API

ä¸¤ç±» API: `Repository`, `HfApi`. æ›´æ¨è `HfApi` æ¥å£.

`HfApi` çš„å¤§è‡´åŸç†å¦‚ä¸‹: 

- å¯¹äºæ–‡ä»¶ä¸Šä¼ æ“ä½œ, ç›´æ¥åˆ©ç”¨æœ¬åœ°çš„å•ä¸ªæ–‡ä»¶æˆ–è€…å•ä¸ªç‰ˆæœ¬å¯¹è¿œç¨‹ä»“åº“å‘é€ HTTP è¯·æ±‚, æœåŠ¡ç«¯ (å³ Huggingface Hub) å¤„ç†è¯·æ±‚ (ä¾‹å¦‚: æ“ä½œè¿œç¨‹ä»“åº“), å› æ­¤æ— éœ€ä¿å­˜å®Œæ•´çš„ git ä»“åº“å¤‡ä»½.
- å¯¹äºä¸‹è½½æ–‡ä»¶æ“ä½œ, è¿™ä¸ªåº“çš„ä½œè€…è®¾è®¡äº†ä¸€ä¸ªç¼“å­˜ç›®å½•ç»“æ„æ¥å¯¹ä¸‹è½½çš„æ–‡ä»¶è¿›è¡Œä¿å­˜, è¿™ç§ç›®å½•ç»“æ„ä¸ä¼ ç»Ÿçš„ git ä»“åº“çš„ `.git` ç›®å½•ç•¥æœ‰ä¸åŒ, ç®—æ˜¯å€Ÿç”¨äº† git ä¸­åº•å±‚çš„ä¸€äº›å†…å®¹è¿›è¡ŒæŒ‰éœ€ç®€åŒ–.

å…·ä½“æ¯”è¾ƒé‡è¦çš„ API å¦‚ä¸‹:

- `create_repo`, `delete_repo`
- `create_branch`, `create_tag`, `delete_branch`, `delete_tag`: è¿œç¨‹åˆ›å»º/åˆ é™¤branch/tag
- `create_commit`, `create_commit_on_pr`: åº•å±‚æ¥å£, ä¸‹é¢å››ä¸ªåº•å±‚éƒ½è°ƒç”¨äº† create_commit æ–¹æ³•, é™¤æ­¤ä¹‹å¤–, `metadata_update` ä¹Ÿä½¿ç”¨äº†æ­¤æ–¹æ³•
- `upload_file`, `upload_folder`, `delete_file`, `delete_folder`
- `hf_hub_download`:
  - å¹¿æ³›ç”¨äº transformers åº“ä¸­å„ç§æ¨¡å‹çš„æƒé‡è½¬æ¢è„šæœ¬ä¸­, ä¾‹å¦‚ `transformers/models/videomae/convert_videomae_to_pytorch.py`
- `snapshot_download`

`Repository` çš„å¤§è‡´åŸç†

ç”±äº

åŸç”Ÿ git å‘½ä»¤



### API List

#### `HfApi`: ä»“åº“æ–‡ä»¶ç›¸å…³

åŒæ—¶é€‚ç”¨äº model/dataset/space

```python
# create_repo

# duplicate_space

# move_repo

# create_tag

# create_branch
# exist_ok é»˜è®¤ä¸º False
create_branch(repo_id, branch="new_branch", revision="from", exist_ok=False)

# create_commit: (è§åç»­)

# create_commits_on_pr: (è§åç»­)

# delete_branch

# delete_file

# delete_folder

# delete_repo

# delete_tag

# metadata_update

# snapshot_download

# hf_hub_download

# super_squash_history

# update_repo_visibility

# upload_file, upload_folder

# huggingface_hub.plan_multi_commits (ä¸æ˜¯HfApiç±»çš„æ–¹æ³•, è€Œæ˜¯å•ç‹¬çš„æ–¹æ³•)
```

#### `HfApi`: discussion, PR ç›¸å…³

åŒæ—¶é€‚ç”¨äº model/dataset/space

```python
# create_discussion
# é»˜è®¤pull_request ä¸º False, è€Œå½“å–å€¼ä¸º True æ—¶, ä¼šåœ¨è¿œç¨‹ä»“åº“å»ºç«‹ç±»ä¼¼refs/pr/6è¿™ç§åˆ†æ”¯å, ç„¶ååˆ›å»ºçš„ discussion ä¼šè¢«æ ‡è®°ä¸º Draft PR, ç½‘é¡µç•Œé¢ä¸Šä¼šæœ‰æ“ä½œæŒ‡å¼•:
# git clone https://huggingface.co/Buxian/test-model
# cd test-model && git fetch origin refs/pr/6:pr/6
# git checkout pr/6
# huggingface-cli login
# git push origin pr/6:refs/pr/6
# åœ¨ç½‘é¡µä¸Šç‚¹æŒ‰é’®å°†PRè½¬æ¢ä¸ºæ­£å¼çŠ¶æ€
# 
# å…·ä½“å¯å‚è€ƒ:
# https://huggingface.co/docs/hub/repositories-pull-requests-discussions
create_discussion(repo_id, title="title", description="content", pull_request=True)

# git clone æ—¶ä¸ä¼š clone refs/pr/6 è¿™ä¸ªåˆ†æ”¯, æ‰§è¡Œgit fetch origin refs/pr/6:xxyyæ—¶, ç›®å½•ç»“æ„ä¼šå¢åŠ ä¸€ä¸ª
# .git/refs/
# â”œâ”€â”€ heads
# â”‚Â Â  â”œâ”€â”€ main  # ä¿å­˜ç€ commit-id
# â”‚Â Â  â””â”€â”€ xxyy  # ä¿å­˜ç€ commit-id


# create_pull_request
# æœ¬è´¨ä¸Š, å°±æ˜¯è°ƒç”¨ create_discussion è®¾å®šå‚æ•° pull_request=True å®ç°çš„
create_pull_request(repo_id, title="title", description="content")


# change_discussion_status
# æ³¨æ„PRä¸Discussionçš„ç¼–å·æ˜¯æ··åœ¨ä¸€èµ·çš„, åºå·ä»1å¼€å§‹, ä¾‹å¦‚å¯èƒ½æ˜¯è¿™æ ·
# https://huggingface.co/Buxian/test-model/discussions/1    PR
# https://huggingface.co/Buxian/test-model/discussions/2    Discussion
# https://huggingface.co/Buxian/test-model/discussions/3    PR
# å¦‚æœçŠ¶æ€æœ¬èº«å°±æ˜¯ closed, é‚£ä¹ˆä¼šæŠ¥é”™
change_discussion_status(repo_id, discussion_num=2, new_status='closed', comment='finish the discussion')

# comment_discussion
comment_discussion(repo_id,  discussion_num=2, comment="add comment")

# edit_discussion_comment

# hidden_discussion_comment

# rename_discussion

# merge_pull_request
```

å¤‡æ³¨: é’ˆå¯¹ PR ç»§ç»­æäº¤ä»£ç [æš‚æ— ](https://huggingface.co/docs/huggingface_hub/guides/community#push-changes-to-a-pull-request)


#### `HfApi`: æŸ¥è¯¢

æœ‰äº›æ˜¯é’ˆå¯¹ç‰¹å®šçš„ repo ç±»å‹, æœ‰äº›æ˜¯é€šç”¨çš„

```python
# dataset_info/model_info/repo_info/space_info

# like, unlike

# list_datasets, list_files_info, list_liked_repos, list_metrics, list_models, list_repo_commits, list_repo_files, list_repo_refs, list_spaces

# file_exists

# get_dataset_tags

# get_discussion_details

# get_full_repo_name

# get_model_tags

# get_repo_discussions

# get_space_runtime

# get_space_variables

# get_token_permission

# repo_exists

# whoami
```

#### `HfApi`: å…¶ä»–

```python
# run_as_future(è¿™ä¸ªå¯ä»¥ç ”ç©¶ä¸‹)

# add_space_secret
# å¢åŠ ä¸€ä¸ªsecretç¯å¢ƒå˜é‡, å¤åˆ¶ç©ºé—´æ—¶ä¸ä¼šè¢«æ‹·è´

# add_space_variable
# å¢åŠ ä¸€ä¸ªå…¬å¼€çš„ç¯å¢ƒå˜é‡, å¤åˆ¶ç©ºé—´æ—¶ä¼šè¢«æ‹·è´

# delete_space_secret

# delete_space_storage

# delete_space_variable

# request_space_hardware, request_space_storage

# restart_space

# set_space_sleep_time

# pause_space
```

#### HfFileSystem

```python
# huggingface_hub.HfFileSystem (ä»…ä»…æ˜¯å¯¹HfApiçš„ä¸€ç‚¹å°è£…)
# pip install pandas huggingface_hub
import pandas as pd
df = pd.read_csv("hf://Buxian/test-model/.gitattributes", sep=" ")
```

#### Inference API

è¿™ä¸ªä¸€èˆ¬é€‚ç”¨äº model ç±»å‹çš„ä»“åº“, æ— éœ€ä»£ç è‡ªåŠ¨éƒ¨ç½²

```python
import json
import requests
API_URL = "https://api-inference.huggingface.co/models/gpt2"
headers = {"Authorization": f"Bearer {token}"}
def query(payload):
    data = json.dumps(payload)
    response = requests.request("POST", API_URL, headers=headers, data=data)
    return json.loads(response.content.decode("utf-8"))
data = query("Can you please let us know more details about your ")
```

æ€ä¹ˆç¡®å®šå®ƒæ˜¯è¯­è¨€æ¨¡å‹? å…¥å‚å‡ºå‚æ€ä¹ˆç¡®å®šçš„å‘¢? å¯èƒ½çš„å› ç´ :

ä»»åŠ¡ç±»å‹ç¡®å®š:

```
# https://huggingface.co/bert-base-uncased/blob/main/config.json
# https://huggingface.co/bert-base-uncased
# é¡µé¢ä¸Š Inference API ä¸Šæ˜¾ç¤ºçš„æ˜¯ Fill-Mask
{
    "architectures": ["BertForMaskedLM"]
}

# https://huggingface.co/internlm/internlm-chat-7b/blob/main/config.json
# https://huggingface.co/internlm/internlm-chat-7b
# é¡µé¢ä¸Š Inference API ä¸Šæ˜¾ç¤ºçš„æ˜¯ Text Generation
{
  "architectures": [
    "InternLMForCausalLM"
  ],
  "auto_map": {
    "AutoConfig": "configuration_internlm.InternLMConfig",
    "AutoModel": "modeling_internlm.InternLMForCausalLM",
    "AutoModelForCausalLM": "modeling_internlm.InternLMForCausalLM"
  },
}
```

ä»»åŠ¡ç±»å‹ä¸è¯·æ±‚å‡ºå…¥å‚å¯¹åº”å…³ç³»: [https://huggingface.co/docs/api-inference/detailed_parameters](https://huggingface.co/docs/api-inference/detailed_parameters)

#### Inference Endpoint

è¿™ç§é€‚ç”¨äº Space ç±»å‹çš„ä»“åº“, å¯å®Œå…¨æ§åˆ¶éƒ¨ç½²çš„æœåŠ¡


### Cheetsheet

```python
from huggingface_hub import login, create_repo
token = "hf_xxxyyy"
login(token)
create_repo("Buxian/test-model")
```


### Upload


#### `upload_file`

```python
def upload_file(
  path_or_fileobj,
  path_in_repo,
  repo_id,
  token=None,
  repo_type=None,  # åªèƒ½æ˜¯ model, dataset, space, é»˜è®¤æ˜¯ model
  revision=None,
  commit_message=None,
  commit_description=None,
  create_pr=None,
  parent_commit=None,
  run_as_future=False
):
  pass

# å¸Œæœ›å¯¹è¿œç¨‹ä»“åº“çš„ç‰¹å®šåˆ†æ”¯æäº¤ä¸€ä¸ªã€å¢åŠ ä¸€ä¸ªæ–‡ä»¶çš„æäº¤ã€‘: åˆ†æ”¯å¿…é¡»å·²å­˜åœ¨, æœ‰å¯èƒ½ä¼šäº§ç”Ÿä¸€ä¸ªâ€œç©ºæäº¤â€
upload_file("hello.c", "c/hello.c", "Buxian/test-model", revision="main", commit_message="add hello.c")

# å»ºç«‹ä¸€ä¸ª PR è¯·æ±‚:
# æ–¹å¼1: åŸºäºè¿œç¨‹åˆ†æ”¯åå»ºç«‹: åœ¨mainåˆ†æ”¯çš„åŸºç¡€ä¸Šåˆ›å»ºä¸€ä¸ªå¢åŠ ä¸€ä¸ªæ–‡ä»¶çš„æäº¤, ä»¥æ­¤å»ºç«‹PRè¯·æ±‚
upload_file(
  path_or_fileobj="hello.c", path_in_repo="c/hello.c", repo_id="Buxian/test-model", commit_message="(pr branch) add hello.c",
  create_pr=True, revision="main"
)

# æ–¹å¼2: åŸºäºç‰¹å®šçš„æäº¤å»ºç«‹: åœ¨parent_commitçš„åŸºç¡€ä¸Š, å»ºç«‹ä¸€ä¸ªæäº¤, å¹¶è¯·æ±‚åˆå¹¶è‡³main
upload_file(
  path_or_fileobj="hello.c", path_in_repo="c/hello.c", repo_id="Buxian/test-model", commit_message="(pr parent commit) add hello.c",
  create_pr=True, revision="main", parent_commit="ea9c8da4cda73fb6456cef85627d789394354a29"
)
```


å¤‡æ³¨: git ä¸­çš„ commit message ä¸ commit description æœ‰ä»€ä¹ˆä¸åŒ: æœ¬è´¨ä¸Šå¯ä»¥è®¤ä¸º commit message æ˜¯æ ‡é¢˜, commit description æ˜¯è¯¦ç»†å†…å®¹, è¿™é‡Œæœ‰ä¸€ç¯‡å…³äºå†™å¥½ commit message çš„[åšå®¢](https://cbea.ms/git-commit/)

ä½¿ç”¨åŸç”Ÿçš„ git cli å·¥å…·å¯ä»¥ç”¨è¿™ä¸¤ç§æ–¹å¼åŒºåˆ† commit message å’Œ commit description.
```bash
git commit -m "This is Title" -m "This is Description"
git commit  # åœ¨å¼¹å‡ºçš„æ–‡æœ¬ç¼–è¾‘å™¨ä¸­, ç¬¬ä¸€è¡Œæ˜¯ commit message, å…¶ä½™å‡ä¸º commit description
```

åœ¨ GitHub/GitLab çš„ç½‘é¡µç•Œé¢ä¸Š, ä¸€èˆ¬åœ¨æµè§ˆæ–‡ä»¶å¤¹æ—¶, æ˜¾ç¤ºçš„æ˜¯ commit message, è€ŒæŸ¥çœ‹æŸä¸ªç‰ˆæœ¬çš„è¯¦ç»†ä¿¡æ¯æ—¶å¯ä»¥çœ‹åˆ° commit description.

å¤‡æ³¨: å¦‚æœåœ¨æ²¡æœ‰ä¿®æ”¹æ–‡ä»¶çš„æƒ…å†µä¸‹ä½¿ç”¨ `upload_file` æ—¶, ä»ç„¶ä¼šä¸ºè¿œç«¯ä»“åº“å¢åŠ ä¸€ä¸ªâ€œæ²¡æœ‰å®é™…æ„ä¹‰â€çš„æäº¤, ä½œç”¨ç­‰æ•ˆäº
```bash
git commit --allow-empty -m "no file changed"
```

å¤‡æ³¨: åœ¨ä½¿ç”¨ `create_pr=True` çš„æ—¶å€™äº§ç”Ÿäº†ä¸¤ä¸ªç–‘é—®:
- æ€ä¹ˆæŒç»­ä¸ºä¸€ä¸ª pr å¢åŠ æäº¤
- æ€ä¹ˆè§£å†³ pr ä¸éœ€è¦åˆå¹¶çš„åˆ†æ”¯çš„å†²çª (ä¼¼ä¹åªæœ‰ç”¨ Repository API æ¥åš? å¯èƒ½ä¹Ÿåšä¸äº†, åªèƒ½ç”¨ git CLI)


**æºç **

```python
# create_commit æºç :

# step 1: å¾…ä¸Šä¼ æ–‡ä»¶å“ˆå¸Œå€¼è®¡ç®—(sha256, è€Œé git oid)

# step 2: fetch_upload_modes

# library_name: mylib, library_version: v1.0
headers = {
  "user-agent": "mylib/v1.0; hf_hub/0.18.0.dev0; python/3.9.10; torch/2.0.1;",
  "authorization": "Bearer hf_cdfjjfjfj",
}

json = {
  "files": [
    {
      "path": op.path_in_repo,
      "sample": base64.b64encode(op.upload_info.sample).decode("ascii"),  # sample æ˜¯å°‘é‡å­—èŠ‚
      "size": op.upload_info.size,
      "sha": op.upload_info.sha256.hex()
    }
    for op in chunk
  ]
}

preupload_info = get_session().post(
  f"{endpoint}/api/{repo_type}s/{repo_id}/preupload/{revision}",
  json=json,
  headers=headers,
  params={"create_pr": "1"} if create_pr else None
).json()


```

#### `upload_folder`

ç±»ä¼¼äº `upload_file`, ä¸èµ˜è¿°å¤ªå¤š

#### `create_commit` / `create_commit_on_pr`

`create_commit` æ˜¯ `upload_folder` ä¸ `upload_file` åœ¨å†…éƒ¨è°ƒç”¨çš„æ–¹æ³•. æœ¬å°èŠ‚å®è´¨ä¸Šæ˜¯å¯¹ `uploader_folder` çš„åŸç†/æºç è¿›è¡Œè§£æ, æœ¬è´¨ä¸Š: æœ¬åœ°å‘é€ HTTP è¯·æ±‚ç»™ Hub æœåŠ¡å™¨, æœ¬åœ°å·²ç»æ‰“åŒ…äº†åˆ›å»ºçš„ commit ç›¸å…³çš„ä¿¡æ¯ä»¥åŠä¸Šä¼ æ–‡ä»¶, Hub æœåŠ¡å™¨æ¥æ”¶åˆ°è¯·æ±‚åæ›´æ–°è¿œç«¯ä»“åº“


### Download

æ ¹æ®å®˜æ–¹æ–‡æ¡£[https://huggingface.co/docs/huggingface_hub/guides/download](https://huggingface.co/docs/huggingface_hub/guides/download) ä¸­æè¿°çš„, æœ€ä¸»è¦çš„å°±æ˜¯è¿™ä¸¤ä¸ªå‡½æ•°

- `hf_hub_download`: ä¸‹è½½å•ä¸ªæ–‡ä»¶
- `snapshot_download`: ä¸‹è½½ä¸€ä¸ªç‰ˆæœ¬çš„å¤šä¸ªæ–‡ä»¶

#### `hf_hub_download`

```python
from huggingface_hub import hf_hub_download
hf_hub_download(repo_id="huggingface/label-files", filename="kinetics400-id2label.json", repo_type="dataset")
```

æŒ‰ç…§ç¼“å­˜ç›®å½•ç»“æ„ä¸‹è½½å•ä¸ªæ–‡ä»¶
```
~/.cache/huggingface/hub/
â”œâ”€â”€ datasets--huggingface--label-files
â”‚Â Â  â”œâ”€â”€ blobs
â”‚Â Â  â”‚Â Â  â””â”€â”€ 32cb9c6d5f5fe544580663ec11808e15c0ae2080
â”‚Â Â  â”œâ”€â”€ refs
â”‚Â Â  â”‚Â Â  â””â”€â”€ main
â”‚Â Â  â””â”€â”€ snapshots
â”‚Â Â      â””â”€â”€ 9462154cba99c3c7f569d3b4f1ba26614afd558c
â”‚Â Â          â””â”€â”€ kinetics400-id2label.json -> ../../blobs/32cb9c6d5f5fe544580663ec11808e15c0ae2080
â””â”€â”€ version.txt
```

```python
@validate_hf_hub_args
def hf_hub_download(...)
```

`validate_hf_hub_args` è£…é¥°å™¨ç”¨äºæ£€æŸ¥è¢«è£…é¥°çš„å‡½æ•°çš„å…¥å‚:

- å¦‚æœ `repo_id`, `from_id`, `to_id` æ˜¯å‡½æ•°çš„å…¥å‚, æ£€æŸ¥å…¶ä¼ å…¥çš„å®å‚çš„å€¼æ˜¯æ»¡è¶³æ¡ä»¶çš„å­—ç¬¦ä¸²: è‡³å¤šåªåŒ…å«ä¸€ä¸ª `/`, ä¸åŒ…å« `--` ä¸ `__`, ä»¥ `/` åˆ†éš”çš„ä¸¤éƒ¨åˆ†åªèƒ½ç”± æ•°å­—/å­—æ¯/`.-_` æ„æˆ, ä¸èƒ½ä»¥ `.git` ç»“å°¾. ç®€å•æ¥è¯´å°±æ˜¯æ£€æŸ¥å…¥å‚æ˜¯ä¸€ä¸ªåˆæ³•çš„ repo_id
- å…³äº `use_auth_token` ä¸ `token` å‚æ•°çš„å…¼å®¹æ€§æ£€æŸ¥, å…·ä½“ç»†èŠ‚ä¸æ·±ç©¶, åªéœ€è®°ä½ä¸€ç‚¹, æ—§ç‰ˆæœ¬çš„å‚æ•°ä¸€èˆ¬æ˜¯ `use_auth_token`, æœªæ¥ç‰ˆæœ¬æœ€ç»ˆè®¡åˆ’å¼ƒç”¨è¿™ä¸ªå‚æ•°, ä½¿ç”¨ `token` ä½œä¸ºå…¥å‚


### ç¼“å­˜ç›®å½•

å‚è€ƒå®˜æ–¹æ–‡æ¡£: [https://huggingface.co/docs/huggingface_hub/guides/manage-cache](https://huggingface.co/docs/huggingface_hub/guides/manage-cache)

åœ¨å®˜æ–¹æ–‡æ¡£ä¸­, æœ‰ä¸¤ä¸ªæœ¯è¯­:

- cache: ä» huggingface.co ä¸‹è½½çš„æ–‡ä»¶, ç¼“å­˜åœ°å€é»˜è®¤åœ¨ `~/.cache/huggingface/hub`
- asset (asset cache): ä¸€äº›ä¸‹æ¸¸åº“é™¤äº†ä¸‹è½½åŸå§‹æ–‡ä»¶ä¹‹å¤–, å¯èƒ½è¿˜éœ€è¦åšäº›åå¤„ç†, ä¾‹å¦‚: ã€å¾…ç†æ¸…ã€‘
  - ğŸ¤— Dataset çš„ `load_dataset` æ–¹æ³•ä¸‹è½½è„šæœ¬å, ä¼šæ‰§è¡Œè„šæœ¬å°†æ•°æ®ä»¥ arrow çš„æ ¼å¼é»˜è®¤ç¼“å­˜åœ¨ `~/.cache/huggingface/dataset` ç›®å½•ä¸‹
  - ğŸ¤— Transformer ä½¿ç”¨ `AutoConfig.from_pretrained(trust_remote_code=True)` æ—¶, ä¼šå°† Hub ä¸­çš„è„šæœ¬ç¼“å­˜åœ¨ `~/.cache/huggingface/modules/transformers_modules` ç›®å½•ä¸‹

ä» Huggingface å„ä¸ªé¡¹ç›®ä¹‹é—´çš„ç»„ç»‡æ–¹å¼æ¥è€ƒè™‘é—®é¢˜çš„è¯, Huggingface Hub åº“å…¶æœ¬èº«çš„å®šä½, ä»¥åŠä¸ä¸‹æ¸¸åº“ (ä¾‹å¦‚: Huggingface transformers, huggingface datasets) çš„å…³ç³», åœ¨ç¼“å­˜ç›®å½•çš„é—®é¢˜ä¸Š, ä¸»è¦æ˜¯åšè¿™å‡ ä»¶äº‹

- æä¾›ä» Hub ä¸‹è½½æ–‡ä»¶çš„ API, ä¸‹æ¸¸åº“å¯å¤ç”¨è¿™äº›æ¥å£


```python
from huggingface_hub import cached_assets_path

assets_path = cached_assets_path(library_name="datasets", namespace="SQuAD", subfolder="download")
something_path = assets_path / "something.json" # Do anything you like in your assets folder !
```

æ³¨æ„: ä¾‹å¦‚ `datasets` åº“å°±æ²¡æœ‰ä½¿ç”¨ cached_assets_path æ¥ç¡®å®šé»˜è®¤çš„ç¼“å­˜ç›®å½•, è€Œæ˜¯ç”¨ `~/.cache/huggingface/dataset`


cache æ–‡ä»¶ç»“æ„ç›®å½•, ä¹Ÿå¯å‚è€ƒå®˜æ–¹ç¤ºä¾‹: [https://huggingface.co/docs/huggingface_hub/guides/manage-cache#in-practice](https://huggingface.co/docs/huggingface_hub/guides/manage-cache#in-practice)
```
~/.cache/huggingface/hub
  - models--username--projectname/
    - refs/                  # åŒ…å«çš„æ˜¯åˆ†æ”¯åå¯¹åº”çš„æœ€æ–° commit-id
      - main                 # æ–‡æœ¬æ–‡ä»¶, å®é™…å­˜å‚¨çš„æ˜¯å¯¹åº”çš„ commit-id, ä¾‹å¦‚: eee
      - dev                  # æ–‡æœ¬æ–‡ä»¶, å®é™…å­˜å‚¨çš„æ˜¯å¯¹åº”çš„ commit-id, ä¾‹å¦‚: fff
    - blobs/
      - aaaaaaaaaaaaaaaaaaaaaaaaa
      - bbbbbbbbbbbbbbbbbbbbbbbbb
      - ccccccccccccccccccccccccc
      - ddddddddddddddddddddddddd
    - snapshots/  # å‡è®¾devåˆ†æ”¯å†å²ç‰ˆæœ¬æœ‰fffå’Œggg
      - eee/
        - pytorch_model.bin  # è½¯è¿æ¥è‡³ blobs/aaaaaaaaaaaaaaaaaaaaaaaaa
        - README.md          # è½¯è¿æ¥è‡³ blobs/bbbbbbbbbbbbbbbbbbbbbbbbb
      - fff/
        - pytorch_model.bin  # è½¯è¿æ¥è‡³ blobs/aaaaaaaaaaaaaaaaaaaaaaaaa
        - README.md          # è½¯è¿æ¥è‡³ blobs/ccccccccccccccccccccccccc
      - ggg/
        - README.md
```

asset æ–‡ä»¶ç»“æ„ç¤ºä¾‹: [https://huggingface.co/docs/huggingface_hub/guides/manage-cache#assets-in-practice](https://huggingface.co/docs/huggingface_hub/guides/manage-cache#assets-in-practice)

```
~/.cache/huggingface
    assets/
        â””â”€â”€ datasets/
        â”‚   â”œâ”€â”€ SQuAD/
        â”‚   â”‚   â”œâ”€â”€ downloaded/
        â”‚   â”‚   â”œâ”€â”€ extracted/
        â”‚   â”‚   â””â”€â”€ processed/
        â”‚   â”œâ”€â”€ Helsinki-NLP--tatoeba_mt/
        â”‚       â”œâ”€â”€ downloaded/
        â”‚       â”œâ”€â”€ extracted/
        â”‚       â””â”€â”€ processed/
        â””â”€â”€ transformers/
            â”œâ”€â”€ default/
            â”‚   â”œâ”€â”€ something/
            â”œâ”€â”€ bert-base-cased/
            â”‚   â”œâ”€â”€ default/
            â”‚   â””â”€â”€ training/
    hub/
    â””â”€â”€ models--julien-c--EsperBERTo-small/
        â”œâ”€â”€ blobs/
        â”‚   â”œâ”€â”€ (...)
        â”‚   â”œâ”€â”€ (...)
        â”œâ”€â”€ refs/
        â”‚   â””â”€â”€ (...)
        â””â”€â”€ [ 128]  snapshots/
            â”œâ”€â”€ 2439f60ef33a0d46d85da5001d52aeda5b00ce9f/
            â”‚   â”œâ”€â”€ (...)
            â””â”€â”€ bbc77c8132af1cc5cf678da3f1ddf2de43606d48/
                â””â”€â”€ (...)
    datasets/
    modules/
```

### å¤§æ–‡ä»¶å¤„ç†


```python
# huggingface-cli lfs-enable-largefiles
# åº•å±‚å®é™…å¹²çš„äº‹:
lfs_config = "git config lfs.customtransfer.multipart"
LFS_MULTIPART_UPLOAD_COMMAND = "lfs-multipart-upload"
run_subprocess(f"{lfs_config}.path huggingface-cli", self.local_dir)
run_subprocess(
    f"{lfs_config}.args {LFS_MULTIPART_UPLOAD_COMMAND}",
    self.local_dir,
)

git config lfs.customtransfer.multipart.path huggingface-cli <local_dir>
git config lfs.customtransfer.multipart.args lfs-multipart-upload <local_dir>
```


## ğŸ¤— Transformers


### `transformers.utils.hub.try_to_load_from_cache`

è¾“å…¥: ğŸ¤— Hub çš„ repo-id; repo çš„ commit-id/åˆ†æ”¯å; æ–‡ä»¶å
è¾“å‡º: æ£€æŸ¥æœ¬åœ°çš„ç¼“å­˜ç›®å½•ä¸­æ˜¯å¦æœ‰æ»¡è¶³è¾“å…¥æ¡ä»¶çš„ç¼“å­˜, å¦‚æœæœ‰åˆ™è¿”å›å®é™…è·¯å¾„, æ²¡æœ‰åˆ™è¿”å›Noneæˆ–ç‰¹æ®Šå€¼


```python
try_to_load_from_cache("username/projectname", "README.md", revision="dev")
# è¿”å›ç»“æœæ˜¯: "~/.cache/huggingface/models--username--projectname/snapshots/dev/README.md"
```


```python
def try_to_load_from_cache(
    repo_id: str,  # ä¸€çº§æˆ–ä¸¤çº§, ä¾‹å¦‚: bert-base, fnlp/bart-base-chinese
    filename: str,  # æ–‡ä»¶å, ä¾‹å¦‚ pytorch_model.bin
    cache_dir: Union[str, Path, None] = None,  # é»˜è®¤ä¸º TRANSFORMERS_CACHE=~/.cache/huggingface/hub
    revision: Optional[str] = None,  # åˆ†æ”¯å/commit-id, æ³¨æ„ä¸æ˜¯æ–‡ä»¶æœ¬èº«çš„hash-id
    repo_type: Optional[str] = None,  # model/dataset/space
) -> Optional[str]:
    """
    Returns:
        `Optional[str]` or `_CACHED_NO_EXIST`:
            Will return `None` if the file was not cached. Otherwise:
            - The exact path to the cached file if it's found in the cache
            - A special value `_CACHED_NO_EXIST` if the file does not exist at the given commit hash and this fact was
              cached.
    """
    if revision is None:
        revision = "main"

    if cache_dir is None:
        cache_dir = TRANSFORMERS_CACHE

    object_id = repo_id.replace("/", "--")
    if repo_type is None:
        repo_type = "model"
    repo_cache = os.path.join(cache_dir, f"{repo_type}s--{object_id}")
    if not os.path.isdir(repo_cache):
        # No cache for this model
        return None
    for subfolder in ["refs", "snapshots"]:
        if not os.path.isdir(os.path.join(repo_cache, subfolder)):
            return None

    # Resolve refs (for instance to convert main to the associated commit sha)
    cached_refs = os.listdir(os.path.join(repo_cache, "refs"))
    if revision in cached_refs:
        with open(os.path.join(repo_cache, "refs", revision)) as f:
            revision = f.read()

    if os.path.isfile(os.path.join(repo_cache, ".no_exist", revision, filename)):
        return _CACHED_NO_EXIST

    cached_shas = os.listdir(os.path.join(repo_cache, "snapshots"))
    if revision not in cached_shas:
        # No cache for this revision and we won't try to return a random revision
        return None

    cached_file = os.path.join(repo_cache, "snapshots", revision, filename)
    return cached_file if os.path.isfile(cached_file) else None
```
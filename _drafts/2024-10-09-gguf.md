---
layout: post
title: "(P0) GGUF,GGML,llama.cpp"
date: 2024-10-09 13:00:04 +0800
labels: [llm]
---

## 动机、参考资料、涉及内容

涉及内容: GGUF 文件格式, llama.cpp, GGML

## 简介

[GGML](https://github.com/ggerganov/ggml)(GPT-Generated Model Language) 是一个开源项目(可以类比 pytorch), 用于高效的利用 CPU 进行张量计算, 项目定义了一种 GGUF(GPT-Generated Unified Format) 文件格式. GGML 的作者也同样是 [llama.cpp](https://github.com/ggerganov/llama.cpp) 的作者, 而 llama.cpp 用于高效的利用 CPU 进行市面上流行的许多开源大模型的推理.

目前看 GGML 和 llama.cpp 项目没有依赖关系, 因此可能有代码会重复?

如果只希望快速部署一些开源大模型, 一般只需要关心 llama.cpp 即可, 具体例子见下节

## llama.cpp Quick Start

普通的算法工程师一般只需要知道按如下方式部署一个现成的模型

参考: [https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF), 步骤如下:

```bash
git clone --depth=1 -b master https://github.com/ggerganov/llama.cpp.git
cd llama.cpp
# 编译可执行文件
make -j8
# 下载 gguf 文件
huggingface-cli download Qwen/Qwen2.5-1.5B-Instruct-GGUF qwen2.5-1.5b-instruct-q5_k_m.gguf --local-dir . --local-dir-use-symlinks False
# 运行一个命令行交互的简单 demo
./llama-cli -m qwen2.5-1.5b-instruct-q5_k_m.gguf -co -cnv -p "You are Qwen, created by Alibaba Cloud. You are a helpful assistant." -fa -ngl 80 -n 512
```

更深入的情况是:

- Q1: 如果只有 `pytorch_model.bin` 这种形式的权重, 怎么转换为 GGUF 格式?
- A1: 如果模型结构被 [convert_hf_to_gguf.py](https://github.com/ggerganov/llama.cpp/blob/master/convert_hf_to_gguf.py) 脚本支持, 那么直接用脚本转化即可
- Q2: 如果模型结构不被支持呢?
- A2: 可以修改 `convert_hf_to_gguf.py` 文件, 其实如果你这么做了, 你事实上可以为 llama.cpp 提 PR, 实际做起来你可能需要参考 [HOWTO-add-model.md](https://github.com/ggerganov/llama.cpp/blob/master/docs/development/HOWTO-add-model.md)
- Q3: 如果你很想知道 GGUF 文件的具体格式, 以探索用 GGUF 文件存储别的东西, 或者做更多的事情
- A3: 请看下文

通常情况下, 至多只需要知道 A1 即可: 一般是你对模型做了微调, 需要自己转换格式, 但一般来说也就是用 huggingface transformers 进行微调, 而它大概也继承了这个转换脚本, 因此甚至于不需要知道 A1.

## GGUF 文件格式

- GGML 文档 (最官方的描述): [https://github.com/ggerganov/ggml/blob/master/docs/gguf.md](https://github.com/ggerganov/ggml/blob/master/docs/gguf.md)
- huggingface hub 文档: [https://huggingface.co/docs/hub/en/gguf](https://huggingface.co/docs/hub/en/gguf)

`llama.cpp` 项目下包含一个子项目: gguf-py ([pypi:gguf](https://pypi.org/project/gguf/)), 这个子项目是纯 python 实现 GGUF 文件的读写, 因此可以用来了解 GGUF 的文件格式.

TODO: llama.cpp 里实际使用的应该是 C 语言的实现, 待搜寻

### 初体验: 读取一个实际的 GGUF 文件

```bash
cd /path/to/llama.cpp/gguf-py
pip install -e .
python examples/reader.py ../qwen/qwen2.5-1.5b-instruct-q5_k_m.gguf
```

可以得到这样的输出(省略了许多层)

```
Key-Value Pairs:
GGUF.version                           : [3]
GGUF.tensor_count                      : [339]
GGUF.kv_count                          : [26]
general.architecture                   : [113 119 101 110  50]
general.type                           : [109 111 100 101 108]
general.name                           : [113 119 101 110  50  46  53  45  49  46  53  98  45 105 110 115 116 114 117  99 116]
general.version                        : [118  48  46  49]
general.finetune                       : [113 119 101 110  50  46  53  45  49  46  53  98  45 105 110 115 116 114 117  99 116]
general.size_label                     : [49 46 56 66]
qwen2.block_count                      : [28]
qwen2.context_length                   : [32768]
qwen2.embedding_length                 : [1536]
qwen2.feed_forward_length              : [8960]
qwen2.attention.head_count             : [12]
qwen2.attention.head_count_kv          : [2]
qwen2.rope.freq_base                   : [1000000.]
qwen2.attention.layer_norm_rms_epsilon : [1.e-06]
general.file_type                      : [17]
tokenizer.ggml.model                   : [103 112 116  50]
tokenizer.ggml.pre                     : [113 119 101 110  50]
tokenizer.ggml.tokens                  : [33]
tokenizer.ggml.token_type              : [1]
tokenizer.ggml.merges                  : [196 160  32 196 160]
tokenizer.ggml.eos_token_id            : [151645]
tokenizer.ggml.padding_token_id        : [151643]
tokenizer.ggml.bos_token_id            : [151643]
tokenizer.ggml.add_bos_token           : [False]
tokenizer.chat_template                : [123  37  45 ...  37 125  10]
general.quantization_version           : [2]
----
Tensors:
Tensor Name                    | Shape: Shape           | Size: Size         | Quantization: Quantization
--------------------------------------------------------------------------------
output.weight                  | Shape: 1536x151936     | Size: 233373696    | Quantization: Q6_K
token_embd.weight              | Shape: 1536x151936     | Size: 233373696    | Quantization: Q5_K
blk.0.attn_norm.weight         | Shape: 1536            | Size: 1536         | Quantization: F32
blk.0.ffn_down.weight          | Shape: 8960x1536       | Size: 13762560     | Quantization: Q6_K
blk.0.ffn_gate.weight          | Shape: 1536x8960       | Size: 13762560     | Quantization: Q5_K
blk.0.ffn_up.weight            | Shape: 1536x8960       | Size: 13762560     | Quantization: Q5_K
blk.0.ffn_norm.weight          | Shape: 1536            | Size: 1536         | Quantization: F32
blk.0.attn_k.bias              | Shape: 256             | Size: 256          | Quantization: F32
blk.0.attn_k.weight            | Shape: 1536x256        | Size: 393216       | Quantization: Q5_K
blk.0.attn_output.weight       | Shape: 1536x1536       | Size: 2359296      | Quantization: Q5_K
blk.0.attn_q.bias              | Shape: 1536            | Size: 1536         | Quantization: F32
blk.0.attn_q.weight            | Shape: 1536x1536       | Size: 2359296      | Quantization: Q5_K
blk.0.attn_v.bias              | Shape: 256             | Size: 256          | Quantization: F32
blk.0.attn_v.weight            | Shape: 1536x256        | Size: 393216       | Quantization: Q6_K
...
output_norm.weight             | Shape: 1536            | Size: 1536         | Quantization: F32
```

这些输出可以与[huggingface-hub](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/tree/main?show_file_info=qwen2.5-1.5b-instruct-q5_k_m.gguf)的显示进行对照, 两者本质是完全一致的, 只是 huggingface-hub 上的显示更为友好一些, 例如:

```python
# general.architecture: [113 119 101 110  50]
x = [113, 119, 101, 110, 50]
assert "".join([chr(_) for _ in x]) == "qwen2"
```

GGUF 与 Pytorch 相互转化, 可以参考: [https://huggingface.co/docs/transformers/v4.45.2/en/gguf](https://huggingface.co/docs/transformers/v4.45.2/en/gguf)

```python
# 利用 transformers 将 GGUF 转化为普通的 Pytorch Module 的 state_dict: 本质上也是利用 gguf python 包: from gguf import GGUFReader, dequantize
from transformers import AutoModelForCausalLM
import os
path = "/path/to/qwen/qwen2.5-1.5b-instruct-q5_k_m.gguf"
model = AutoModelForCausalLM.from_pretrained(os.path.dirname(path), gguf_file=path)  # 转化后是普通版本 float 权重的模型

# 将 transformers 的 Pytorch Module 权重文件转化为 GGUF 格式: 本质上是一个模型一个模型去与 huggingface 对齐的, 实质上也是使用了 GGUFWriter
https://github.com/ggerganov/llama.cpp/blob/master/convert_hf_to_gguf.py
```

接下来, 我们将深入理解读取过程, 从而理解 GGUF 的数据排布方式

### 前置知识: numpy 与 C 结构体的文件读写

<details markdown="1">
<summary>隐藏</summary>

#### numpy: memmap 与 .npy 文件

```python
import numpy as np
import struct

# memmap
nrows, ncols = 2, 3
arr = np.memmap('arr.dat', dtype=np.int32, mode='w', shape=(nrows, ncols))
arr[0][0] = 1
arr[0][1] = 2
arr[0][2] = 3
arr[1][0] = 4
arr[1][1] = 5
arr[1][2] = 6
arr.flush()

with open('arr.dat', "rb") as fr:
    x = fr.read()

struct.unpack("6I", x)  # (1, 2, 3, 4, 5, 6)


# npy 文件
with open("arr.npy", "wb") as fw:
    np.save(fw, np.array([1, 2, 3, 4], dtype=np.int32))
with open("arr.npy", "rb") as fr:
    x = fr.read()  # b"\x93NUMPY\x01\x00v\x00{'descr': '<i4', 'fortran_order': False, 'shape': (4,), }
len(x)  # 144
```

以上示例代码有如下要点:

- `np.memmap` 写入的内容只包含纯数据, 而 `.npy` 文件还包含了一些额外信息
- `numpy` 数组是行优先存储的

#### C 语言结构体写入文件

```C
#include <stdio.h>
#include <string.h>

struct MyStruct {
    int id;
    float value;
    char name[20];
};

int write_example() {
    struct MyStruct example;

    example.id = 1;
    example.value = 10.5;
    snprintf(example.name, sizeof(example.name), "ExampleName");

    // 打开文件以二进制写入模式
    FILE *file = fopen("data.bin", "wb");
    if (!file) {
        perror("Failed to open file");
        return 1;
    }

    // 将结构体写入文件
    fwrite(&example, sizeof(struct MyStruct), 1, file);

    // 关闭文件
    fclose(file);

    printf("Structure saved to binary file.\n");
    return 0;
}

int read_example() {
    struct MyStruct example_read;
    FILE *file = fopen("data.bin", "rb");
    if (!file) {
        perror("Failed to open file");
        return 1;
    }

    fread(&example_read, sizeof(struct MyStruct), 1, file);
    fclose(file);

    printf("ID: %d, Value: %f, Name: %s\n", example_read.id, example_read.value, example_read.name);
    return 0;
}

int main() {
    write_example();
    read_example();
    return 0;
}
```

使用 python 读取文件

```python
import numpy as np
with open("data.bin", "rb") as fr:
    x = fr.read(4) # 32 位整数
    y = fr.read(4) # 浮点数
    z = fr.read()  # 长度为 20

np.frombuffer(x, dtype=np.int32)   # array([1], dtype=int32)
np.frombuffer(y, dtype=np.float32) # array([10.5], dtype=float32)
"".join([chr(x) for x in np.frombuffer(z, dtype=np.uint8)])  # 'ExampleName\x00\x00\x00\x00\x00 á\x1d*'
```

</details>

### GGUF 文件数据排布

`reader.py` 详解: GGUF 文件的内容格式如下图所示

![https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/gguf-spec.png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/gguf-spec.png)

以下为文件内容的 Overview (精确描述)

- 文件的前 4 个字节以 uint32 按 Little Endian 读取必须是 GGUF
- 接下来的 4 个字节以 uint32 按系统默认的字节序读取, 得到版本号(目前是3), 并同时得知后续内容中文件的字节序是 Big Endian 还是 Little Endian
- 接下来的 8 个字节代表 metadata 总共有几个
- 接下来的 8 个字节代表 tensor 总共有几个
- metadata 的实际数据内容
- tensor 的元信息, 例如数据类型, 数据个数, 起始位置
- padding: 字节对齐, 使得第一个 tensor 的起始位置是字节对齐的
- tensor 的实际数据内容, 每个 tensor 结尾都需要 padding 用于字节对齐

其准确的数据排布定义于 [https://github.com/ggerganov/ggml/blob/master/docs/gguf.md](https://github.com/ggerganov/ggml/blob/master/docs/gguf.md) 文件内

<details markdown="1">
<summary>个人注释版</summary>

```C
// GGUF 所支持的 tensor 数据类型
enum ggml_type: uint32_t {
    GGML_TYPE_F32     = 0,  // float32 类型
    GGML_TYPE_F16     = 1,  // float16 类型
    GGML_TYPE_Q4_0    = 2,
    // ...
    GGML_TYPE_IQ1_M   = 29,
    GGML_TYPE_COUNT,
};

// GGUF 文件中 value 的数据类型
enum gguf_metadata_value_type: uint32_t {
    GGUF_METADATA_VALUE_TYPE_UINT8 = 0,
    GGUF_METADATA_VALUE_TYPE_INT8 = 1,
    GGUF_METADATA_VALUE_TYPE_UINT16 = 2,
    GGUF_METADATA_VALUE_TYPE_INT16 = 3,
    GGUF_METADATA_VALUE_TYPE_UINT32 = 4,
    GGUF_METADATA_VALUE_TYPE_INT32 = 5,
    GGUF_METADATA_VALUE_TYPE_FLOAT32 = 6,
    GGUF_METADATA_VALUE_TYPE_BOOL = 7,
    GGUF_METADATA_VALUE_TYPE_STRING = 8,
    GGUF_METADATA_VALUE_TYPE_ARRAY = 9,
    GGUF_METADATA_VALUE_TYPE_UINT64 = 10,
    GGUF_METADATA_VALUE_TYPE_INT64 = 11,
    GGUF_METADATA_VALUE_TYPE_FLOAT64 = 12,
};

// GGUF 文件中的字符串数据结构: len 代表长度, 然后跟着实际的字符串数据
struct gguf_string_t {
    uint64_t len;
    char string[len];
};

// GGUF 文件中 metadata 的 value 实际值的数据结构
union gguf_metadata_value_t {
    // 数值类型: 直接存值
    uint8_t uint8;
    int8_t int8;
    uint16_t uint16;
    int16_t int16;
    uint32_t uint32;
    int32_t int32;
    float float32;
    uint64_t uint64;
    int64_t int64;
    double float64;
    bool bool_;
    // 字符串类型: 先存长度, 再存值
    gguf_string_t string;
    // 数组类型: 先存元素类型, 再存元素个数, 最后存值
    struct {
        gguf_metadata_value_type type;
        uint64_t len;
        gguf_metadata_value_t array[len];
    } array;
};

// GGUF 文件中一项 metadata 的 kv 对的数据结构: 先存key,再存value的数据类型,最存value的值
struct gguf_metadata_kv_t {
    gguf_string_t key;
    gguf_metadata_value_type value_type;
    gguf_metadata_value_t value;
};

// GGUF 文件头部分
struct gguf_header_t {
    uint32_t magic;  // "GGUF" 的字节表示: 0x47475546
    uint32_t version;  // 目前是 3
    uint64_t tensor_count;  // 文件中 tensor 的数量
    uint64_t metadata_kv_count;  // 文件中 metadata 的数量
    gguf_metadata_kv_t metadata_kv[metadata_kv_count];  // metadata
};

// 字节对齐: 每个 tensor data 的起始位置必须是 ALIGNMENT 的整数倍
uint64_t align_offset(uint64_t offset) {
    return offset + (ALIGNMENT - (offset % ALIGNMENT)) % ALIGNMENT;
}

// GGUF 文件的一项 tensor info 的数据结构
struct gguf_tensor_info_t {
    gguf_string_t name;  // tensor 的名称
    uint32_t n_dimensions;  // tensor 的维度, 目前最大是 4
    uint64_t dimensions[n_dimensions];  // tensor 的 shape.
    ggml_type type;  // tensor 的数据类型
    uint64_t offset;  // 相较于 gguf_file_t.tensor_data 的 offset
};


// GGUF 文件
struct gguf_file_t {
    gguf_header_t header;  // GGUF 文件头部分
    gguf_tensor_info_t tensor_infos[header.tensor_count];  // tensor info
    // 字节对齐
    uint8_t _padding[];
    // tensor 的实际值, 每个 tensor 的起始位置必须是 ALIGNMENT 的整数倍(字节对齐)
    uint8_t tensor_data[];
};
```

</details>

### GGUFReader 详解

以 `qwen2.5-1.5b-instruct-q5_k_m.gguf` 文件为例, 阅读 `gguf.GGUFReader` 的 `__init__` 方法

本质上是按顺序解析

- (1) 头部
- (2) metadata
- (3) tensor info
- (4) tensor data

#### (1) 头部

共 `4+4+8+8=24` 个字节, `GGUFReader` 最终会在 `self.fields` 里增加 `"GGUF.version"`, `"GGUF.tensor_count"`, `"GGUF.kv_count"` 这三个 `ReaderField`

以下是直接对字节进行手工解析的代码

```python
import numpy as np
with open(path, "rb") as fr:
    offset = 0
    
    x = fr.read(4)  # b'GGUF': 魔术数字
    offset += 4
    
    x = fr.read(4)   # b'\x03\x00\x00\x00'
    np.frombuffer(x, dtype=np.uint32)  # array([3], dtype=uint32): GGUF 版本号
    offset += 4

    tensor_count = fr.read(8)
    tensor_count = int(np.frombuffer(tensor_count, dtype=np.uint64))  # 339, 表示有 339 个 tensor
    offset += 8

    kv_count = fr.read(8)
    kv_count = int(np.frombuffer(kv_count, dtype=np.uint64)[0])  # 26, 表示后续有 26 个 metadata
    offset += 8
```

#### (2) metadata

```python
class GGUFValueType(IntEnum):
    UINT8   = 0
    INT8    = 1
    UINT16  = 2
    INT16   = 3
    UINT32  = 4
    INT32   = 5
    FLOAT32 = 6
    BOOL    = 7
    STRING  = 8
    ARRAY   = 9
    UINT64  = 10
    INT64   = 11
    FLOAT64 = 12

# 一个 ReaderField 代表了一个 metadata 的 kv 对
class ReaderField(NamedTuple):
    offset: int  # 起始地址
    name: str    # key的字符串表示
    parts: list[npt.NDArray[Any]] = []  # 将字节拆分为多个部分, 将 parts 转化为字节合并在一起即为文件中针对该 metadata 的原始的字节表示
    data: list[int] = [-1]  # parts 的下标数组, 真实的数据所对应的实际下标
    types: list[GGUFValueType] = []  # value的数据类型描述, 对于简单的标量, types 仅包含一个元素, 对于嵌套情形, types 包含多个元素

# GGUFReader 中最终是将这些 metadata 放在 self.fields 里
# field: ReaderField
# self.fields[field.name] = field
```

以下是直接对字节进行手工解析的代码(TODO)

```python
import numpy as np
from gguf.constants import GGUFValueType

with open(path, "rb") as fr:
    fr.seek(24)  # 跳过头部的 24 个字节

    # value 的类型仅支持数字,字符串, Array. 但 Array 里必须是同类型的, 且允许嵌套(嵌套情形后面再看)

    # metadata 的数据组织形式
    # uint64: key 的长度
    # key
    # uint32: value 的类型
    # 以下排布方式与 value 类型相关:
    # (1) string:
    # uint64: value 的长度
    # value
    # 例子: [20, general.architecture, 8, 5, qwen2], GGUFValueType.STRING=8
    # (2) uint8,int8,uint16,int16,uint32,int32,uint64,int64,bool,float32,float64
    # value
    # 例子: [26, qwen2.attention.head_count, 4, 12], GGUFValueType.UINT32=4
    # (3) array
    # uint32: value 中每个元素的类型
    # value: 根据每个元素是字符串还是数值类型确定
    # 例子(array[string]): [21, tokenizer.ggml.tokens, 9, 8, 1, 33, 1, 34, ...]
    # 其中 GGUFValueType.ARRAY=9, GGUFValueType.STRING=8
    # 接下来每两个数据项为一组, 例如: [1, 33] 代表 `!`, [1, 34] 代表 `"`
    

    # ReaderField: NamedTuple
    # offest: int, 起始地址
    # name: str, key 的字符串形式
    # parts: List[np.array], 以 value 是字符串类型为例, parts 是一个五元组
    #     [
    #         np.array([20], dtype=np.uint64),
    #         np.array([103, 101, 110, 101, 114,  97, 108,  46,  97, 114,  99, 104, 105, 116, 101,  99, 116, 117, 114, 101], dtype=np.uint8),
    #         np.array([8], dtype=np.uint32),
    #         np.array([5], dtype=np.uint64),
    #         np.array([113, 119, 101, 110,  50], dtype=np.uint8)
    #     ]
    # data: List[int], parts 中哪些项是数据, value 是字符串类型为例, data 是 [4], 代表 parts[4] 是 value 的值 
    # types: List[GGUFValueType], 以 value 是字符串类型为例, types = [GGUFValueType.STRING]
    # types 与 data 的长度不一定一致, 例如 data=[6,8,...], type = [GGUFValueType.ARRAY, GGUFValueType.STRING]
    
    key_len = fr.read(8)
    key_len = int(np.frombuffer(key_len, dtype=np.uint64)[0])
    offset += 8
    
    key_data = fr.read(key_len)
    key_data = np.frombuffer(key_data, dtype=np.uint8)
    offset += key_len

    raw_kv_type = fr.read(4)
    raw_kv_type = int(np.frombuffer(raw_kv_type, dtype=np.uint32)[0])  # 8, 代表 String
```


metadata 中的 value 可以是 Array, 且允许一定程度的嵌套, 首先利用 `GGUFWriter` 和 `GGUFReader` 观察一下可以怎么嵌套

```python
from gguf import GGUFWriter, GGUFReader
import numpy as np

def writer_example() -> None:
    gguf_writer = GGUFWriter("example.gguf", "llama")
    
    gguf_writer.add_array("arr", [[1, 2, 3], [4, 5, 6]])  # 情况1, ok
    # gguf_writer.add_array("arr", [[1, 2, 3], ["abc", "def"]])  # 情况2, ok, 嵌套时允许不等长, 也允许基本元素类型不一致
    # gguf_writer.add_array("arr", [[1, 2, 3], ["abc", "def", 3]])  # error
    
    tensor1 = np.ones((32,), dtype=np.float32) * 100.0
    gguf_writer.add_tensor("tensor1", tensor1)
    gguf_writer.write_header_to_file()
    gguf_writer.write_kv_data_to_file()
    gguf_writer.write_tensors_to_file()
    gguf_writer.close()

writer_example()
reader = GGUFReader("example.gguf")

parts = reader.fields['arr'].parts
types = reader.fields["arr"].types
data_indexes = reader.fields["arr"].data
data = [parts[idx] for idx in data_indexes]

print("parts:", parts)
print("types:", types)
print("data_indexes:", data_indexes)
print("data:", data)
```

<details markdown="1">
<summary>情况1</summary>

情况1: `[[1, 2, 3], [4, 5, 6]]`

```text
parts:
[
    memmap([3], dtype=uint64),           # key 字符串 "arr" 的字节数是 3
    memmap([97, 114, 114], dtype=uint8), # key 字符串: "arr" 的 ASCII 码表示是 [97, 114, 114]
    memmap([9], dtype=uint32),           # GGUFValueType.ARRAY=9, 代表 value 的数据类型是 ARRAY, 因此按照 gguf_metadata_value_t 的定义, 接下来需要记录 value 中每个元素的数据类型和 value 的长度, 最后是 value 的实际数据
    memmap([9], dtype=uint32),           # GGUFValueType.ARRAY=9, 由于 value 的数据类型是 ARRAY, 这里需要记录 value 中元素的数据类型, 这里内层依然是 ARRAY
    memmap([2], dtype=uint64),           # 代表 value 的长度是 2
    memmap([5], dtype=uint32),           # GGUFValueType.INT32=5, 由于 value 中元素的数据类型是 ARRAY, 因此需要记录内部数据类型, 长度以及实际内容
    memmap([3], dtype=uint64),           # 长度为 3
    memmap([1], dtype=int32),            # 1, 实际数据
    memmap([2], dtype=int32),            # 2, 实际数据
    memmap([3], dtype=int32),            # 3, 实际数据
    memmap([5], dtype=uint32),           # GGUFValueType.INT32=5, 由于 value 中元素的数据类型是 ARRAY, 因此需要记录内部数据类型, 长度以及实际内容
    memmap([3], dtype=uint64),           # 长度为 3
    memmap([4], dtype=int32),            # 4, 实际数据
    memmap([5], dtype=int32),            # 5, 实际数据
    memmap([6], dtype=int32)             # 6, 实际数据
]
types:
[<GGUFValueType.ARRAY: 9>, <GGUFValueType.ARRAY: 9>, <GGUFValueType.INT32: 5>]
data_indexes:
[7, 8, 9, 12, 13, 14]
data:
[memmap([1], dtype=int32), memmap([2], dtype=int32), memmap([3], dtype=int32), memmap([4], dtype=int32), memmap([5], dtype=int32), memmap([6], dtype=int32)]
```

备注: `types` 字段看起来少记录了一个 `GGUFValueType.INT32`, 这应该是 gguf 的 BUG

</details>

<details markdown="1">
<summary>情况2</summary>

情况2: `[[1, 2, 3], ["abc", "def"]]`

```text
parts:
[
    memmap([3], dtype=uint64),            # key 字符串 "arr" 的字节数是 3
    memmap([ 97, 114, 114], dtype=uint8), # key 字符串: "arr" 的 ASCII 码表示是 [97, 114, 114]
    memmap([9], dtype=uint32),            # GGUFValueType.ARRAY=9, 代表 value 的数据类型是 ARRAY, 因此按照 gguf_metadata_value_t 的定义, 接下来需要记录 value 中每个元素的数据类型和 value 的长度, 最后是 value 的实际数据
    memmap([9], dtype=uint32),            # GGUFValueType.ARRAY=9, 由于 value 的数据类型是 ARRAY, 这里需要记录 value 中元素的数据类型, 这里内层依然是 ARRAY
    memmap([2], dtype=uint64),            # 2, 代表 value 的长度是 2
    memmap([5], dtype=uint32),            # GGUFValueType.INT32=5, 由于 value 中元素的数据类型是 ARRAY, 因此需要记录内部数据类型, 长度以及实际内容
    memmap([3], dtype=uint64),            # 长度为 3
    memmap([1], dtype=int32),             # 1, 实际数据
    memmap([2], dtype=int32),             # 2, 实际数据
    memmap([3], dtype=int32),             # 3, 实际数据
    memmap([8], dtype=uint32),            # GGUFValueType.STRING=8, 由于 value 中元素的数据类型是 ARRAY, 因此需要记录内部数据类型, 长度以及实际内容
    memmap([2], dtype=uint64),            # 长度为 2
    memmap([3], dtype=uint64),            # 字符串长度是 3
    memmap([97, 98, 99], dtype=uint8),    # 实际数据: "abc"
    memmap([3], dtype=uint64),            # 字符串长度是 3
    memmap([100, 101, 102], dtype=uint8)  # 实际数据: "def"
]
types:
[<GGUFValueType.ARRAY: 9>, <GGUFValueType.ARRAY: 9>, <GGUFValueType.INT32: 5>]
data_indexes:
[7, 8, 9, 13, 15]
data:
[memmap([1], dtype=int32), memmap([2], dtype=int32), memmap([3], dtype=int32), memmap([97, 98, 99], dtype=uint8), memmap([100, 101, 102], dtype=uint8)]
```

备注: `types` 字段看起来少记录了一个 `GGUFValueType.STRING`, 这应该是 gguf 的 BUG

</details>

#### (3) tensor info 以及 padding

TODO

#### (4) tensor data

TODO

## 量化与反量化

TODO
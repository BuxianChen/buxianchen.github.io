---
layout: post
title: "(LTS) 大模型应用层工具"
date: 2024-02-21 10:05:04 +0800
labels: [llm]
---

## 动机、参考资料、涉及内容

一些面向大模型应用层面 (也就是提示工程) 的工具记录

## LLM

### litellm
litellm 是一个 Python 包, 用于将各个大模型提供的大模型接口的输入输出格式统一为 OpenAI 格式

文档: [https://docs.litellm.ai/docs/](https://docs.litellm.ai/docs/)

主要有两种用法

#### 作为 python 模块使用

```python
from litellm import completion
import os

messages = [{ "content": "Hello, how are you?", "role": "user"}]

# OpenAI
os.environ["OPENAI_API_KEY"] = "your-api-key"

response = completion(
  model="gpt-3.5-turbo",
  messages=messages
)

# Azure OpenAI
os.environ["AZURE_API_KEY"] = ""
os.environ["AZURE_API_BASE"] = ""
os.environ["AZURE_API_VERSION"] = ""

response = completion(
  "azure/<your_deployment_name>",
  messages=messages
)

output_text: str = response['choices'][0]['message']['content']
```

#### 作为代理使用

litellm 还可以作为代理使用, 具体做法如下

**启动代理服务**

方案 1:

```bash
pip install litellm[proxy]
export OPEN_API_KEY=my-api-key
litellm --model gpt-3.5-turbo
```

方案 2:

先编写一个 `config.yaml` 文件

```yaml
model_list:
  - model_name: gpt-3.5-turbo # user-facing model alias
    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
      model: azure/<your-deployment-name>
      api_base: <your-azure-api-endpoint>
      api_key: <your-azure-api-key>
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: azure/gpt-turbo-small-ca
      api_base: https://my-endpoint-canada-berri992.openai.azure.com/
      api_key: <your-azure-api-key>
  - model_name: vllm-model
    litellm_params:
      model: openai/<your-model-name>
      api_base: <your-api-base> # e.g. http://0.0.0.0:3000
```

使用配置文件 `config.yaml` 文件启动

```bash
litllm --config config.yaml
```

**使用代理**

`curl` 的使用

```bash
curl --location 'http://0.0.0.0:4000/chat/completions' \
--header 'Content-Type: application/json' \
--data ' {
      "model": "gpt-3.5-turbo",
      "messages": [
        {
          "role": "user",
          "content": "what llm are you"
        }
      ]
    }
'
```

`openai-python` 的使用

```python
import openai
client = openai.OpenAI(
    api_key="anything",  # 这里随便传即可, 会被忽略, api_key 在代理启动时设置
    base_url="http://0.0.0.0:4000"
)

response = client.chat.completions.create(model="gpt-3.5-turbo", messages = [
    {
        "role": "user",
        "content": "this is a test request, write a short poem"
    }
])
```

作为代理使用的好处是, `api_key` 在使用代理时无需关心, 只需要在代理服务启动时配置好即可. 并且可以在配置文件中自定义模型名.

备注: 关于 `base_url` 为什么写作 `0.0.0.0` 而不是 `127.0.0.1`, 这是因为当 `0.0.0.0` 作为目标 IP 时, 通常会解释为本机 IP, 所以这么写是 OK 的. 当然, 最明确的写法的确是使用 `127.0.0.1` 或者本机 IP (准确地说是代理服务的 IP)

关于 `127.0.0.1` 与 `0.0.0.0` 的问答: [https://unix.stackexchange.com/questions/419880/connecting-to-ip-0-0-0-0-succeeds-how-why](https://unix.stackexchange.com/questions/419880/connecting-to-ip-0-0-0-0-succeeds-how-why)

## OCR

### rapidocr

只需要 `pip install` 即可, 安装包内自带模型文件 `site-packages/rapidocr_onnxruntime/models/{ch_ppocr_mobile_v2.0_cls_infer.onnx,ch_PP-OCRv4_det_infer.onnx,ch_PP-OCRv4_rec_infer.onnx}`, 无需再额外下载模型. 以下是一个例子, 样例图片来源于[此处](https://github.com/chatchat-space/Langchain-Chatchat/blob/1fa714ee71940a25818c72b3e663d05ff9b3b19d/knowledge_base/samples/content/llm/img/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86-%E5%B9%95%E5%B8%83%E5%9B%BE%E7%89%87-42284-124759.jpg) (注意: 在这个例子中实际上有漏识别的文字)

```python
# pip install rapidocr_onnxruntime
from rapidocr_onnxruntime import RapidOCR
ocr = RapidOCR()
result, _ = ocr("分布式训练技术原理-幕布图片-42284-124759.jpg")
```

输出

```
# result
[[[[935.0, 171.0], [1015.0, 171.0], [1015.0, 233.0], [935.0, 233.0]],
  'Y1',
  0.6642794211705526],
 [[[1107.0, 171.0], [1201.0, 171.0], [1201.0, 235.0], [1107.0, 235.0]],
  'Y2',
  0.6654683748881022],
 [[[462.0, 193.0], [561.0, 193.0], [561.0, 235.0], [462.0, 235.0]],
  'WE1',
  0.7467206418514252],
 [[[635.0, 192.0], [744.0, 194.0], [744.0, 235.0], [634.0, 234.0]],
  'WE2',
  0.7468263655900955],
 [[[536.0, 384.0], [678.0, 382.0], [679.0, 428.0], [537.0, 430.0]],
  '(h,v/N)',
  0.8688599616289139],
 [[[1371.0, 375.0], [1636.0, 376.0], [1635.0, 427.0], [1370.0, 426.0]],
  '知s@猛猿',
  0.6824508408705393],
 [[[91.0, 385.0], [233.0, 383.0], [233.0, 428.0], [91.0, 429.0]],
  '(b, s, h)',
  0.8148094713687897],
 [[[978.0, 386.0], [1161.0, 383.0], [1162.0, 426.0], [978.0, 429.0]],
  '(b,S,v/N)',
  0.7499212145805358]]

# _, 暂时不明白含义是什么, 每次运行结果还不一样
[1.8297991752624512, 0.01677227020263672, 0.4000370502471924]
```
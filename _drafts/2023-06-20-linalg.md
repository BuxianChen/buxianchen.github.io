---
layout: post
title: "(WIP) 线性代数回顾"
date: 2023-06-20 13:50:04 +0800
labels: [math]
---

## 动机、参考资料、涉及内容

动机

- GPTQ 算法中涉及到一些关于矩阵的逆, 矩阵分解的内容

参考资料

待定

涉及内容

- 线性代数定理(重结论, 适当证明)
- numpy/torch 相关函数的使用

不涉及内容

待定

## 高斯消元法

高斯消元法 (Gaussian elimination) 中的重要步骤是: 

**将一个矩阵的第 $i$ 行乘上一个系数 $k$ 加到第 $j$ 行上**

$$
\begin{bmatrix}
a_{1,1} &a_{1,2} &\cdots &a_{1,n-1} &a_{1,n}\\
a_{2,1} &a_{2,2} &\cdots &a_{2,n-1} &a_{2,n}\\
\vdots &\vdots   &\ddots &\vdots &\vdots \\
a_{j,1} &a_{j,2} &\cdots &a_{j,n-1} &a_{j,n}\\
\vdots &\vdots   &\ddots &\vdots &\vdots \\
a_{m-1,1} &a_{m-1,2} &\cdots &a_{m-1,n-1} &a_{m-1,n}\\
a_{m,1}   &a_{m,2} &\cdots &a_{m,n-1} &a_{m,n}\\
\end{bmatrix}

\to

\begin{bmatrix}
a_{1,1} &a_{1,2} &\cdots &a_{1,n-1} &a_{1,n}\\
a_{2,1} &a_{2,2} &\cdots &a_{2,n-1} &a_{2,n}\\
\vdots &\vdots   &\ddots &\vdots &\vdots \\
k\times a_{i, 1}+a_{j,1} &k\times a_{i, 2}+a_{j,2} &\cdots &k\times a_{i, n-1}+a_{j,n-1} &k\times a_{i, n}+a_{j,n}\\
\vdots &\vdots   &\ddots &\vdots &\vdots \\
a_{m-1,1} &a_{m-1,2} &\cdots &a_{m-1,n-1} &a_{m-1,n}\\
a_{m,1}   &a_{m,2} &\cdots &a_{m,n-1} &a_{m,n}\\
\end{bmatrix}
$$

这个操作用矩阵乘法来表达可以写作

$$
(\mathbf{I}_{(n,n)}+k\mathbf{E}_{j,i})A=
\begin{bmatrix}
1 & 0 & \cdots &0 &0 \\
0 & 1 & \cdots &0 &0 \\
\vdots &\vdots   &\ddots &\vdots &\vdots \\
0 & \dots & (j,i)=k, \dots &(j, j)=1 &0\\
\vdots &\vdots   &\ddots &\vdots &\vdots \\
0 & 0 & \cdots &1 &0 \\
0 & 0 & \cdots &0 &1 \\
\end{bmatrix}

\begin{bmatrix}
a_{1,1} &a_{1,2} &\cdots &a_{1,n-1} &a_{1,n}\\
a_{2,1} &a_{2,2} &\cdots &a_{2,n-1} &a_{2,n}\\
\vdots &\vdots   &\ddots &\vdots &\vdots \\
a_{j,1} &a_{j,2} &\cdots &a_{j,n-1} &a_{j,n}\\
\vdots &\vdots   &\ddots &\vdots &\vdots \\
a_{n-1,1} &a_{n-1,2} &\cdots &a_{n-1,n-1} &a_{n-1,n}\\
a_{m,1}   &a_{m,2} &\cdots &a_{m,n-1} &a_{m,n}\\
\end{bmatrix}
$$

其中 $\mathbf{E}_{j,i}$ 为 $(j, i)$ 元为 $1$, 其余元素均为 $0$ 的 $m\times m$ 方阵, 同样的道理,

**将一个矩阵的第 $i$ 列乘上一个系数 $k$ 加到第 $j$ 列上**, 用矩阵乘法表示是:

$$
A(\mathbf{I}_{(m,m)}+k\mathbf{E}_{i, j})
$$

其中 $\mathbf{E}_{i,j}$ 为 $(i, j)$ 元为 $1$, 其余元素均为 $0$ 的 $n\times n$ 方阵

### 小结论

(1)

$$
\mathbf{E}_{j, i}A\mathbf{E}_{i, j}=a_{i,i}\mathbf{E}_{j, j}
$$

(2) 假设 $A$ 是方阵, 且对角线元素 $a_{i, i}\neq 0$, 那么如下矩阵的第 $i$ 行与第 $i$ 列均为 $0$

$$
A-\frac{1}{a_{i,i}}A_{:,i}A_{i,:}
$$

注意:

$$
A_{:,i}A_{i,:}=(A\mathbf{E}_{i, i})(\mathbf{E}_{i, i}A)=A\mathbf{E}_{i, i}A
$$

## 正定/半正定矩阵

实正定矩阵对角线元素必为正数?

实半正定矩阵对角线元素非负? 分解后非零元的个数等于秩

实对称矩阵/正交/正定矩阵的分解形式

## Cholesky 矩阵分解

PSD (Positive Semi-Definite matrix) 表示半正定矩阵, PD (Positive Definite matrix) 表示正定矩阵.


```python
import torch
from torch.utils import benchmark

n = 256
k = 100

a = torch.randn((n, n))
M = a @ a.T + torch.eye(n)
y = torch.empty_like(M)
z = torch.empty_like(M)

t = benchmark.Timer(stmt="torch.inverse(M, out=y)", globals={"M": M, "y": y}).blocked_autorange(min_run_time=3).median
print(f"inverse ({n}, {n}) matrix, median time usage: {t*1000}ms")  # 0.71ms

t = benchmark.Timer(stmt="torch.cholesky_inverse(torch.linalg.cholesky(M), out=z)", globals={"M": M, "z": z}).blocked_autorange(min_run_time=3).median
print(f"cholesky_inverse ({n}, {n}) matrix, median time usage: {t*1000}ms")  # 0.60ms
```
---
layout: post
title: "(LTS) 资源与计划"
date: 2023-11-18 11:10:04 +0800
---

## 动机、参考资料、涉及内容

梳理学习资源及计划

## 资源

**Pytorch 与分布式训练相关**

- Pytorch tutorial: [https://pytorch.org/tutorials](https://pytorch.org/tutorials)
- 博客园(罗西的思考), 包含了一些关于分布式机器学习的博客(最大的优点是注明了原文的出处), 博主还出了本书: [https://www.cnblogs.com/rossiXYZ/](https://www.cnblogs.com/rossiXYZ/)
- [deepspeed](https://github.com/microsoft/DeepSpeed)
- [ColossalAI](https://github.com/hpcaitech/ColossalAI)

**大模型部署相关**

- [text-generation-inference](https://huggingface.co/docs/text-generation-inference/quicktour): huggingface 出品
- [vLLM](https://github.com/vllm-project/vllm)
- [deepspeed](https://www.deepspeed.ai/tutorials/inference-tutorial/): Microsoft 出品
- [DeepSpeed-MII](https://github.com/microsoft/DeepSpeed-MII): Microsoft 出品, 也许是目前最快的?
- [lmdeploy](https://github.com/InternLM/lmdeploy): mmlab 出品
- [FastTransformer](https://github.com/NVIDIA/FasterTransformer): Nvidia 出品
- [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM): Nvidia 出品, 似乎是 fastertransformer 的替代, 也许是目前最快的?
- [triton-inference-server](https://developer.nvidia.com/triton-inference-server): Nvidia 出品

**量化**

`W8A8` 指模型权重和激活值都量化到 8 bit int; `W4A16` 指模型权重量化到 4 bit int, 激活值保持为 FP 16

- [GPTQ](https://github.com/IST-DASLab/gptq), [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ)
- [exllama](https://github.com/turboderp/exllama): GPTQ 量化后模型推理的算子优化
- [AWQ](https://github.com/mit-han-lab/llm-awq), [AutoAWQ](https://github.com/casper-hansen/AutoAWQ)

pytorch 原生量化

pytorch 中的[量化公式](https://pytorch.org/docs/stable/quantization-support.html#quantized-dtypes-and-quantization-schemes)

- blog (2020/3/26, pytorch 1.4): [https://pytorch.org/blog/introduction-to-quantization-on-pytorch/](https://pytorch.org/blog/introduction-to-quantization-on-pytorch/)
- docs:
  - [https://pytorch.org/docs/stable/quantization.html](https://pytorch.org/docs/stable/quantization.html)
  - [pytorch wiki](https://github.com/pytorch/pytorch/wiki/Introducing-Quantized-Tensor)
- API: [https://pytorch.org/docs/stable/quantization-support.html](https://pytorch.org/docs/stable/quantization-support.html)
- tutorial:
  - [https://pytorch.org/tutorials/recipes/quantization.html](https://pytorch.org/tutorials/recipes/quantization.html)
  - [https://leimao.github.io/article/Neural-Networks-Quantization/](https://leimao.github.io/article/Neural-Networks-Quantization/)
  - [https://leimao.github.io/blog/PyTorch-Dynamic-Quantization/](https://leimao.github.io/blog/PyTorch-Dynamic-Quantization/)

**rapidapi**
[rapidapi](https://docs.rapidapi.com/docs/what-is-rapidapi): [ToolLLM paper](https://github.com/OpenBMB/ToolBench#data)


**pytorch compiler 相关**

- [torch.jit 文档](https://pytorch.org/docs/1.9.0/jit.html)
- [torch.fx 论文](https://arxiv.org/pdf/2112.08429.pdf)
- [Pytorch LazyTensor 论文](https://arxiv.org/pdf/2102.13267.pdf)
- [博客: Pytorch 的 2000+ 算子](https://dev-discuss.pytorch.org/t/where-do-the-2000-pytorch-operators-come-from-more-than-you-wanted-to-know/373/9)

**新闻**

- (2024/01/25) OpenAI 模型更新: [https://openai.com/blog/new-embedding-models-and-api-updates](https://openai.com/blog/new-embedding-models-and-api-updates): 文本嵌入模型 `text-embedding-3-large` 和 `text-embedding-3-small`, gpt 系列: `gpt-3.5-turbo-0125` 和 `gpt-4-0125-preview`, 合规检测模型(一个多分类模型, 免费使用): `text-moderation-007`
- (2024/02/13) OpenAI ChatGPT 聊天界面增加记忆管理等新功能: [https://openai.com/blog/memory-and-new-controls-for-chatgpt](https://openai.com/blog/memory-and-new-controls-for-chatgpt)
- (2024/02/09) Gemini Ultra: [https://deepmind.google/technologies/gemini/#gemini-1.0](https://deepmind.google/technologies/gemini/#gemini-1.0)
- (2024/02/14) Gemini 1.5: [https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)
- (2024/02/16) OpenAI 文生视频: [https://openai.com/sora](https://openai.com/sora)


**博客**

- [https://ruslanspivak.com/](https://ruslanspivak.com/): let's build a [compiler | web server] from scratch

**未归类**

- Langchain-Chatchat: [https://github.com/chatchat-space/Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat), 主要可以关注前端写法, 中文文本切分, 以及对 Langchain 的使用, asyncio 的用法等
- 一门深度学习系统课程: [https://github.com/chenzomi12/DeepLearningSystem](https://github.com/chenzomi12/DeepLearningSystem), B站/youtube 上还有视频课程


## 计划

- 线路1 (优先): Rust 入门 + text-generation-inference/huggingface Tokenizer 库
- 线路2: 《网络是怎样连接的》
- 线路3 (torch.fx 优先): torch.fx + torchscript + torch.compile
- 线路4 (优先): torch 原生支持的量化 + QAT + AWQ
- 线路5: lmdeploy 的组装 batch 的一些细节
- 线路6: DDP 与 FSDP
- 线路7: 自动微分 + 陈天奇 dlsyscourse 课程
- 线路8: Tensor Parallel + Pipeline Parallel (lmdeploy 等框架)